[2022-12-21 15:14:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 540
train_sample_count: 540
avg_envstep_per_episode: 77.14285714285714
avg_sample_per_episode: 77.14285714285714
avg_envstep_per_sec: 514.7057158435955
avg_train_sample_per_sec: 514.7057158435955
avg_episode_per_sec: 6.672111131305868
collect_time: 1.049143196544743
reward_mean: 449.28570556640625
reward_std: 189.08480834960938
reward_max: 618.0
reward_min: 231.0
total_envstep_count: 1147
total_train_sample_count: 1128
total_episode_count: 7
total_duration: 1.049143196544743
[2022-12-21 15:15:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 327
train_sample_count: 327
avg_envstep_per_episode: 109.0
avg_sample_per_episode: 109.0
avg_envstep_per_sec: 526.4168278227937
avg_train_sample_per_sec: 526.4168278227937
avg_episode_per_sec: 4.829512181860493
collect_time: 0.6211807501527613
reward_mean: 492.6666564941406
reward_std: 383.50518798828125
reward_max: 1035.0
reward_min: 217.0
total_envstep_count: 2152
total_train_sample_count: 2103
total_episode_count: 10
total_duration: 1.6703239466975044
[2022-12-21 15:15:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 471
train_sample_count: 471
avg_envstep_per_episode: 117.75
avg_sample_per_episode: 117.75
avg_envstep_per_sec: 505.9595281482294
avg_train_sample_per_sec: 505.9595281482294
avg_episode_per_sec: 4.296896205080505
collect_time: 0.9309044968948832
reward_mean: 482.75
reward_std: 258.86712646484375
reward_max: 750.0
reward_min: 217.0
total_envstep_count: 3124
total_train_sample_count: 3090
total_episode_count: 14
total_duration: 2.6012284435923876
[2022-12-21 15:15:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1456
train_sample_count: 1456
avg_envstep_per_episode: 364.0
avg_sample_per_episode: 364.0
avg_envstep_per_sec: 515.9102314652004
avg_train_sample_per_sec: 515.9102314652004
avg_episode_per_sec: 1.4173358007285726
collect_time: 2.822196403945928
reward_mean: 938.0
reward_std: 221.61904907226562
reward_max: 1285.0
reward_min: 741.0
total_envstep_count: 4121
total_train_sample_count: 4078
total_episode_count: 18
total_duration: 5.423424847538316
[2022-12-21 15:15:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 628
train_sample_count: 628
avg_envstep_per_episode: 157.0
avg_sample_per_episode: 157.0
avg_envstep_per_sec: 517.9594256408736
avg_train_sample_per_sec: 517.9594256408736
avg_episode_per_sec: 3.299104621916393
collect_time: 1.2124501822183709
reward_mean: 593.25
reward_std: 426.9252624511719
reward_max: 1275.0
reward_min: 231.0
total_envstep_count: 5093
total_train_sample_count: 5066
total_episode_count: 22
total_duration: 6.635875029756686
[2022-12-21 15:15:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1649
train_sample_count: 1649
avg_envstep_per_episode: 206.125
avg_sample_per_episode: 206.125
avg_envstep_per_sec: 515.2228746436783
avg_train_sample_per_sec: 515.2228746436783
avg_episode_per_sec: 2.4995651892961956
collect_time: 3.2005566545166064
reward_mean: 736.0
reward_std: 439.0703125
reward_max: 1287.0
reward_min: 222.0
total_envstep_count: 6102
total_train_sample_count: 6067
total_episode_count: 30
total_duration: 9.836431684273293
[2022-12-21 15:15:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 464
train_sample_count: 464
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 493.4817804708589
avg_train_sample_per_sec: 493.4817804708589
avg_episode_per_sec: 4.254153279921197
collect_time: 0.9402576110454804
reward_mean: 446.0
reward_std: 221.74197387695312
reward_max: 714.0
reward_min: 223.0
total_envstep_count: 7059
total_train_sample_count: 7035
total_episode_count: 34
total_duration: 10.776689295318773
[2022-12-21 15:15:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1269
train_sample_count: 1269
avg_envstep_per_episode: 211.5
avg_sample_per_episode: 211.5
avg_envstep_per_sec: 506.3722710594939
avg_train_sample_per_sec: 506.3722710594939
avg_episode_per_sec: 2.394195135033068
collect_time: 2.50606139499867
reward_mean: 848.5
reward_std: 477.9228515625
reward_max: 1312.0
reward_min: 223.0
total_envstep_count: 8086
total_train_sample_count: 8040
total_episode_count: 40
total_duration: 13.282750690317442
[2022-12-21 15:15:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1848
train_sample_count: 1848
avg_envstep_per_episode: 184.8
avg_sample_per_episode: 184.8
avg_envstep_per_sec: 523.2801054610239
avg_train_sample_per_sec: 523.2801054610239
avg_episode_per_sec: 2.831602302278268
collect_time: 3.5315693845686376
reward_mean: 676.0
reward_std: 402.18353271484375
reward_max: 1774.0
reward_min: 231.0
total_envstep_count: 9069
total_train_sample_count: 9024
total_episode_count: 50
total_duration: 16.81432007488608
[2022-12-21 15:15:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 429
train_sample_count: 429
avg_envstep_per_episode: 71.5
avg_sample_per_episode: 71.5
avg_envstep_per_sec: 524.9444784856004
avg_train_sample_per_sec: 524.9444784856004
avg_episode_per_sec: 7.3418808179804245
collect_time: 0.8172292834427209
reward_mean: 363.0
reward_std: 189.539794921875
reward_max: 635.0
reward_min: 223.0
total_envstep_count: 10048
total_train_sample_count: 10017
total_episode_count: 56
total_duration: 17.6315493583288
[2022-12-21 15:15:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1460
train_sample_count: 1460
avg_envstep_per_episode: 146.0
avg_sample_per_episode: 146.0
avg_envstep_per_sec: 534.7893836243442
avg_train_sample_per_sec: 534.7893836243442
avg_episode_per_sec: 3.662940983728385
collect_time: 2.730046715036434
reward_mean: 520.7999877929688
reward_std: 247.8845672607422
reward_max: 788.0
reward_min: 215.0
total_envstep_count: 11056
total_train_sample_count: 11033
total_episode_count: 66
total_duration: 20.361596073365234
[2022-12-21 15:15:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 211
train_sample_count: 211
avg_envstep_per_episode: 105.5
avg_sample_per_episode: 105.5
avg_envstep_per_sec: 509.98590373336367
avg_train_sample_per_sec: 509.98590373336367
avg_episode_per_sec: 4.833989608847049
collect_time: 0.4137369257765158
reward_mean: 481.5
reward_std: 250.5
reward_max: 732.0
reward_min: 231.0
total_envstep_count: 12014
total_train_sample_count: 12000
total_episode_count: 68
total_duration: 20.77533299914175
[2022-12-21 15:15:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 332
train_sample_count: 332
avg_envstep_per_episode: 66.4
avg_sample_per_episode: 66.4
avg_envstep_per_sec: 508.4885699011589
avg_train_sample_per_sec: 508.4885699011589
avg_episode_per_sec: 7.657960390077694
collect_time: 0.6529153645765035
reward_mean: 302.79998779296875
reward_std: 151.72659301757812
reward_max: 606.0
reward_min: 215.0
total_envstep_count: 13041
total_train_sample_count: 12992
total_episode_count: 73
total_duration: 21.428248363718254
[2022-12-21 15:15:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1122
train_sample_count: 1122
avg_envstep_per_episode: 374.0
avg_sample_per_episode: 374.0
avg_envstep_per_sec: 519.0586924191538
avg_train_sample_per_sec: 519.0586924191538
avg_episode_per_sec: 1.3878574663613736
collect_time: 2.1616052604200586
reward_mean: 959.3333129882812
reward_std: 266.1795654296875
reward_max: 1286.0
reward_min: 634.0
total_envstep_count: 14022
total_train_sample_count: 13982
total_episode_count: 76
total_duration: 23.589853624138314
[2022-12-21 15:15:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1110
train_sample_count: 1110
avg_envstep_per_episode: 185.0
avg_sample_per_episode: 185.0
avg_envstep_per_sec: 515.4364565362932
avg_train_sample_per_sec: 515.4364565362932
avg_episode_per_sec: 2.786143008304288
collect_time: 2.153514727031812
reward_mean: 717.5
reward_std: 149.04893493652344
reward_max: 1030.0
reward_min: 618.0
total_envstep_count: 15010
total_train_sample_count: 14984
total_episode_count: 82
total_duration: 25.743368351170126
[2022-12-21 15:15:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1383
train_sample_count: 1383
avg_envstep_per_episode: 276.6
avg_sample_per_episode: 276.6
avg_envstep_per_sec: 516.6727424946555
avg_train_sample_per_sec: 516.6727424946555
avg_episode_per_sec: 1.8679419468353415
collect_time: 2.6767427159452017
reward_mean: 656.7999877929688
reward_std: 400.9575500488281
reward_max: 1238.0
reward_min: 223.0
total_envstep_count: 16029
total_train_sample_count: 15995
total_episode_count: 87
total_duration: 28.42011106711533
[2022-12-21 15:15:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 843
train_sample_count: 843
avg_envstep_per_episode: 421.5
avg_sample_per_episode: 421.5
avg_envstep_per_sec: 518.4221585381737
avg_train_sample_per_sec: 518.4221585381737
avg_episode_per_sec: 1.2299458091059874
collect_time: 1.6260879017537717
reward_mean: 785.0
reward_std: 149.0
reward_max: 934.0
reward_min: 636.0
total_envstep_count: 17011
total_train_sample_count: 16958
total_episode_count: 89
total_duration: 30.0461989688691
[2022-12-21 15:15:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1172
train_sample_count: 1172
avg_envstep_per_episode: 234.4
avg_sample_per_episode: 234.4
avg_envstep_per_sec: 510.3007314473531
avg_train_sample_per_sec: 510.3007314473531
avg_episode_per_sec: 2.1770509020791513
collect_time: 2.296684930620981
reward_mean: 852.7999877929688
reward_std: 259.3425598144531
reward_max: 1288.0
reward_min: 610.0
total_envstep_count: 18031
total_train_sample_count: 17998
total_episode_count: 94
total_duration: 32.34288389949008
[2022-12-21 15:15:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 926
train_sample_count: 926
avg_envstep_per_episode: 231.5
avg_sample_per_episode: 231.5
avg_envstep_per_sec: 509.4947470645329
avg_train_sample_per_sec: 509.4947470645329
avg_episode_per_sec: 2.2008412400195807
collect_time: 1.8174868442416194
reward_mean: 576.25
reward_std: 207.064453125
reward_max: 782.0
reward_min: 231.0
total_envstep_count: 19029
total_train_sample_count: 19008
total_episode_count: 98
total_duration: 34.160370743731704
[2022-12-21 15:16:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1381
train_sample_count: 1381
avg_envstep_per_episode: 230.16666666666666
avg_sample_per_episode: 230.16666666666666
avg_envstep_per_sec: 521.3098498770497
avg_train_sample_per_sec: 521.3098498770497
avg_episode_per_sec: 2.264923315903185
collect_time: 2.6490963106216143
reward_mean: 749.0
reward_std: 329.53656005859375
reward_max: 1276.0
reward_min: 231.0
total_envstep_count: 20040
total_train_sample_count: 19993
total_episode_count: 104
total_duration: 36.80946705435332
[2022-12-21 15:16:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1334
train_sample_count: 1334
avg_envstep_per_episode: 148.22222222222223
avg_sample_per_episode: 148.22222222222223
avg_envstep_per_sec: 520.7883105413216
avg_train_sample_per_sec: 520.7883105413216
avg_episode_per_sec: 3.5135643139969224
collect_time: 2.56150142581619
reward_mean: 647.6666870117188
reward_std: 340.3224182128906
reward_max: 1114.0
reward_min: 231.0
total_envstep_count: 21018
total_train_sample_count: 20991
total_episode_count: 113
total_duration: 39.37096848016951
[2022-12-21 15:16:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 505
train_sample_count: 505
avg_envstep_per_episode: 168.33333333333334
avg_sample_per_episode: 168.33333333333334
avg_envstep_per_sec: 513.9141570907836
avg_train_sample_per_sec: 513.9141570907836
avg_episode_per_sec: 3.052955388658121
collect_time: 0.9826543850411792
reward_mean: 780.3333129882812
reward_std: 439.1858825683594
reward_max: 1306.0
reward_min: 231.0
total_envstep_count: 22007
total_train_sample_count: 21964
total_episode_count: 116
total_duration: 40.35362286521069
[2022-12-21 15:16:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 629
train_sample_count: 629
avg_envstep_per_episode: 104.83333333333333
avg_sample_per_episode: 104.83333333333333
avg_envstep_per_sec: 518.9792931983783
avg_train_sample_per_sec: 518.9792931983783
avg_episode_per_sec: 4.950517900143513
collect_time: 1.2119944056410872
reward_mean: 493.0
reward_std: 302.1870422363281
reward_max: 1036.0
reward_min: 217.0
total_envstep_count: 22993
total_train_sample_count: 22941
total_episode_count: 122
total_duration: 41.565617270851774
[2022-12-21 15:16:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1152
train_sample_count: 1152
avg_envstep_per_episode: 164.57142857142858
avg_sample_per_episode: 164.57142857142858
avg_envstep_per_sec: 510.529023187504
avg_train_sample_per_sec: 510.529023187504
avg_episode_per_sec: 3.1021728839518468
collect_time: 2.2564828788918834
reward_mean: 593.7142944335938
reward_std: 384.505126953125
reward_max: 1269.0
reward_min: 215.0
total_envstep_count: 23986
total_train_sample_count: 23949
total_episode_count: 129
total_duration: 43.822100149743655
[2022-12-21 15:16:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1210
train_sample_count: 1210
avg_envstep_per_episode: 201.66666666666666
avg_sample_per_episode: 201.66666666666666
avg_envstep_per_sec: 513.9537313739029
avg_train_sample_per_sec: 513.9537313739029
avg_episode_per_sec: 2.548530899374725
collect_time: 2.354297529400991
reward_mean: 635.0
reward_std: 223.8131561279297
reward_max: 984.0
reward_min: 231.0
total_envstep_count: 25028
total_train_sample_count: 24979
total_episode_count: 135
total_duration: 46.17639767914464
[2022-12-21 15:16:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1107
train_sample_count: 1107
avg_envstep_per_episode: 158.14285714285714
avg_sample_per_episode: 158.14285714285714
avg_envstep_per_sec: 524.6262393933765
avg_train_sample_per_sec: 524.6262393933765
avg_episode_per_sec: 3.317419761295064
collect_time: 2.1100736426756317
reward_mean: 679.8571166992188
reward_std: 263.34576416015625
reward_max: 1039.0
reward_min: 215.0
total_envstep_count: 25999
total_train_sample_count: 25966
total_episode_count: 142
total_duration: 48.28647132182027
[2022-12-21 15:16:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1370
train_sample_count: 1370
avg_envstep_per_episode: 171.25
avg_sample_per_episode: 171.25
avg_envstep_per_sec: 510.18661074999807
avg_train_sample_per_sec: 510.18661074999807
avg_episode_per_sec: 2.9791918875912295
collect_time: 2.685291952264361
reward_mean: 530.875
reward_std: 394.5245056152344
reward_max: 1448.0
reward_min: 217.0
total_envstep_count: 27008
total_train_sample_count: 26964
total_episode_count: 150
total_duration: 50.97176327408464
[2022-12-21 15:16:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 906
train_sample_count: 906
avg_envstep_per_episode: 129.42857142857142
avg_sample_per_episode: 129.42857142857142
avg_envstep_per_sec: 508.96269320928167
avg_train_sample_per_sec: 508.96269320928167
avg_episode_per_sec: 3.932382839365311
collect_time: 1.7800911777780528
reward_mean: 585.5714111328125
reward_std: 262.303466796875
reward_max: 1036.0
reward_min: 231.0
total_envstep_count: 28019
total_train_sample_count: 27966
total_episode_count: 157
total_duration: 52.75185445186269
[2022-12-21 15:16:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 330
train_sample_count: 330
avg_envstep_per_episode: 82.5
avg_sample_per_episode: 82.5
avg_envstep_per_sec: 519.40057947533
avg_train_sample_per_sec: 519.40057947533
avg_episode_per_sec: 6.29576459970097
collect_time: 0.6353477701802872
reward_mean: 447.75
reward_std: 219.12481689453125
reward_max: 710.0
reward_min: 231.0
total_envstep_count: 28983
total_train_sample_count: 28944
total_episode_count: 161
total_duration: 53.38720222204298
[2022-12-21 15:16:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 608
train_sample_count: 608
avg_envstep_per_episode: 304.0
avg_sample_per_episode: 304.0
avg_envstep_per_sec: 512.4207240057657
avg_train_sample_per_sec: 512.4207240057657
avg_episode_per_sec: 1.6855944868610715
collect_time: 1.186525000876348
reward_mean: 987.5
reward_std: 280.5
reward_max: 1268.0
reward_min: 707.0
total_envstep_count: 29942
total_train_sample_count: 29912
total_episode_count: 163
total_duration: 54.57372722291933
[2022-12-21 15:16:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1535
train_sample_count: 1535
avg_envstep_per_episode: 255.83333333333334
avg_sample_per_episode: 255.83333333333334
avg_envstep_per_sec: 519.3152476912039
avg_train_sample_per_sec: 519.3152476912039
avg_episode_per_sec: 2.0298967336464
collect_time: 2.955815387328554
reward_mean: 905.3333129882812
reward_std: 256.1917724609375
reward_max: 1293.0
reward_min: 613.0
total_envstep_count: 30946
total_train_sample_count: 30907
total_episode_count: 169
total_duration: 57.52954261024789
[2022-12-21 15:17:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1448
train_sample_count: 1448
avg_envstep_per_episode: 241.33333333333334
avg_sample_per_episode: 241.33333333333334
avg_envstep_per_sec: 515.0106403784678
avg_train_sample_per_sec: 515.0106403784678
avg_episode_per_sec: 2.1340219905185127
collect_time: 2.8115923953258575
reward_mean: 820.1666870117188
reward_std: 246.98880004882812
reward_max: 1287.0
reward_min: 610.0
total_envstep_count: 31957
total_train_sample_count: 31923
total_episode_count: 175
total_duration: 60.34113500557375
[2022-12-21 15:17:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1171
train_sample_count: 1171
avg_envstep_per_episode: 146.375
avg_sample_per_episode: 146.375
avg_envstep_per_sec: 513.2876223796361
avg_train_sample_per_sec: 513.2876223796361
avg_episode_per_sec: 3.5066618095961477
collect_time: 2.2813719812123363
reward_mean: 570.375
reward_std: 305.762939453125
reward_max: 1036.0
reward_min: 231.0
total_envstep_count: 32967
total_train_sample_count: 32926
total_episode_count: 183
total_duration: 62.622506986786085
[2022-12-21 15:17:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 963
train_sample_count: 963
avg_envstep_per_episode: 137.57142857142858
avg_sample_per_episode: 137.57142857142858
avg_envstep_per_sec: 494.5732824586517
avg_train_sample_per_sec: 494.5732824586517
avg_episode_per_sec: 3.5950290521397323
collect_time: 1.9471330825083755
reward_mean: 682.1428833007812
reward_std: 260.3823547363281
reward_max: 1039.0
reward_min: 231.0
total_envstep_count: 33969
total_train_sample_count: 33913
total_episode_count: 190
total_duration: 64.56964006929446
[2022-12-21 15:17:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 847
train_sample_count: 847
avg_envstep_per_episode: 105.875
avg_sample_per_episode: 105.875
avg_envstep_per_sec: 511.7591563252738
avg_train_sample_per_sec: 511.7591563252738
avg_episode_per_sec: 4.833616588668465
collect_time: 1.6550754188394967
reward_mean: 457.875
reward_std: 231.31712341308594
reward_max: 764.0
reward_min: 226.0
total_envstep_count: 34977
total_train_sample_count: 34940
total_episode_count: 198
total_duration: 66.22471548813397
[2022-12-21 15:17:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 629
train_sample_count: 629
avg_envstep_per_episode: 89.85714285714286
avg_sample_per_episode: 89.85714285714286
avg_envstep_per_sec: 504.4445141222055
avg_train_sample_per_sec: 504.4445141222055
avg_episode_per_sec: 5.613849918689091
collect_time: 1.2469161273257896
reward_mean: 434.8571472167969
reward_std: 372.55120849609375
reward_max: 1294.0
reward_min: 231.0
total_envstep_count: 35978
total_train_sample_count: 35941
total_episode_count: 205
total_duration: 67.47163161545976
[2022-12-21 15:17:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 979
train_sample_count: 979
avg_envstep_per_episode: 139.85714285714286
avg_sample_per_episode: 139.85714285714286
avg_envstep_per_sec: 496.71943506068584
avg_train_sample_per_sec: 496.71943506068584
avg_episode_per_sec: 3.551620066828193
collect_time: 1.9709315378013996
reward_mean: 536.2857055664062
reward_std: 361.5489501953125
reward_max: 1031.0
reward_min: 226.0
total_envstep_count: 36964
total_train_sample_count: 36932
total_episode_count: 212
total_duration: 69.44256315326116
[2022-12-21 15:17:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 852
train_sample_count: 852
avg_envstep_per_episode: 284.0
avg_sample_per_episode: 284.0
avg_envstep_per_sec: 514.5273770620639
avg_train_sample_per_sec: 514.5273770620639
avg_episode_per_sec: 1.811716116415718
collect_time: 1.6558885648901613
reward_mean: 1278.3333740234375
reward_std: 730.5286865234375
reward_max: 2310.0
reward_min: 715.0
total_envstep_count: 37945
total_train_sample_count: 37904
total_episode_count: 215
total_duration: 71.09845171815132
[2022-12-21 15:17:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1037
train_sample_count: 1037
avg_envstep_per_episode: 207.4
avg_sample_per_episode: 207.4
avg_envstep_per_sec: 513.500198806523
avg_train_sample_per_sec: 513.500198806523
avg_episode_per_sec: 2.4758929547084043
collect_time: 2.019473414830598
reward_mean: 619.7999877929688
reward_std: 346.61297607421875
reward_max: 1019.0
reward_min: 226.0
total_envstep_count: 38949
total_train_sample_count: 38905
total_episode_count: 220
total_duration: 73.11792513298192
[2022-12-21 15:17:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1305
train_sample_count: 1305
avg_envstep_per_episode: 163.125
avg_sample_per_episode: 163.125
avg_envstep_per_sec: 512.4869068233755
avg_train_sample_per_sec: 512.4869068233755
avg_episode_per_sec: 3.1416821874229917
collect_time: 2.5464065181469264
reward_mean: 606.625
reward_std: 315.3057861328125
reward_max: 1013.0
reward_min: 231.0
total_envstep_count: 39967
total_train_sample_count: 39922
total_episode_count: 228
total_duration: 75.66433165112885
[2022-12-21 15:17:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 701
train_sample_count: 701
avg_envstep_per_episode: 100.14285714285714
avg_sample_per_episode: 100.14285714285714
avg_envstep_per_sec: 502.041497432043
avg_train_sample_per_sec: 502.041497432043
avg_episode_per_sec: 5.013253184057491
collect_time: 1.396298918686275
reward_mean: 418.1428527832031
reward_std: 226.0887451171875
reward_max: 778.0
reward_min: 215.0
total_envstep_count: 40962
total_train_sample_count: 40923
total_episode_count: 235
total_duration: 77.06063056981512
[2022-12-21 15:17:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 700
train_sample_count: 700
avg_envstep_per_episode: 140.0
avg_sample_per_episode: 140.0
avg_envstep_per_sec: 490.26481146522207
avg_train_sample_per_sec: 490.26481146522207
avg_episode_per_sec: 3.501891510465872
collect_time: 1.4277998004954837
reward_mean: 483.0
reward_std: 325.42340087890625
reward_max: 1010.0
reward_min: 222.0
total_envstep_count: 41934
total_train_sample_count: 41899
total_episode_count: 240
total_duration: 78.4884303703106
[2022-12-21 15:17:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1452
train_sample_count: 1452
avg_envstep_per_episode: 207.42857142857142
avg_sample_per_episode: 207.42857142857142
avg_envstep_per_sec: 508.70555023736176
avg_train_sample_per_sec: 508.70555023736176
avg_episode_per_sec: 2.4524372256622122
collect_time: 2.8543034360889075
reward_mean: 750.1428833007812
reward_std: 305.85076904296875
reward_max: 1295.0
reward_min: 223.0
total_envstep_count: 42927
total_train_sample_count: 42883
total_episode_count: 247
total_duration: 81.34273380639951
[2022-12-21 15:17:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1389
train_sample_count: 1389
avg_envstep_per_episode: 347.25
avg_sample_per_episode: 347.25
avg_envstep_per_sec: 504.0360199450187
avg_train_sample_per_sec: 504.0360199450187
avg_episode_per_sec: 1.4515076168323073
collect_time: 2.7557554322239013
reward_mean: 697.25
reward_std: 304.85028076171875
reward_max: 1002.0
reward_min: 226.0
total_envstep_count: 43899
total_train_sample_count: 43864
total_episode_count: 251
total_duration: 84.09848923862342
[2022-12-21 15:17:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 611
train_sample_count: 611
avg_envstep_per_episode: 101.83333333333333
avg_sample_per_episode: 101.83333333333333
avg_envstep_per_sec: 506.90276690942136
avg_train_sample_per_sec: 506.90276690942136
avg_episode_per_sec: 4.97776857848859
collect_time: 1.205359370447429
reward_mean: 457.3333435058594
reward_std: 230.99110412597656
reward_max: 744.0
reward_min: 231.0
total_envstep_count: 44902
total_train_sample_count: 44871
total_episode_count: 257
total_duration: 85.30384860907084
[2022-12-21 15:17:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 849
train_sample_count: 849
avg_envstep_per_episode: 141.5
avg_sample_per_episode: 141.5
avg_envstep_per_sec: 504.57960342128695
avg_train_sample_per_sec: 504.57960342128695
avg_episode_per_sec: 3.5659335930833
collect_time: 1.6825888209578446
reward_mean: 625.0
reward_std: 441.49896240234375
reward_max: 1303.0
reward_min: 231.0
total_envstep_count: 45881
total_train_sample_count: 45852
total_episode_count: 263
total_duration: 86.98643743002869
[2022-12-21 15:17:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 903
train_sample_count: 903
avg_envstep_per_episode: 180.6
avg_sample_per_episode: 180.6
avg_envstep_per_sec: 497.78335953329804
avg_train_sample_per_sec: 497.78335953329804
avg_episode_per_sec: 2.7562755234401886
collect_time: 1.8140421585137299
reward_mean: 717.5999755859375
reward_std: 160.89450073242188
reward_max: 1019.0
reward_min: 589.0
total_envstep_count: 46868
total_train_sample_count: 46839
total_episode_count: 268
total_duration: 88.80047958854242
[2022-12-21 15:17:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1235
train_sample_count: 1235
avg_envstep_per_episode: 308.75
avg_sample_per_episode: 308.75
avg_envstep_per_sec: 499.274325311751
avg_train_sample_per_sec: 499.274325311751
avg_episode_per_sec: 1.617082835017817
collect_time: 2.4735900433671527
reward_mean: 1107.5
reward_std: 465.03790283203125
reward_max: 1791.0
reward_min: 635.0
total_envstep_count: 47856
total_train_sample_count: 47810
total_episode_count: 272
total_duration: 91.27406963190957
[2022-12-21 15:17:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1104
train_sample_count: 1104
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 510.88153897403083
avg_train_sample_per_sec: 510.88153897403083
avg_episode_per_sec: 2.776530103119733
collect_time: 2.1609706277840637
reward_mean: 707.3333129882812
reward_std: 141.83518981933594
reward_max: 1016.0
reward_min: 618.0
total_envstep_count: 48844
total_train_sample_count: 48806
total_episode_count: 278
total_duration: 93.43504025969364
[2022-12-21 15:17:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1065
train_sample_count: 1065
avg_envstep_per_episode: 177.5
avg_sample_per_episode: 177.5
avg_envstep_per_sec: 509.19664764488965
avg_train_sample_per_sec: 509.19664764488965
avg_episode_per_sec: 2.8687135078585335
collect_time: 2.0915298734305963
reward_mean: 685.6666870117188
reward_std: 271.6852722167969
reward_max: 1019.0
reward_min: 231.0
total_envstep_count: 49848
total_train_sample_count: 49811
total_episode_count: 284
total_duration: 95.52657013312424
[2022-12-21 15:18:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 914
train_sample_count: 914
avg_envstep_per_episode: 182.8
avg_sample_per_episode: 182.8
avg_envstep_per_sec: 519.8538739522495
avg_train_sample_per_sec: 519.8538739522495
avg_episode_per_sec: 2.84383957304294
collect_time: 1.7581863785128864
reward_mean: 698.2000122070312
reward_std: 340.67132568359375
reward_max: 1269.0
reward_min: 223.0
total_envstep_count: 50812
total_train_sample_count: 50785
total_episode_count: 289
total_duration: 97.28475651163713
[2022-12-21 15:18:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 611
train_sample_count: 611
avg_envstep_per_episode: 305.5
avg_sample_per_episode: 305.5
avg_envstep_per_sec: 517.1035135102866
avg_train_sample_per_sec: 517.1035135102866
avg_episode_per_sec: 1.6926465254019198
collect_time: 1.181581606074014
reward_mean: 1020.0
reward_std: 9.0
reward_max: 1029.0
reward_min: 1011.0
total_envstep_count: 51802
total_train_sample_count: 51756
total_episode_count: 291
total_duration: 98.46633811771115
[2022-12-21 15:18:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1338
train_sample_count: 1338
avg_envstep_per_episode: 267.6
avg_sample_per_episode: 267.6
avg_envstep_per_sec: 519.8642651660103
avg_train_sample_per_sec: 519.8642651660103
avg_episode_per_sec: 1.9426915738640147
collect_time: 2.5737487449204286
reward_mean: 1088.4000244140625
reward_std: 239.7169952392578
reward_max: 1394.0
reward_min: 708.0
total_envstep_count: 52781
total_train_sample_count: 52734
total_episode_count: 296
total_duration: 101.04008686263157
[2022-12-21 15:18:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1015
train_sample_count: 1015
avg_envstep_per_episode: 145.0
avg_sample_per_episode: 145.0
avg_envstep_per_sec: 524.1252219171524
avg_train_sample_per_sec: 524.1252219171524
avg_episode_per_sec: 3.6146567028769137
collect_time: 1.9365601149422251
reward_mean: 683.0
reward_std: 322.4779052734375
reward_max: 1392.0
reward_min: 231.0
total_envstep_count: 53768
total_train_sample_count: 53713
total_episode_count: 303
total_duration: 102.9766469775738
[2022-12-21 15:18:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1046
train_sample_count: 1046
avg_envstep_per_episode: 209.2
avg_sample_per_episode: 209.2
avg_envstep_per_sec: 498.8865133620398
avg_train_sample_per_sec: 498.8865133620398
avg_episode_per_sec: 2.3847347675049706
collect_time: 2.096669226335494
reward_mean: 743.2000122070312
reward_std: 359.83294677734375
reward_max: 1249.0
reward_min: 231.0
total_envstep_count: 54747
total_train_sample_count: 54711
total_episode_count: 308
total_duration: 105.07331620390929
[2022-12-21 15:18:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 345
train_sample_count: 345
avg_envstep_per_episode: 115.0
avg_sample_per_episode: 115.0
avg_envstep_per_sec: 498.4162686313814
avg_train_sample_per_sec: 498.4162686313814
avg_episode_per_sec: 4.334054509838099
collect_time: 0.6921924939315234
reward_mean: 534.0
reward_std: 226.110595703125
reward_max: 774.0
reward_min: 231.0
total_envstep_count: 55730
total_train_sample_count: 55692
total_episode_count: 311
total_duration: 105.76550869784081
[2022-12-21 15:18:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 905
train_sample_count: 905
avg_envstep_per_episode: 150.83333333333334
avg_sample_per_episode: 150.83333333333334
avg_envstep_per_sec: 519.5744764586192
avg_train_sample_per_sec: 519.5744764586192
avg_episode_per_sec: 3.444692661604105
collect_time: 1.7418099637388125
reward_mean: 650.0
reward_std: 232.1457977294922
reward_max: 1018.0
reward_min: 231.0
total_envstep_count: 56766
total_train_sample_count: 56741
total_episode_count: 317
total_duration: 107.50731866157963
[2022-12-21 15:18:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1988
train_sample_count: 1988
avg_envstep_per_episode: 248.5
avg_sample_per_episode: 248.5
avg_envstep_per_sec: 520.2499069260546
avg_train_sample_per_sec: 520.2499069260546
avg_episode_per_sec: 2.0935609936662156
collect_time: 3.821240472192075
reward_mean: 747.5
reward_std: 358.6575622558594
reward_max: 1252.0
reward_min: 223.0
total_envstep_count: 57816
total_train_sample_count: 57781
total_episode_count: 325
total_duration: 111.3285591337717
[2022-12-21 15:18:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 720
train_sample_count: 720
avg_envstep_per_episode: 180.0
avg_sample_per_episode: 180.0
avg_envstep_per_sec: 529.6103665937367
avg_train_sample_per_sec: 529.6103665937367
avg_episode_per_sec: 2.9422798144096483
collect_time: 1.359490005134871
reward_mean: 801.0
reward_std: 148.5950927734375
reward_max: 1035.0
reward_min: 635.0
total_envstep_count: 58804
total_train_sample_count: 58765
total_episode_count: 329
total_duration: 112.68804913890658
[2022-12-21 15:18:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1320
train_sample_count: 1320
avg_envstep_per_episode: 188.57142857142858
avg_sample_per_episode: 188.57142857142858
avg_envstep_per_sec: 503.7645966698436
avg_train_sample_per_sec: 503.7645966698436
avg_episode_per_sec: 2.6714789217340194
collect_time: 2.6202714695036406
reward_mean: 784.8571166992188
reward_std: 353.8944091796875
reward_max: 1385.0
reward_min: 222.0
total_envstep_count: 59775
total_train_sample_count: 59737
total_episode_count: 336
total_duration: 115.30832060841021
[2022-12-21 15:18:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 761
train_sample_count: 761
avg_envstep_per_episode: 152.2
avg_sample_per_episode: 152.2
avg_envstep_per_sec: 492.36664942073713
avg_train_sample_per_sec: 492.36664942073713
avg_episode_per_sec: 3.234997696588286
collect_time: 1.5455961546041075
reward_mean: 658.5999755859375
reward_std: 523.71044921875
reward_max: 1305.0
reward_min: 231.0
total_envstep_count: 60770
total_train_sample_count: 60750
total_episode_count: 341
total_duration: 116.85391676301433
[2022-12-21 15:18:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 109
train_sample_count: 109
avg_envstep_per_episode: 109.0
avg_sample_per_episode: 109.0
avg_envstep_per_sec: 497.40295002937427
avg_train_sample_per_sec: 497.40295002937427
avg_episode_per_sec: 4.56332981678325
collect_time: 0.21913822584599263
reward_mean: 618.0
reward_std: 0.0
reward_max: 618.0
reward_min: 618.0
total_envstep_count: 61729
total_train_sample_count: 61711
total_episode_count: 342
total_duration: 117.07305498886032
[2022-12-21 15:18:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2055
train_sample_count: 2055
avg_envstep_per_episode: 256.875
avg_sample_per_episode: 256.875
avg_envstep_per_sec: 500.75897744939556
avg_train_sample_per_sec: 500.75897744939556
avg_episode_per_sec: 1.9494266762020265
collect_time: 4.103770661221284
reward_mean: 982.5
reward_std: 354.0360107421875
reward_max: 1299.0
reward_min: 226.0
total_envstep_count: 62770
total_train_sample_count: 62734
total_episode_count: 350
total_duration: 121.17682565008161
[2022-12-21 15:18:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 674
train_sample_count: 674
avg_envstep_per_episode: 134.8
avg_sample_per_episode: 134.8
avg_envstep_per_sec: 514.3617137016171
avg_train_sample_per_sec: 514.3617137016171
avg_episode_per_sec: 3.815739715887367
collect_time: 1.3103619146719572
reward_mean: 532.7999877929688
reward_std: 258.4363708496094
reward_max: 808.0
reward_min: 222.0
total_envstep_count: 63750
total_train_sample_count: 63720
total_episode_count: 355
total_duration: 122.48718756475357
[2022-12-21 15:18:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1038
train_sample_count: 1038
avg_envstep_per_episode: 173.0
avg_sample_per_episode: 173.0
avg_envstep_per_sec: 512.6481782704814
avg_train_sample_per_sec: 512.6481782704814
avg_episode_per_sec: 2.96328426745943
collect_time: 2.0247804322681793
reward_mean: 716.3333129882812
reward_std: 273.0644836425781
reward_max: 1035.0
reward_min: 231.0
total_envstep_count: 64746
total_train_sample_count: 64710
total_episode_count: 361
total_duration: 124.51196799702174
[2022-12-21 15:18:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 829
train_sample_count: 829
avg_envstep_per_episode: 207.25
avg_sample_per_episode: 207.25
avg_envstep_per_sec: 489.4452291961876
avg_train_sample_per_sec: 489.4452291961876
avg_episode_per_sec: 2.36161751119994
collect_time: 1.693754378526604
reward_mean: 795.75
reward_std: 139.04742431640625
reward_max: 1014.0
reward_min: 627.0
total_envstep_count: 65758
total_train_sample_count: 65719
total_episode_count: 365
total_duration: 126.20572237554835
[2022-12-21 15:18:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1572
train_sample_count: 1572
avg_envstep_per_episode: 142.9090909090909
avg_sample_per_episode: 142.9090909090909
avg_envstep_per_sec: 489.5923392342337
avg_train_sample_per_sec: 489.5923392342337
avg_episode_per_sec: 3.425900592605961
collect_time: 3.210834553618116
reward_mean: 567.3636474609375
reward_std: 352.79925537109375
reward_max: 1275.0
reward_min: 226.0
total_envstep_count: 66782
total_train_sample_count: 66739
total_episode_count: 376
total_duration: 129.41655692916646
[2022-12-21 15:18:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 527
train_sample_count: 527
avg_envstep_per_episode: 105.4
avg_sample_per_episode: 105.4
avg_envstep_per_sec: 520.4918814461635
avg_train_sample_per_sec: 520.4918814461635
avg_episode_per_sec: 4.938253144650507
collect_time: 1.0125037849500247
reward_mean: 550.0
reward_std: 172.24981689453125
reward_max: 718.0
reward_min: 217.0
total_envstep_count: 67761
total_train_sample_count: 67722
total_episode_count: 381
total_duration: 130.42906071411647
[2022-12-21 15:18:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 734
train_sample_count: 734
avg_envstep_per_episode: 122.33333333333333
avg_sample_per_episode: 122.33333333333333
avg_envstep_per_sec: 515.5835407102343
avg_train_sample_per_sec: 515.5835407102343
avg_episode_per_sec: 4.214579351854776
collect_time: 1.423629619729306
reward_mean: 517.5
reward_std: 211.40383911132812
reward_max: 787.0
reward_min: 231.0
total_envstep_count: 68772
total_train_sample_count: 68732
total_episode_count: 387
total_duration: 131.85269033384577
[2022-12-21 15:18:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 732
train_sample_count: 732
avg_envstep_per_episode: 183.0
avg_sample_per_episode: 183.0
avg_envstep_per_sec: 514.1048364100272
avg_train_sample_per_sec: 514.1048364100272
avg_episode_per_sec: 2.809316045956433
collect_time: 1.4238341057273953
reward_mean: 735.25
reward_std: 381.9118957519531
reward_max: 1296.0
reward_min: 231.0
total_envstep_count: 69753
total_train_sample_count: 69716
total_episode_count: 391
total_duration: 133.27652443957317
[2022-12-21 15:19:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1674
train_sample_count: 1674
avg_envstep_per_episode: 279.0
avg_sample_per_episode: 279.0
avg_envstep_per_sec: 511.7020397504941
avg_train_sample_per_sec: 511.7020397504941
avg_episode_per_sec: 1.8340574901451403
collect_time: 3.271435073458457
reward_mean: 736.8333129882812
reward_std: 260.2021179199219
reward_max: 1011.0
reward_min: 231.0
total_envstep_count: 70749
total_train_sample_count: 70730
total_episode_count: 397
total_duration: 136.54795951303163
[2022-12-21 15:19:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1202
train_sample_count: 1202
avg_envstep_per_episode: 133.55555555555554
avg_sample_per_episode: 133.55555555555554
avg_envstep_per_sec: 522.1707860076812
avg_train_sample_per_sec: 522.1707860076812
avg_episode_per_sec: 3.909764620689792
collect_time: 2.3019288558634887
reward_mean: 554.7777709960938
reward_std: 322.0620422363281
reward_max: 1039.0
reward_min: 231.0
total_envstep_count: 71742
total_train_sample_count: 71716
total_episode_count: 406
total_duration: 138.8498883688951
[2022-12-21 15:19:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1201
train_sample_count: 1201
avg_envstep_per_episode: 133.44444444444446
avg_sample_per_episode: 133.44444444444446
avg_envstep_per_sec: 513.1698160842394
avg_train_sample_per_sec: 513.1698160842394
avg_episode_per_sec: 3.845568979815283
collect_time: 2.3403558867983962
reward_mean: 560.4444580078125
reward_std: 346.10791015625
reward_max: 1292.0
reward_min: 226.0
total_envstep_count: 72775
total_train_sample_count: 72737
total_episode_count: 415
total_duration: 141.1902442556935
[2022-12-21 15:19:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 796
train_sample_count: 796
avg_envstep_per_episode: 159.2
avg_sample_per_episode: 159.2
avg_envstep_per_sec: 514.1789632694469
avg_train_sample_per_sec: 514.1789632694469
avg_episode_per_sec: 3.229767357220143
collect_time: 1.548099118910996
reward_mean: 794.0
reward_std: 268.0753479003906
reward_max: 1309.0
reward_min: 599.0
total_envstep_count: 73771
total_train_sample_count: 73725
total_episode_count: 420
total_duration: 142.73834337460448
[2022-12-21 15:19:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 767
train_sample_count: 767
avg_envstep_per_episode: 153.4
avg_sample_per_episode: 153.4
avg_envstep_per_sec: 519.1592415480462
avg_train_sample_per_sec: 519.1592415480462
avg_episode_per_sec: 3.384349684146325
collect_time: 1.477388705848583
reward_mean: 849.7999877929688
reward_std: 378.6626281738281
reward_max: 1308.0
reward_min: 231.0
total_envstep_count: 74728
total_train_sample_count: 74696
total_episode_count: 425
total_duration: 144.21573208045308
[2022-12-21 15:19:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1042
train_sample_count: 1042
avg_envstep_per_episode: 115.77777777777777
avg_sample_per_episode: 115.77777777777777
avg_envstep_per_sec: 501.57873881636664
avg_train_sample_per_sec: 501.57873881636664
avg_episode_per_sec: 4.332253982099136
collect_time: 2.077440527999508
reward_mean: 570.7777709960938
reward_std: 225.37118530273438
reward_max: 1037.0
reward_min: 231.0
total_envstep_count: 75751
total_train_sample_count: 75714
total_episode_count: 434
total_duration: 146.29317260845258
[2022-12-21 15:19:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 902
train_sample_count: 902
avg_envstep_per_episode: 225.5
avg_sample_per_episode: 225.5
avg_envstep_per_sec: 513.2170570060525
avg_train_sample_per_sec: 513.2170570060525
avg_episode_per_sec: 2.27590712641265
collect_time: 1.757540961833937
reward_mean: 766.25
reward_std: 137.2340545654297
reward_max: 997.0
reward_min: 636.0
total_envstep_count: 76733
total_train_sample_count: 76712
total_episode_count: 438
total_duration: 148.05071357028652
[2022-12-21 15:19:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1002
train_sample_count: 1002
avg_envstep_per_episode: 167.0
avg_sample_per_episode: 167.0
avg_envstep_per_sec: 522.5625253486228
avg_train_sample_per_sec: 522.5625253486228
avg_episode_per_sec: 3.1291169182552263
collect_time: 1.9174738933518527
reward_mean: 831.8333129882812
reward_std: 264.8001708984375
reward_max: 1312.0
reward_min: 606.0
total_envstep_count: 77768
total_train_sample_count: 77714
total_episode_count: 444
total_duration: 149.96818746363837
[2022-12-21 15:19:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 842
train_sample_count: 842
avg_envstep_per_episode: 168.4
avg_sample_per_episode: 168.4
avg_envstep_per_sec: 507.33156518605443
avg_train_sample_per_sec: 507.33156518605443
avg_episode_per_sec: 3.012657750511012
collect_time: 1.659664128509749
reward_mean: 824.7999877929688
reward_std: 291.9845275878906
reward_max: 1310.0
reward_min: 590.0
total_envstep_count: 78739
total_train_sample_count: 78700
total_episode_count: 449
total_duration: 151.62785159214812
[2022-12-21 15:20:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 913
train_sample_count: 913
avg_envstep_per_episode: 228.25
avg_sample_per_episode: 228.25
avg_envstep_per_sec: 513.9001933445893
avg_train_sample_per_sec: 513.9001933445893
avg_episode_per_sec: 2.2514794889138634
collect_time: 1.7766095670405777
reward_mean: 710.5
reward_std: 317.5039367675781
reward_max: 1027.0
reward_min: 231.0
total_envstep_count: 79727
total_train_sample_count: 79685
total_episode_count: 453
total_duration: 153.40446115918868
[2022-12-21 15:20:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1481
train_sample_count: 1481
avg_envstep_per_episode: 211.57142857142858
avg_sample_per_episode: 211.57142857142858
avg_envstep_per_sec: 509.87697964718717
avg_train_sample_per_sec: 509.87697964718717
avg_episode_per_sec: 2.409951963221006
collect_time: 2.9046222110768523
reward_mean: 809.8571166992188
reward_std: 283.8779602050781
reward_max: 1032.0
reward_min: 231.0
total_envstep_count: 80722
total_train_sample_count: 80674
total_episode_count: 460
total_duration: 156.30908337026554
[2022-12-21 15:20:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 907
train_sample_count: 907
avg_envstep_per_episode: 129.57142857142858
avg_sample_per_episode: 129.57142857142858
avg_envstep_per_sec: 499.40650543756556
avg_train_sample_per_sec: 499.40650543756556
avg_episode_per_sec: 3.854294970300947
collect_time: 1.8161557571327847
reward_mean: 654.5714111328125
reward_std: 310.5262145996094
reward_max: 1039.0
reward_min: 231.0
total_envstep_count: 81709
total_train_sample_count: 81677
total_episode_count: 467
total_duration: 158.12523912739832
[2022-12-21 15:20:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 898
train_sample_count: 898
avg_envstep_per_episode: 179.6
avg_sample_per_episode: 179.6
avg_envstep_per_sec: 490.03429180883455
avg_train_sample_per_sec: 490.03429180883455
avg_episode_per_sec: 2.7284760122986333
collect_time: 1.8325248151211333
reward_mean: 812.2000122070312
reward_std: 178.7471923828125
reward_max: 1032.0
reward_min: 626.0
total_envstep_count: 82680
total_train_sample_count: 82659
total_episode_count: 472
total_duration: 159.95776394251945
[2022-12-21 15:20:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 412
train_sample_count: 412
avg_envstep_per_episode: 137.33333333333334
avg_sample_per_episode: 137.33333333333334
avg_envstep_per_sec: 487.9518889740261
avg_train_sample_per_sec: 487.9518889740261
avg_episode_per_sec: 3.5530477352477625
collect_time: 0.844345537561657
reward_mean: 720.6666870117188
reward_std: 443.5390319824219
reward_max: 1305.0
reward_min: 231.0
total_envstep_count: 83661
total_train_sample_count: 83623
total_episode_count: 475
total_duration: 160.8021094800811
[2022-12-21 15:20:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1720
train_sample_count: 1720
avg_envstep_per_episode: 191.11111111111111
avg_sample_per_episode: 191.11111111111111
avg_envstep_per_sec: 495.7238552385387
avg_train_sample_per_sec: 495.7238552385387
avg_episode_per_sec: 2.593903893690028
collect_time: 3.4696736536359514
reward_mean: 808.2222290039062
reward_std: 357.21942138671875
reward_max: 1293.0
reward_min: 222.0
total_envstep_count: 84700
total_train_sample_count: 84659
total_episode_count: 484
total_duration: 164.27178313371707
[2022-12-21 15:20:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 277
train_sample_count: 277
avg_envstep_per_episode: 138.5
avg_sample_per_episode: 138.5
avg_envstep_per_sec: 507.48145624872797
avg_train_sample_per_sec: 507.48145624872797
avg_episode_per_sec: 3.6641260378969527
collect_time: 0.5458327522892504
reward_mean: 611.5
reward_std: 23.5
reward_max: 635.0
reward_min: 588.0
total_envstep_count: 85658
total_train_sample_count: 85632
total_episode_count: 486
total_duration: 164.8176158860063
[2022-12-21 15:20:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1971
train_sample_count: 1971
avg_envstep_per_episode: 246.375
avg_sample_per_episode: 246.375
avg_envstep_per_sec: 492.81124331996847
avg_train_sample_per_sec: 492.81124331996847
avg_episode_per_sec: 2.000248577655884
collect_time: 3.999502906471404
reward_mean: 993.25
reward_std: 273.6424560546875
reward_max: 1319.0
reward_min: 605.0
total_envstep_count: 86699
total_train_sample_count: 86643
total_episode_count: 494
total_duration: 168.81711879247771
[2022-12-21 15:20:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 206
train_sample_count: 206
avg_envstep_per_episode: 103.0
avg_sample_per_episode: 103.0
avg_envstep_per_sec: 494.17779915293204
avg_train_sample_per_sec: 494.17779915293204
avg_episode_per_sec: 4.797842710222641
collect_time: 0.4168540156055243
reward_mean: 620.5
reward_std: 5.5
reward_max: 626.0
reward_min: 615.0
total_envstep_count: 87657
total_train_sample_count: 87605
total_episode_count: 496
total_duration: 169.23397280808325
[2022-12-21 15:20:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1415
train_sample_count: 1415
avg_envstep_per_episode: 235.83333333333334
avg_sample_per_episode: 235.83333333333334
avg_envstep_per_sec: 491.208380110355
avg_train_sample_per_sec: 491.208380110355
avg_episode_per_sec: 2.082862389160516
collect_time: 2.880651180425924
reward_mean: 937.6666870117188
reward_std: 333.6133728027344
reward_max: 1290.0
reward_min: 223.0
total_envstep_count: 88659
total_train_sample_count: 88624
total_episode_count: 502
total_duration: 172.11462398850918
[2022-12-21 15:20:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 731
train_sample_count: 731
avg_envstep_per_episode: 182.75
avg_sample_per_episode: 182.75
avg_envstep_per_sec: 500.93550559407055
avg_train_sample_per_sec: 500.93550559407055
avg_episode_per_sec: 2.7410971578334915
collect_time: 1.4592696900833388
reward_mean: 776.25
reward_std: 287.6946105957031
reward_max: 1274.0
reward_min: 590.0
total_envstep_count: 89631
total_train_sample_count: 89607
total_episode_count: 506
total_duration: 173.57389367859253
[2022-12-21 15:20:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1065
train_sample_count: 1065
avg_envstep_per_episode: 177.5
avg_sample_per_episode: 177.5
avg_envstep_per_sec: 498.2031714320208
avg_train_sample_per_sec: 498.2031714320208
avg_episode_per_sec: 2.8067784306029337
collect_time: 2.137682096520572
reward_mean: 771.1666870117188
reward_std: 327.96563720703125
reward_max: 1284.0
reward_min: 231.0
total_envstep_count: 90650
total_train_sample_count: 90600
total_episode_count: 512
total_duration: 175.7115757751131
[2022-12-21 15:20:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1244
train_sample_count: 1244
avg_envstep_per_episode: 248.8
avg_sample_per_episode: 248.8
avg_envstep_per_sec: 503.84208080455613
avg_train_sample_per_sec: 503.84208080455613
avg_episode_per_sec: 2.025088749214454
collect_time: 2.4690275929583505
reward_mean: 848.0
reward_std: 152.34828186035156
reward_max: 1021.0
reward_min: 620.0
total_envstep_count: 91655
total_train_sample_count: 91616
total_episode_count: 517
total_duration: 178.18060336807144
[2022-12-21 15:20:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 772
train_sample_count: 772
avg_envstep_per_episode: 154.4
avg_sample_per_episode: 154.4
avg_envstep_per_sec: 513.3443112425858
avg_train_sample_per_sec: 513.3443112425858
avg_episode_per_sec: 3.3247688551980943
collect_time: 1.5038639429573497
reward_mean: 648.0
reward_std: 266.35992431640625
reward_max: 1025.0
reward_min: 215.0
total_envstep_count: 92644
total_train_sample_count: 92616
total_episode_count: 522
total_duration: 179.68446731102878
[2022-12-21 15:20:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1133
train_sample_count: 1133
avg_envstep_per_episode: 188.83333333333334
avg_sample_per_episode: 188.83333333333334
avg_envstep_per_sec: 518.29431445165
avg_train_sample_per_sec: 518.29431445165
avg_episode_per_sec: 2.74471834661068
collect_time: 2.186016648086719
reward_mean: 747.1666870117188
reward_std: 336.10040283203125
reward_max: 1290.0
reward_min: 231.0
total_envstep_count: 93663
total_train_sample_count: 93629
total_episode_count: 528
total_duration: 181.8704839591155
[2022-12-21 15:20:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 739
train_sample_count: 739
avg_envstep_per_episode: 184.75
avg_sample_per_episode: 184.75
avg_envstep_per_sec: 519.6445798678293
avg_train_sample_per_sec: 519.6445798678293
avg_episode_per_sec: 2.8126905540883858
collect_time: 1.4221258695471497
reward_mean: 726.5
reward_std: 328.519775390625
reward_max: 1029.0
reward_min: 231.0
total_envstep_count: 94644
total_train_sample_count: 94596
total_episode_count: 532
total_duration: 183.29260982866265
[2022-12-21 15:20:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1325
train_sample_count: 1325
avg_envstep_per_episode: 189.28571428571428
avg_sample_per_episode: 189.28571428571428
avg_envstep_per_sec: 506.6560764238498
avg_train_sample_per_sec: 506.6560764238498
avg_episode_per_sec: 2.6766736112958105
collect_time: 2.615186241034152
reward_mean: 783.2857055664062
reward_std: 329.82232666015625
reward_max: 1307.0
reward_min: 231.0
total_envstep_count: 95621
total_train_sample_count: 95597
total_episode_count: 539
total_duration: 185.90779606969681
[2022-12-21 15:20:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1048
train_sample_count: 1048
avg_envstep_per_episode: 149.71428571428572
avg_sample_per_episode: 149.71428571428572
avg_envstep_per_sec: 502.5151450508346
avg_train_sample_per_sec: 502.5151450508346
avg_episode_per_sec: 3.3564942894616814
collect_time: 2.0855092832953006
reward_mean: 650.8571166992188
reward_std: 306.9003601074219
reward_max: 1034.0
reward_min: 231.0
total_envstep_count: 96647
total_train_sample_count: 96597
total_episode_count: 546
total_duration: 187.9933053529921
[2022-12-21 15:20:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1070
train_sample_count: 1070
avg_envstep_per_episode: 133.75
avg_sample_per_episode: 133.75
avg_envstep_per_sec: 502.49936114550223
avg_train_sample_per_sec: 502.49936114550223
avg_episode_per_sec: 3.757004569312166
collect_time: 2.129355940992279
reward_mean: 550.875
reward_std: 340.32611083984375
reward_max: 1032.0
reward_min: 231.0
total_envstep_count: 97642
total_train_sample_count: 97607
total_episode_count: 554
total_duration: 190.12266129398438
[2022-12-21 15:20:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 643
train_sample_count: 643
avg_envstep_per_episode: 128.6
avg_sample_per_episode: 128.6
avg_envstep_per_sec: 509.3067309190124
avg_train_sample_per_sec: 509.3067309190124
avg_episode_per_sec: 3.960394486150952
collect_time: 1.2625004952118861
reward_mean: 659.7999877929688
reward_std: 263.7691345214844
reward_max: 1033.0
reward_min: 231.0
total_envstep_count: 98638
total_train_sample_count: 98598
total_episode_count: 559
total_duration: 191.38516178919627
[2022-12-21 15:21:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 582
train_sample_count: 582
avg_envstep_per_episode: 194.0
avg_sample_per_episode: 194.0
avg_envstep_per_sec: 510.2723643544503
avg_train_sample_per_sec: 510.2723643544503
avg_episode_per_sec: 2.6302699193528367
collect_time: 1.1405673531551976
reward_mean: 841.6666870117188
reward_std: 325.3401794433594
reward_max: 1301.0
reward_min: 589.0
total_envstep_count: 99619
total_train_sample_count: 99576
total_episode_count: 562
total_duration: 192.52572914235148
[2022-12-21 15:21:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1251
train_sample_count: 1251
avg_envstep_per_episode: 250.2
avg_sample_per_episode: 250.2
avg_envstep_per_sec: 506.5231188903546
avg_train_sample_per_sec: 506.5231188903546
avg_episode_per_sec: 2.0244728972436237
collect_time: 2.469778680074028
reward_mean: 1028.0
reward_std: 239.60467529296875
reward_max: 1301.0
reward_min: 736.0
total_envstep_count: 100591
total_train_sample_count: 100563
total_episode_count: 567
total_duration: 194.9955078224255
[2022-12-21 15:21:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 591
train_sample_count: 591
avg_envstep_per_episode: 118.2
avg_sample_per_episode: 118.2
avg_envstep_per_sec: 505.15217314666853
avg_train_sample_per_sec: 505.15217314666853
avg_episode_per_sec: 4.273707048618177
collect_time: 1.1699444868633793
reward_mean: 618.5999755859375
reward_std: 255.55946350097656
reward_max: 1038.0
reward_min: 231.0
total_envstep_count: 101587
total_train_sample_count: 101550
total_episode_count: 572
total_duration: 196.1654523092889
[2022-12-21 15:21:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1823
train_sample_count: 1823
avg_envstep_per_episode: 303.8333333333333
avg_sample_per_episode: 303.8333333333333
avg_envstep_per_sec: 510.2043314219375
avg_train_sample_per_sec: 510.2043314219375
avg_episode_per_sec: 1.679224349167101
collect_time: 3.573078250667347
reward_mean: 1161.8333740234375
reward_std: 886.7022094726562
reward_max: 2955.0
reward_min: 231.0
total_envstep_count: 102567
total_train_sample_count: 102533
total_episode_count: 578
total_duration: 199.73853055995625
[2022-12-21 15:21:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1063
train_sample_count: 1063
avg_envstep_per_episode: 132.875
avg_sample_per_episode: 132.875
avg_envstep_per_sec: 497.00184067132574
avg_train_sample_per_sec: 497.00184067132574
avg_episode_per_sec: 3.740371331486929
collect_time: 2.138825076712295
reward_mean: 617.75
reward_std: 281.3599853515625
reward_max: 1027.0
reward_min: 223.0
total_envstep_count: 103575
total_train_sample_count: 103524
total_episode_count: 586
total_duration: 201.87735563666854
[2022-12-21 15:21:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 827
train_sample_count: 827
avg_envstep_per_episode: 103.375
avg_sample_per_episode: 103.375
avg_envstep_per_sec: 507.9736857904661
avg_train_sample_per_sec: 507.9736857904661
avg_episode_per_sec: 4.913892970161704
collect_time: 1.628037087616245
reward_mean: 556.25
reward_std: 331.1373291015625
reward_max: 1295.0
reward_min: 231.0
total_envstep_count: 104567
total_train_sample_count: 104531
total_episode_count: 594
total_duration: 203.50539272428477
[2022-12-21 15:21:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1421
train_sample_count: 1421
avg_envstep_per_episode: 177.625
avg_sample_per_episode: 177.625
avg_envstep_per_sec: 521.4082749228415
avg_train_sample_per_sec: 521.4082749228415
avg_episode_per_sec: 2.9354441937950266
collect_time: 2.725311561674545
reward_mean: 790.875
reward_std: 354.5752258300781
reward_max: 1308.0
reward_min: 231.0
total_envstep_count: 105552
total_train_sample_count: 105520
total_episode_count: 602
total_duration: 206.23070428595932
[2022-12-21 15:21:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 629
train_sample_count: 629
avg_envstep_per_episode: 89.85714285714286
avg_sample_per_episode: 89.85714285714286
avg_envstep_per_sec: 524.9027232303692
avg_train_sample_per_sec: 524.9027232303692
avg_episode_per_sec: 5.841524741832408
collect_time: 1.1983172732063434
reward_mean: 453.71429443359375
reward_std: 288.60784912109375
reward_max: 1033.0
reward_min: 231.0
total_envstep_count: 106564
total_train_sample_count: 106533
total_episode_count: 609
total_duration: 207.42902155916568
[2022-12-21 15:21:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 968
train_sample_count: 968
avg_envstep_per_episode: 193.6
avg_sample_per_episode: 193.6
avg_envstep_per_sec: 518.9080415421095
avg_train_sample_per_sec: 518.9080415421095
avg_episode_per_sec: 2.6803101319323837
collect_time: 1.8654557696258915
reward_mean: 767.5999755859375
reward_std: 367.0311279296875
reward_max: 1297.0
reward_min: 231.0
total_envstep_count: 107559
total_train_sample_count: 107525
total_episode_count: 614
total_duration: 209.29447732879157
[2022-12-21 15:21:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1298
train_sample_count: 1298
avg_envstep_per_episode: 129.8
avg_sample_per_episode: 129.8
avg_envstep_per_sec: 506.60649909295364
avg_train_sample_per_sec: 506.60649909295364
avg_episode_per_sec: 3.9029776509472547
collect_time: 2.562146364730783
reward_mean: 645.9000244140625
reward_std: 292.0792541503906
reward_max: 1322.0
reward_min: 222.0
total_envstep_count: 108638
total_train_sample_count: 108595
total_episode_count: 624
total_duration: 211.85662369352235
[2022-12-21 15:21:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 152
train_sample_count: 152
avg_envstep_per_episode: 76.0
avg_sample_per_episode: 76.0
avg_envstep_per_sec: 500.35880259150355
avg_train_sample_per_sec: 500.35880259150355
avg_episode_per_sec: 6.583668455151362
collect_time: 0.30378200445909587
reward_mean: 417.0
reward_std: 194.0
reward_max: 611.0
reward_min: 223.0
total_envstep_count: 109604
total_train_sample_count: 109563
total_episode_count: 626
total_duration: 212.16040569798145
[2022-12-21 15:21:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1222
train_sample_count: 1222
avg_envstep_per_episode: 244.4
avg_sample_per_episode: 244.4
avg_envstep_per_sec: 503.68014644257147
avg_train_sample_per_sec: 503.68014644257147
avg_episode_per_sec: 2.060884396246201
collect_time: 2.4261428778379095
reward_mean: 1074.199951171875
reward_std: 275.8437194824219
reward_max: 1402.0
reward_min: 606.0
total_envstep_count: 110583
total_train_sample_count: 110545
total_episode_count: 631
total_duration: 214.58654857581936
[2022-12-21 15:21:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 744
train_sample_count: 744
avg_envstep_per_episode: 148.8
avg_sample_per_episode: 148.8
avg_envstep_per_sec: 503.86739015725686
avg_train_sample_per_sec: 503.86739015725686
avg_episode_per_sec: 3.386205579013823
collect_time: 1.4765789859268286
reward_mean: 658.4000244140625
reward_std: 263.1596984863281
reward_max: 1036.0
reward_min: 231.0
total_envstep_count: 111578
total_train_sample_count: 111541
total_episode_count: 636
total_duration: 216.0631275617462
[2022-12-21 15:21:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1393
train_sample_count: 1393
avg_envstep_per_episode: 278.6
avg_sample_per_episode: 278.6
avg_envstep_per_sec: 503.0250484336988
avg_train_sample_per_sec: 503.0250484336988
avg_episode_per_sec: 1.8055457589149275
collect_time: 2.769245794692477
reward_mean: 917.4000244140625
reward_std: 384.7017822265625
reward_max: 1293.0
reward_min: 231.0
total_envstep_count: 112535
total_train_sample_count: 112514
total_episode_count: 641
total_duration: 218.83237335643867
[2022-12-21 15:21:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 630
train_sample_count: 630
avg_envstep_per_episode: 157.5
avg_sample_per_episode: 157.5
avg_envstep_per_sec: 513.2317985042973
avg_train_sample_per_sec: 513.2317985042973
avg_episode_per_sec: 3.258614593678078
collect_time: 1.2275155238549098
reward_mean: 836.5
reward_std: 349.6551818847656
reward_max: 1045.0
reward_min: 231.0
total_envstep_count: 113572
total_train_sample_count: 113552
total_episode_count: 645
total_duration: 220.05988888029358
[2022-12-21 15:21:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1391
train_sample_count: 1391
avg_envstep_per_episode: 231.83333333333334
avg_sample_per_episode: 231.83333333333334
avg_envstep_per_sec: 515.3260235759412
avg_train_sample_per_sec: 515.3260235759412
avg_episode_per_sec: 2.2228297206726437
collect_time: 2.699262091108067
reward_mean: 813.1666870117188
reward_std: 204.9613037109375
reward_max: 1034.0
reward_min: 590.0
total_envstep_count: 114598
total_train_sample_count: 114547
total_episode_count: 651
total_duration: 222.75915097140165
[2022-12-21 15:21:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 978
train_sample_count: 978
avg_envstep_per_episode: 195.6
avg_sample_per_episode: 195.6
avg_envstep_per_sec: 504.1720227098878
avg_train_sample_per_sec: 504.1720227098878
avg_episode_per_sec: 2.5775665782714103
collect_time: 1.9398141030184923
reward_mean: 830.2000122070312
reward_std: 358.0035705566406
reward_max: 1324.0
reward_min: 231.0
total_envstep_count: 115577
total_train_sample_count: 115525
total_episode_count: 656
total_duration: 224.69896507442016
[2022-12-21 15:21:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 799
train_sample_count: 799
avg_envstep_per_episode: 133.16666666666666
avg_sample_per_episode: 133.16666666666666
avg_envstep_per_sec: 488.57188232197336
avg_train_sample_per_sec: 488.57188232197336
avg_episode_per_sec: 3.6688752114290866
collect_time: 1.6353785981352313
reward_mean: 603.0
reward_std: 356.4870300292969
reward_max: 1299.0
reward_min: 231.0
total_envstep_count: 116548
total_train_sample_count: 116516
total_episode_count: 662
total_duration: 226.33434367255538
[2022-12-21 15:21:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1119
train_sample_count: 1119
avg_envstep_per_episode: 186.5
avg_sample_per_episode: 186.5
avg_envstep_per_sec: 502.0679963813116
avg_train_sample_per_sec: 502.0679963813116
avg_episode_per_sec: 2.6920535998997943
collect_time: 2.2287817747103316
reward_mean: 668.1666870117188
reward_std: 448.7577209472656
reward_max: 1308.0
reward_min: 231.0
total_envstep_count: 117534
total_train_sample_count: 117503
total_episode_count: 668
total_duration: 228.56312544726572
[2022-12-21 15:22:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1511
train_sample_count: 1511
avg_envstep_per_episode: 188.875
avg_sample_per_episode: 188.875
avg_envstep_per_sec: 520.1639734786872
avg_train_sample_per_sec: 520.1639734786872
avg_episode_per_sec: 2.754011772223361
collect_time: 2.9048532329044705
reward_mean: 813.375
reward_std: 328.0110168457031
reward_max: 1321.0
reward_min: 231.0
total_envstep_count: 118543
total_train_sample_count: 118498
total_episode_count: 676
total_duration: 231.46797868017018
[2022-12-21 15:22:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 836
train_sample_count: 836
avg_envstep_per_episode: 167.2
avg_sample_per_episode: 167.2
avg_envstep_per_sec: 504.02899640687565
avg_train_sample_per_sec: 504.02899640687565
avg_episode_per_sec: 3.0145274904717443
collect_time: 1.6586347332389224
reward_mean: 769.2000122070312
reward_std: 269.25482177734375
reward_max: 1302.0
reward_min: 588.0
total_envstep_count: 119547
total_train_sample_count: 119490
total_episode_count: 681
total_duration: 233.1266134134091
[2022-12-21 15:22:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 851
train_sample_count: 851
avg_envstep_per_episode: 106.375
avg_sample_per_episode: 106.375
avg_envstep_per_sec: 505.5062429720053
avg_train_sample_per_sec: 505.5062429720053
avg_episode_per_sec: 4.7521150925687925
collect_time: 1.6834609103870712
reward_mean: 541.125
reward_std: 339.5097351074219
reward_max: 1037.0
reward_min: 223.0
total_envstep_count: 120500
total_train_sample_count: 120473
total_episode_count: 689
total_duration: 234.8100743237962
[2022-12-21 15:22:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1346
train_sample_count: 1346
avg_envstep_per_episode: 149.55555555555554
avg_sample_per_episode: 149.55555555555554
avg_envstep_per_sec: 504.7495866950985
avg_train_sample_per_sec: 504.7495866950985
avg_episode_per_sec: 3.374997236445681
collect_time: 2.666668850217546
reward_mean: 647.0
reward_std: 382.2541198730469
reward_max: 1041.0
reward_min: 215.0
total_envstep_count: 121491
total_train_sample_count: 121447
total_episode_count: 698
total_duration: 237.47674317401373
[2022-12-21 15:22:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 842
train_sample_count: 842
avg_envstep_per_episode: 105.25
avg_sample_per_episode: 105.25
avg_envstep_per_sec: 502.3234761049993
avg_train_sample_per_sec: 502.3234761049993
avg_episode_per_sec: 4.772669606698331
collect_time: 1.676210728849151
reward_mean: 539.0
reward_std: 182.51026916503906
reward_max: 745.0
reward_min: 231.0
total_envstep_count: 122486
total_train_sample_count: 122445
total_episode_count: 706
total_duration: 239.1529539028629
[2022-12-21 15:22:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 469
train_sample_count: 469
avg_envstep_per_episode: 117.25
avg_sample_per_episode: 117.25
avg_envstep_per_sec: 524.2615484165356
avg_train_sample_per_sec: 524.2615484165356
avg_episode_per_sec: 4.471313845770026
collect_time: 0.8945916430769223
reward_mean: 622.0
reward_std: 283.9242858886719
reward_max: 1033.0
reward_min: 231.0
total_envstep_count: 123466
total_train_sample_count: 123430
total_episode_count: 710
total_duration: 240.0475455459398
[2022-12-21 15:22:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 755
train_sample_count: 755
avg_envstep_per_episode: 151.0
avg_sample_per_episode: 151.0
avg_envstep_per_sec: 517.7312089226072
avg_train_sample_per_sec: 517.7312089226072
avg_episode_per_sec: 3.4286835027987226
collect_time: 1.4582856644302873
reward_mean: 747.4000244140625
reward_std: 348.5728454589844
reward_max: 1312.0
reward_min: 231.0
total_envstep_count: 124455
total_train_sample_count: 124425
total_episode_count: 715
total_duration: 241.5058312103701
[2022-12-21 15:22:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1526
train_sample_count: 1526
avg_envstep_per_episode: 254.33333333333334
avg_sample_per_episode: 254.33333333333334
avg_envstep_per_sec: 510.10096382792176
avg_train_sample_per_sec: 510.10096382792176
avg_episode_per_sec: 2.005639438379771
collect_time: 2.991564627811178
reward_mean: 994.5
reward_std: 490.0812072753906
reward_max: 1874.0
reward_min: 231.0
total_envstep_count: 125481
total_train_sample_count: 125435
total_episode_count: 721
total_duration: 244.4973958381813
[2022-12-21 15:22:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 983
train_sample_count: 983
avg_envstep_per_episode: 196.6
avg_sample_per_episode: 196.6
avg_envstep_per_sec: 495.76950738595247
avg_train_sample_per_sec: 495.76950738595247
avg_episode_per_sec: 2.5217167211899922
collect_time: 1.9827762404813305
reward_mean: 1022.5999755859375
reward_std: 511.1127624511719
reward_max: 1893.0
reward_min: 627.0
total_envstep_count: 126436
total_train_sample_count: 126418
total_episode_count: 726
total_duration: 246.48017207866263
[2022-12-21 15:22:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 258
train_sample_count: 258
avg_envstep_per_episode: 129.0
avg_sample_per_episode: 129.0
avg_envstep_per_sec: 493.6988046430869
avg_train_sample_per_sec: 493.6988046430869
avg_episode_per_sec: 3.8271225166130765
collect_time: 0.5225858308215223
reward_mean: 635.0
reward_std: 404.0
reward_max: 1039.0
reward_min: 231.0
total_envstep_count: 127418
total_train_sample_count: 127384
total_episode_count: 728
total_duration: 247.00275790948416
[2022-12-21 15:22:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 2060
train_sample_count: 2060
avg_envstep_per_episode: 187.27272727272728
avg_sample_per_episode: 187.27272727272728
avg_envstep_per_sec: 495.65661202661425
avg_train_sample_per_sec: 495.65661202661425
avg_episode_per_sec: 2.6467100642197847
collect_time: 4.156103136760715
reward_mean: 809.0908813476562
reward_std: 354.3961486816406
reward_max: 1316.0
reward_min: 223.0
total_envstep_count: 128426
total_train_sample_count: 128400
total_episode_count: 739
total_duration: 251.15886104624488
[2022-12-21 15:22:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 585
train_sample_count: 585
avg_envstep_per_episode: 83.57142857142857
avg_sample_per_episode: 83.57142857142857
avg_envstep_per_sec: 490.1988198888191
avg_train_sample_per_sec: 490.1988198888191
avg_episode_per_sec: 5.865626904652537
collect_time: 1.1933933258604794
reward_mean: 454.5714416503906
reward_std: 292.35882568359375
reward_max: 1042.0
reward_min: 223.0
total_envstep_count: 129468
total_train_sample_count: 129453
total_episode_count: 746
total_duration: 252.35225437210536
[2022-12-21 15:22:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1134
train_sample_count: 1134
avg_envstep_per_episode: 189.0
avg_sample_per_episode: 189.0
avg_envstep_per_sec: 503.43911070889334
avg_train_sample_per_sec: 503.43911070889334
avg_episode_per_sec: 2.663698998459753
collect_time: 2.2525067597613004
reward_mean: 708.0
reward_std: 353.93878173828125
reward_max: 1027.0
reward_min: 231.0
total_envstep_count: 130471
total_train_sample_count: 130431
total_episode_count: 752
total_duration: 254.60476113186667
[2022-12-21 15:22:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1286
train_sample_count: 1286
avg_envstep_per_episode: 128.6
avg_sample_per_episode: 128.6
avg_envstep_per_sec: 508.0597241835113
avg_train_sample_per_sec: 508.0597241835113
avg_episode_per_sec: 3.950697699716262
collect_time: 2.531198476845798
reward_mean: 614.7000122070312
reward_std: 438.7040100097656
reward_max: 1319.0
reward_min: 215.0
total_envstep_count: 131448
total_train_sample_count: 131417
total_episode_count: 762
total_duration: 257.1359596087125
[2022-12-21 15:22:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 813
train_sample_count: 813
avg_envstep_per_episode: 90.33333333333333
avg_sample_per_episode: 90.33333333333333
avg_envstep_per_sec: 498.4367089854658
avg_train_sample_per_sec: 498.4367089854658
avg_episode_per_sec: 5.517749545964566
collect_time: 1.631099767219807
reward_mean: 449.77777099609375
reward_std: 273.56768798828125
reward_max: 1041.0
reward_min: 231.0
total_envstep_count: 132473
total_train_sample_count: 132446
total_episode_count: 771
total_duration: 258.76705937593226
[2022-12-21 15:22:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 993
train_sample_count: 993
avg_envstep_per_episode: 110.33333333333333
avg_sample_per_episode: 110.33333333333333
avg_envstep_per_sec: 514.2350377293864
avg_train_sample_per_sec: 514.2350377293864
avg_episode_per_sec: 4.660740523227067
collect_time: 1.931023612052202
reward_mean: 480.22222900390625
reward_std: 230.48199462890625
reward_max: 778.0
reward_min: 231.0
total_envstep_count: 133521
total_train_sample_count: 133487
total_episode_count: 780
total_duration: 260.6980829879845
[2022-12-21 15:22:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1284
train_sample_count: 1284
avg_envstep_per_episode: 142.66666666666666
avg_sample_per_episode: 142.66666666666666
avg_envstep_per_sec: 511.97964891161405
avg_train_sample_per_sec: 511.97964891161405
avg_episode_per_sec: 3.5886423989131826
collect_time: 2.5079121850440274
reward_mean: 715.3333129882812
reward_std: 374.8611755371094
reward_max: 1391.0
reward_min: 218.0
total_envstep_count: 134520
total_train_sample_count: 134483
total_episode_count: 789
total_duration: 263.2059951730285
[2022-12-21 15:22:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 611
train_sample_count: 611
avg_envstep_per_episode: 101.83333333333333
avg_sample_per_episode: 101.83333333333333
avg_envstep_per_sec: 511.79292248311407
avg_train_sample_per_sec: 511.79292248311407
avg_episode_per_sec: 5.025789746151693
collect_time: 1.1938422224276835
reward_mean: 456.5
reward_std: 328.5837097167969
reward_max: 1027.0
reward_min: 223.0
total_envstep_count: 135483
total_train_sample_count: 135466
total_episode_count: 795
total_duration: 264.3998373954562
[2022-12-21 15:22:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1156
train_sample_count: 1156
avg_envstep_per_episode: 144.5
avg_sample_per_episode: 144.5
avg_envstep_per_sec: 506.60386417319313
avg_train_sample_per_sec: 506.60386417319313
avg_episode_per_sec: 3.5059090946241738
collect_time: 2.2818617893621065
reward_mean: 698.625
reward_std: 478.9279479980469
reward_max: 1305.0
reward_min: 223.0
total_envstep_count: 136527
total_train_sample_count: 136490
total_episode_count: 803
total_duration: 266.6816991848183
[2022-12-21 15:23:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 543
train_sample_count: 543
avg_envstep_per_episode: 181.0
avg_sample_per_episode: 181.0
avg_envstep_per_sec: 487.65685217890206
avg_train_sample_per_sec: 487.65685217890206
avg_episode_per_sec: 2.694236752369625
collect_time: 1.1134878912780963
reward_mean: 848.0
reward_std: 132.27999877929688
reward_max: 1035.0
reward_min: 750.0
total_envstep_count: 137493
total_train_sample_count: 137465
total_episode_count: 806
total_duration: 267.7951870760964
[2022-12-21 15:23:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1024
train_sample_count: 1024
avg_envstep_per_episode: 204.8
avg_sample_per_episode: 204.8
avg_envstep_per_sec: 500.02596716083775
avg_train_sample_per_sec: 500.02596716083775
avg_episode_per_sec: 2.441533042777528
collect_time: 2.0478936440327336
reward_mean: 1045.199951171875
reward_std: 551.7794799804688
reward_max: 1890.0
reward_min: 231.0
total_envstep_count: 138496
total_train_sample_count: 138453
total_episode_count: 811
total_duration: 269.84308072012914
[2022-12-21 15:23:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1861
train_sample_count: 1861
avg_envstep_per_episode: 186.1
avg_sample_per_episode: 186.1
avg_envstep_per_sec: 513.5138221067986
avg_train_sample_per_sec: 513.5138221067986
avg_episode_per_sec: 2.759343482572803
collect_time: 3.624050453724606
reward_mean: 835.0999755859375
reward_std: 475.5229797363281
reward_max: 1887.0
reward_min: 231.0
total_envstep_count: 139488
total_train_sample_count: 139462
total_episode_count: 821
total_duration: 273.4671311738537
[2022-12-21 15:23:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 667
train_sample_count: 667
avg_envstep_per_episode: 95.28571428571429
avg_sample_per_episode: 95.28571428571429
avg_envstep_per_sec: 508.76741004155906
avg_train_sample_per_sec: 508.76741004155906
avg_episode_per_sec: 5.339388111380679
collect_time: 1.311011646649135
reward_mean: 513.2857055664062
reward_std: 281.0148620605469
reward_max: 1042.0
reward_min: 231.0
total_envstep_count: 140506
total_train_sample_count: 140465
total_episode_count: 828
total_duration: 274.77814282050286
[2022-12-21 15:23:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 677
train_sample_count: 677
avg_envstep_per_episode: 96.71428571428571
avg_sample_per_episode: 96.71428571428571
avg_envstep_per_sec: 507.778301504618
avg_train_sample_per_sec: 507.778301504618
avg_episode_per_sec: 5.250292630032978
collect_time: 1.3332590187370246
reward_mean: 576.4285888671875
reward_std: 368.8766174316406
reward_max: 1310.0
reward_min: 222.0
total_envstep_count: 141500
total_train_sample_count: 141466
total_episode_count: 835
total_duration: 276.1114018392399
[2022-12-21 15:23:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1030
train_sample_count: 1030
avg_envstep_per_episode: 206.0
avg_sample_per_episode: 206.0
avg_envstep_per_sec: 511.863191851375
avg_train_sample_per_sec: 511.863191851375
avg_episode_per_sec: 2.4847727759775484
collect_time: 2.012256431791
reward_mean: 932.4000244140625
reward_std: 395.6900939941406
reward_max: 1300.0
reward_min: 231.0
total_envstep_count: 142495
total_train_sample_count: 142460
total_episode_count: 840
total_duration: 278.1236582710309
[2022-12-21 15:23:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1085
train_sample_count: 1085
avg_envstep_per_episode: 155.0
avg_sample_per_episode: 155.0
avg_envstep_per_sec: 494.54702319122987
avg_train_sample_per_sec: 494.54702319122987
avg_episode_per_sec: 3.190625956072451
collect_time: 2.1939268646258854
reward_mean: 650.8571166992188
reward_std: 306.97296142578125
reward_max: 1029.0
reward_min: 223.0
total_envstep_count: 143489
total_train_sample_count: 143461
total_episode_count: 847
total_duration: 280.31758513565677
[2022-12-21 15:23:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 985
train_sample_count: 985
avg_envstep_per_episode: 164.16666666666666
avg_sample_per_episode: 164.16666666666666
avg_envstep_per_sec: 500.1587350107377
avg_train_sample_per_sec: 500.1587350107377
avg_episode_per_sec: 3.0466521929588084
collect_time: 1.9693747825454921
reward_mean: 760.3333129882812
reward_std: 297.3817138671875
reward_max: 1041.0
reward_min: 231.0
total_envstep_count: 144452
total_train_sample_count: 144434
total_episode_count: 853
total_duration: 282.2869599182023
[2022-12-21 15:23:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 789
train_sample_count: 789
avg_envstep_per_episode: 197.25
avg_sample_per_episode: 197.25
avg_envstep_per_sec: 507.30843155909645
avg_train_sample_per_sec: 507.30843155909645
avg_episode_per_sec: 2.5719058634174723
collect_time: 1.5552668769474005
reward_mean: 971.0
reward_std: 442.14080810546875
reward_max: 1318.0
reward_min: 231.0
total_envstep_count: 145449
total_train_sample_count: 145415
total_episode_count: 857
total_duration: 283.8422267951497
[2022-12-21 15:23:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1274
train_sample_count: 1274
avg_envstep_per_episode: 159.25
avg_sample_per_episode: 159.25
avg_envstep_per_sec: 517.6092856473109
avg_train_sample_per_sec: 517.6092856473109
avg_episode_per_sec: 3.250293787424244
collect_time: 2.4613159680989174
reward_mean: 753.0
reward_std: 445.6540222167969
reward_max: 1662.0
reward_min: 222.0
total_envstep_count: 146450
total_train_sample_count: 146413
total_episode_count: 865
total_duration: 286.30354276324863
[2022-12-21 15:23:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1161
train_sample_count: 1161
avg_envstep_per_episode: 145.125
avg_sample_per_episode: 145.125
avg_envstep_per_sec: 515.4007377526249
avg_train_sample_per_sec: 515.4007377526249
avg_episode_per_sec: 3.5514262721972427
collect_time: 2.2526161003619696
reward_mean: 600.125
reward_std: 346.0568542480469
reward_max: 1287.0
reward_min: 231.0
total_envstep_count: 147460
total_train_sample_count: 147442
total_episode_count: 873
total_duration: 288.5561588636106
[2022-12-21 15:23:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 523
train_sample_count: 523
avg_envstep_per_episode: 74.71428571428571
avg_sample_per_episode: 74.71428571428571
avg_envstep_per_sec: 494.06920727668233
avg_train_sample_per_sec: 494.06920727668233
avg_episode_per_sec: 6.6127809769345625
collect_time: 1.0585561542739825
reward_mean: 359.71429443359375
reward_std: 209.52444458007812
reward_max: 740.0
reward_min: 218.0
total_envstep_count: 148509
total_train_sample_count: 148481
total_episode_count: 880
total_duration: 289.6147150178846
[2022-12-21 15:23:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1097
train_sample_count: 1097
avg_envstep_per_episode: 156.71428571428572
avg_sample_per_episode: 156.71428571428572
avg_envstep_per_sec: 470.84471348676493
avg_train_sample_per_sec: 470.84471348676493
avg_episode_per_sec: 3.004478572841709
collect_time: 2.329855191271752
reward_mean: 710.5714111328125
reward_std: 334.7386474609375
reward_max: 1042.0
reward_min: 231.0
total_envstep_count: 149527
total_train_sample_count: 149482
total_episode_count: 887
total_duration: 291.9445702091563
[2022-12-21 15:23:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 988
train_sample_count: 988
avg_envstep_per_episode: 247.0
avg_sample_per_episode: 247.0
avg_envstep_per_sec: 494.37428635473685
avg_train_sample_per_sec: 494.37428635473685
avg_episode_per_sec: 2.0015153293714043
collect_time: 1.9984858178709226
reward_mean: 875.75
reward_std: 278.7538146972656
reward_max: 1251.0
reward_min: 601.0
total_envstep_count: 150507
total_train_sample_count: 150458
total_episode_count: 891
total_duration: 293.94305602702724
[2022-12-21 15:23:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 715
train_sample_count: 715
avg_envstep_per_episode: 238.33333333333334
avg_sample_per_episode: 238.33333333333334
avg_envstep_per_sec: 506.9625333630878
avg_train_sample_per_sec: 506.9625333630878
avg_episode_per_sec: 2.1271155246003683
collect_time: 1.4103606340627055
reward_mean: 1026.6666259765625
reward_std: 10.624918937683105
reward_max: 1040.0
reward_min: 1014.0
total_envstep_count: 151488
total_train_sample_count: 151449
total_episode_count: 894
total_duration: 295.35341666108997
[2022-12-21 15:23:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1558
train_sample_count: 1558
avg_envstep_per_episode: 222.57142857142858
avg_sample_per_episode: 222.57142857142858
avg_envstep_per_sec: 505.90992734568687
avg_train_sample_per_sec: 505.90992734568687
avg_episode_per_sec: 2.2730227801154097
collect_time: 3.079599580451448
reward_mean: 869.7142944335938
reward_std: 366.3533630371094
reward_max: 1314.0
reward_min: 231.0
total_envstep_count: 152466
total_train_sample_count: 152419
total_episode_count: 901
total_duration: 298.4330162415414
[2022-12-21 15:23:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1090
train_sample_count: 1090
avg_envstep_per_episode: 181.66666666666666
avg_sample_per_episode: 181.66666666666666
avg_envstep_per_sec: 502.3240889821168
avg_train_sample_per_sec: 502.3240889821168
avg_episode_per_sec: 2.7650867283419274
collect_time: 2.1699138542384437
reward_mean: 791.3333129882812
reward_std: 270.01275634765625
reward_max: 1301.0
reward_min: 599.0
total_envstep_count: 153437
total_train_sample_count: 153401
total_episode_count: 907
total_duration: 300.6029300957798
[2022-12-21 15:23:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 776
train_sample_count: 776
avg_envstep_per_episode: 110.85714285714286
avg_sample_per_episode: 110.85714285714286
avg_envstep_per_sec: 504.21990085720984
avg_train_sample_per_sec: 504.21990085720984
avg_episode_per_sec: 4.548375394330501
collect_time: 1.5390110518857836
reward_mean: 531.7142944335938
reward_std: 292.4828186035156
reward_max: 1040.0
reward_min: 231.0
total_envstep_count: 154446
total_train_sample_count: 154405
total_episode_count: 914
total_duration: 302.1419411476656
[2022-12-21 15:23:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 861
train_sample_count: 861
avg_envstep_per_episode: 172.2
avg_sample_per_episode: 172.2
avg_envstep_per_sec: 499.3419679047254
avg_train_sample_per_sec: 499.3419679047254
avg_episode_per_sec: 2.899779139980984
collect_time: 1.7242692490134919
reward_mean: 815.5999755859375
reward_std: 359.2991027832031
reward_max: 1315.0
reward_min: 231.0
total_envstep_count: 155434
total_train_sample_count: 155386
total_episode_count: 919
total_duration: 303.8662103966791
[2022-12-21 15:24:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1036
train_sample_count: 1036
avg_envstep_per_episode: 172.66666666666666
avg_sample_per_episode: 172.66666666666666
avg_envstep_per_sec: 498.54770569116397
avg_train_sample_per_sec: 498.54770569116397
avg_episode_per_sec: 2.887341924852301
collect_time: 2.078035839245788
reward_mean: 757.8333129882812
reward_std: 334.8135681152344
reward_max: 1305.0
reward_min: 231.0
total_envstep_count: 156430
total_train_sample_count: 156398
total_episode_count: 925
total_duration: 305.9442462359249
[2022-12-21 15:24:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1188
train_sample_count: 1188
avg_envstep_per_episode: 132.0
avg_sample_per_episode: 132.0
avg_envstep_per_sec: 506.943607160989
avg_train_sample_per_sec: 506.943607160989
avg_episode_per_sec: 3.8404818724317353
collect_time: 2.3434559253110954
reward_mean: 674.2222290039062
reward_std: 470.82452392578125
reward_max: 1319.0
reward_min: 226.0
total_envstep_count: 157423
total_train_sample_count: 157382
total_episode_count: 934
total_duration: 308.287702161236
[2022-12-21 15:24:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1112
train_sample_count: 1112
avg_envstep_per_episode: 139.0
avg_sample_per_episode: 139.0
avg_envstep_per_sec: 511.92391624439273
avg_train_sample_per_sec: 511.92391624439273
avg_episode_per_sec: 3.682905872261818
collect_time: 2.17219779094894
reward_mean: 660.625
reward_std: 394.3291320800781
reward_max: 1296.0
reward_min: 226.0
total_envstep_count: 158417
total_train_sample_count: 158386
total_episode_count: 942
total_duration: 310.4598999521849
[2022-12-21 15:24:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 752
train_sample_count: 752
avg_envstep_per_episode: 150.4
avg_sample_per_episode: 150.4
avg_envstep_per_sec: 518.6711430042783
avg_train_sample_per_sec: 518.6711430042783
avg_episode_per_sec: 3.448611323166744
collect_time: 1.4498589523300258
reward_mean: 749.0
reward_std: 301.8536071777344
reward_max: 1041.0
reward_min: 231.0
total_envstep_count: 159407
total_train_sample_count: 159378
total_episode_count: 947
total_duration: 311.90975890451494
[2022-12-21 15:24:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 548
train_sample_count: 548
avg_envstep_per_episode: 137.0
avg_sample_per_episode: 137.0
avg_envstep_per_sec: 505.77532440659303
avg_train_sample_per_sec: 505.77532440659303
avg_episode_per_sec: 3.691790689099219
collect_time: 1.0834850447537108
reward_mean: 727.25
reward_std: 343.0585632324219
reward_max: 1046.0
reward_min: 223.0
total_envstep_count: 160419
total_train_sample_count: 160370
total_episode_count: 951
total_duration: 312.9932439492687
[2022-12-21 15:24:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1821
train_sample_count: 1821
avg_envstep_per_episode: 165.54545454545453
avg_sample_per_episode: 165.54545454545453
avg_envstep_per_sec: 505.0884044099828
avg_train_sample_per_sec: 505.0884044099828
avg_episode_per_sec: 3.051055710329385
collect_time: 3.605309454940259
reward_mean: 708.1818237304688
reward_std: 408.1512145996094
reward_max: 1297.0
reward_min: 223.0
total_envstep_count: 161416
total_train_sample_count: 161387
total_episode_count: 962
total_duration: 316.59855340420893
[2022-12-21 15:24:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 483
train_sample_count: 483
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 522.4378109354426
avg_train_sample_per_sec: 522.4378109354426
avg_episode_per_sec: 3.2449553474251096
collect_time: 0.9245119512601359
reward_mean: 751.3333129882812
reward_std: 199.6802978515625
reward_max: 1033.0
reward_min: 593.0
total_envstep_count: 162391
total_train_sample_count: 162350
total_episode_count: 965
total_duration: 317.52306535546904
[2022-12-21 15:24:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 964
train_sample_count: 964
avg_envstep_per_episode: 120.5
avg_sample_per_episode: 120.5
avg_envstep_per_sec: 517.580784016858
avg_train_sample_per_sec: 517.580784016858
avg_episode_per_sec: 4.295276215907536
collect_time: 1.8625111862124344
reward_mean: 580.125
reward_std: 401.2537841796875
reward_max: 1306.0
reward_min: 217.0
total_envstep_count: 163392
total_train_sample_count: 163362
total_episode_count: 973
total_duration: 319.3855765416815
[2022-12-21 15:24:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1256
train_sample_count: 1256
avg_envstep_per_episode: 179.42857142857142
avg_sample_per_episode: 179.42857142857142
avg_envstep_per_sec: 512.4329308471057
avg_train_sample_per_sec: 512.4329308471057
avg_episode_per_sec: 2.8559160158676273
collect_time: 2.45105246831756
reward_mean: 789.8571166992188
reward_std: 327.62322998046875
reward_max: 1284.0
reward_min: 217.0
total_envstep_count: 164403
total_train_sample_count: 164354
total_episode_count: 980
total_duration: 321.83662900999906
[2022-12-21 15:25:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 804
train_sample_count: 804
avg_envstep_per_episode: 100.5
avg_sample_per_episode: 100.5
avg_envstep_per_sec: 513.1151881674133
avg_train_sample_per_sec: 513.1151881674133
avg_episode_per_sec: 5.1056237628598335
collect_time: 1.56689963294885
reward_mean: 488.25
reward_std: 347.2980651855469
reward_max: 1028.0
reward_min: 218.0
total_envstep_count: 165380
total_train_sample_count: 165326
total_episode_count: 988
total_duration: 323.4035286429479
[2022-12-21 15:25:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1052
train_sample_count: 1052
avg_envstep_per_episode: 210.4
avg_sample_per_episode: 210.4
avg_envstep_per_sec: 508.26109940289604
avg_train_sample_per_sec: 508.26109940289604
avg_episode_per_sec: 2.415689635945323
collect_time: 2.069802314668361
reward_mean: 935.7999877929688
reward_std: 399.34417724609375
reward_max: 1318.0
reward_min: 231.0
total_envstep_count: 166393
total_train_sample_count: 166342
total_episode_count: 993
total_duration: 325.47333095761627
[2022-12-21 15:25:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1145
train_sample_count: 1145
avg_envstep_per_episode: 190.83333333333334
avg_sample_per_episode: 190.83333333333334
avg_envstep_per_sec: 503.75266622083825
avg_train_sample_per_sec: 503.75266622083825
avg_episode_per_sec: 2.6397519627292834
collect_time: 2.272940823499379
reward_mean: 928.1666870117188
reward_std: 226.19491577148438
reward_max: 1312.0
reward_min: 636.0
total_envstep_count: 167380
total_train_sample_count: 167343
total_episode_count: 999
total_duration: 327.74627178111564
[2022-12-21 15:25:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 918
train_sample_count: 918
avg_envstep_per_episode: 183.6
avg_sample_per_episode: 183.6
avg_envstep_per_sec: 498.9533696933811
avg_train_sample_per_sec: 498.9533696933811
avg_episode_per_sec: 2.7176109460423805
collect_time: 1.839851288235879
reward_mean: 855.0
reward_std: 217.65293884277344
reward_max: 1040.0
reward_min: 584.0
total_envstep_count: 168375
total_train_sample_count: 168333
total_episode_count: 1004
total_duration: 329.5861230693515
[2022-12-21 15:25:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1150
train_sample_count: 1150
avg_envstep_per_episode: 164.28571428571428
avg_sample_per_episode: 164.28571428571428
avg_envstep_per_sec: 497.06180482021813
avg_train_sample_per_sec: 497.06180482021813
avg_episode_per_sec: 3.0255935945578494
collect_time: 2.3135955908258583
reward_mean: 777.4285888671875
reward_std: 336.12066650390625
reward_max: 1303.0
reward_min: 231.0
total_envstep_count: 169361
total_train_sample_count: 169339
total_episode_count: 1011
total_duration: 331.89971866017737
[2022-12-21 15:25:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 862
train_sample_count: 862
avg_envstep_per_episode: 143.66666666666666
avg_sample_per_episode: 143.66666666666666
avg_envstep_per_sec: 496.52768309929365
avg_train_sample_per_sec: 496.52768309929365
avg_episode_per_sec: 3.456109163104132
collect_time: 1.7360562750891386
reward_mean: 591.5
reward_std: 289.8515319824219
reward_max: 1029.0
reward_min: 217.0
total_envstep_count: 170366
total_train_sample_count: 170333
total_episode_count: 1017
total_duration: 333.6357749352665
[2022-12-21 15:25:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1241
train_sample_count: 1241
avg_envstep_per_episode: 124.1
avg_sample_per_episode: 124.1
avg_envstep_per_sec: 498.8216753566919
avg_train_sample_per_sec: 498.8216753566919
avg_episode_per_sec: 4.01951390295481
collect_time: 2.4878630206127257
reward_mean: 568.7999877929688
reward_std: 310.41192626953125
reward_max: 1036.0
reward_min: 222.0
total_envstep_count: 171390
total_train_sample_count: 171346
total_episode_count: 1027
total_duration: 336.12363795587925
[2022-12-21 15:25:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 903
train_sample_count: 903
avg_envstep_per_episode: 100.33333333333333
avg_sample_per_episode: 100.33333333333333
avg_envstep_per_sec: 518.632675014292
avg_train_sample_per_sec: 518.632675014292
avg_episode_per_sec: 5.169096428713874
collect_time: 1.7411166775697577
reward_mean: 522.6666870117188
reward_std: 219.6633758544922
reward_max: 808.0
reward_min: 223.0
total_envstep_count: 172374
total_train_sample_count: 172333
total_episode_count: 1036
total_duration: 337.864754633449
[2022-12-21 15:25:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 970
train_sample_count: 970
avg_envstep_per_episode: 161.66666666666666
avg_sample_per_episode: 161.66666666666666
avg_envstep_per_sec: 508.383683701871
avg_train_sample_per_sec: 508.383683701871
avg_episode_per_sec: 3.1446413424858
collect_time: 1.9080077333261396
reward_mean: 850.8333129882812
reward_std: 440.6591491699219
reward_max: 1675.0
reward_min: 231.0
total_envstep_count: 173361
total_train_sample_count: 173327
total_episode_count: 1042
total_duration: 339.77276236677517
[2022-12-21 15:25:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1186
train_sample_count: 1186
avg_envstep_per_episode: 148.25
avg_sample_per_episode: 148.25
avg_envstep_per_sec: 511.90496967123323
avg_train_sample_per_sec: 511.90496967123323
avg_episode_per_sec: 3.4529846183557047
collect_time: 2.316836268969412
reward_mean: 775.5
reward_std: 315.390625
reward_max: 1315.0
reward_min: 231.0
total_envstep_count: 174363
total_train_sample_count: 174333
total_episode_count: 1050
total_duration: 342.0895986357446
[2022-12-21 15:25:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 586
train_sample_count: 586
avg_envstep_per_episode: 146.5
avg_sample_per_episode: 146.5
avg_envstep_per_sec: 502.28844213860964
avg_train_sample_per_sec: 502.28844213860964
avg_episode_per_sec: 3.4285900487277106
collect_time: 1.166660330675675
reward_mean: 854.25
reward_std: 494.57171630859375
reward_max: 1548.0
reward_min: 222.0
total_envstep_count: 175351
total_train_sample_count: 175315
total_episode_count: 1054
total_duration: 343.25625896642026
[2022-12-21 15:25:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1103
train_sample_count: 1103
avg_envstep_per_episode: 122.55555555555556
avg_sample_per_episode: 122.55555555555556
avg_envstep_per_sec: 501.75122658860784
avg_train_sample_per_sec: 501.75122658860784
avg_episode_per_sec: 4.094071658474588
collect_time: 2.1983005552358392
reward_mean: 658.7777709960938
reward_std: 437.4669189453125
reward_max: 1304.0
reward_min: 231.0
total_envstep_count: 176343
total_train_sample_count: 176310
total_episode_count: 1063
total_duration: 345.4545595216561
[2022-12-21 15:25:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 921
train_sample_count: 921
avg_envstep_per_episode: 153.5
avg_sample_per_episode: 153.5
avg_envstep_per_sec: 506.63466242763417
avg_train_sample_per_sec: 506.63466242763417
avg_episode_per_sec: 3.3005515467598316
collect_time: 1.8178779864505465
reward_mean: 737.8333129882812
reward_std: 411.1096496582031
reward_max: 1282.0
reward_min: 217.0
total_envstep_count: 177386
total_train_sample_count: 177351
total_episode_count: 1069
total_duration: 347.27243750810663
[2022-12-21 15:25:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1056
train_sample_count: 1056
avg_envstep_per_episode: 176.0
avg_sample_per_episode: 176.0
avg_envstep_per_sec: 505.9233735366453
avg_train_sample_per_sec: 505.9233735366453
avg_episode_per_sec: 2.874564622367303
collect_time: 2.0872726093243275
reward_mean: 789.8333129882812
reward_std: 334.1219482421875
reward_max: 1309.0
reward_min: 231.0
total_envstep_count: 178391
total_train_sample_count: 178347
total_episode_count: 1075
total_duration: 349.35971011743095
[2022-12-21 15:26:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 859
train_sample_count: 859
avg_envstep_per_episode: 143.16666666666666
avg_sample_per_episode: 143.16666666666666
avg_envstep_per_sec: 498.1726427457008
avg_train_sample_per_sec: 498.1726427457008
avg_episode_per_sec: 3.479669215918748
collect_time: 1.7243018309186613
reward_mean: 733.5
reward_std: 394.07391357421875
reward_max: 1304.0
reward_min: 231.0
total_envstep_count: 179377
total_train_sample_count: 179350
total_episode_count: 1081
total_duration: 351.0840119483496
[2022-12-21 15:26:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1146
train_sample_count: 1146
avg_envstep_per_episode: 191.0
avg_sample_per_episode: 191.0
avg_envstep_per_sec: 503.65040375106213
avg_train_sample_per_sec: 503.65040375106213
avg_episode_per_sec: 2.6369131086443045
collect_time: 2.2753878314499083
reward_mean: 941.3333129882812
reward_std: 255.62319946289062
reward_max: 1315.0
reward_min: 580.0
total_envstep_count: 180379
total_train_sample_count: 180340
total_episode_count: 1087
total_duration: 353.3593997797995
[2022-12-21 15:26:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1007
train_sample_count: 1007
avg_envstep_per_episode: 167.83333333333334
avg_sample_per_episode: 167.83333333333334
avg_envstep_per_sec: 512.026772474089
avg_train_sample_per_sec: 512.026772474089
avg_episode_per_sec: 3.050804999845614
collect_time: 1.9666940365915322
reward_mean: 734.5
reward_std: 339.7218322753906
reward_max: 1282.0
reward_min: 223.0
total_envstep_count: 181384
total_train_sample_count: 181347
total_episode_count: 1093
total_duration: 355.32609381639105
[2022-12-21 15:26:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1010
train_sample_count: 1010
avg_envstep_per_episode: 168.33333333333334
avg_sample_per_episode: 168.33333333333334
avg_envstep_per_sec: 499.46270079881106
avg_train_sample_per_sec: 499.46270079881106
avg_episode_per_sec: 2.9671051532602637
collect_time: 2.0221730239008155
reward_mean: 746.1666870117188
reward_std: 275.5621032714844
reward_max: 1046.0
reward_min: 231.0
total_envstep_count: 182388
total_train_sample_count: 182333
total_episode_count: 1099
total_duration: 357.34826684029184
[2022-12-21 15:26:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1387
train_sample_count: 1387
avg_envstep_per_episode: 126.0909090909091
avg_sample_per_episode: 126.0909090909091
avg_envstep_per_sec: 495.1729719760888
avg_train_sample_per_sec: 495.1729719760888
avg_episode_per_sec: 3.9271108087505238
collect_time: 2.8010414107718633
reward_mean: 638.0908813476562
reward_std: 324.0643615722656
reward_max: 1310.0
reward_min: 215.0
total_envstep_count: 183346
total_train_sample_count: 183312
total_episode_count: 1110
total_duration: 360.1493082510637
[2022-12-21 15:26:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 467
train_sample_count: 467
avg_envstep_per_episode: 77.83333333333333
avg_sample_per_episode: 77.83333333333333
avg_envstep_per_sec: 502.6013607571603
avg_train_sample_per_sec: 502.6013607571603
avg_episode_per_sec: 6.45740506326116
collect_time: 0.9291658090548591
reward_mean: 414.6666564941406
reward_std: 186.9087677001953
reward_max: 618.0
reward_min: 222.0
total_envstep_count: 184366
total_train_sample_count: 184319
total_episode_count: 1116
total_duration: 361.07847406011854
[2022-12-21 15:26:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1475
train_sample_count: 1475
avg_envstep_per_episode: 147.5
avg_sample_per_episode: 147.5
avg_envstep_per_sec: 508.7976530764115
avg_train_sample_per_sec: 508.7976530764115
avg_episode_per_sec: 3.449475614077366
collect_time: 2.898991359495292
reward_mean: 760.4000244140625
reward_std: 403.3326721191406
reward_max: 1308.0
reward_min: 223.0
total_envstep_count: 185350
total_train_sample_count: 185314
total_episode_count: 1126
total_duration: 363.97746541961385
[2022-12-21 15:26:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 153
train_sample_count: 153
avg_envstep_per_episode: 153.0
avg_sample_per_episode: 153.0
avg_envstep_per_sec: 489.3295973666978
avg_train_sample_per_sec: 489.3295973666978
avg_episode_per_sec: 3.1982326625274364
collect_time: 0.3126726869238274
reward_mean: 716.0
reward_std: 0.0
reward_max: 716.0
reward_min: 716.0
total_envstep_count: 186325
total_train_sample_count: 186283
total_episode_count: 1127
total_duration: 364.29013810653765
[2022-12-21 15:26:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1520
train_sample_count: 1520
avg_envstep_per_episode: 217.14285714285714
avg_sample_per_episode: 217.14285714285714
avg_envstep_per_sec: 493.3953245620995
avg_train_sample_per_sec: 493.3953245620995
avg_episode_per_sec: 2.272215310483353
collect_time: 3.080693967558443
reward_mean: 991.2857055664062
reward_std: 365.8421630859375
reward_max: 1307.0
reward_min: 223.0
total_envstep_count: 187344
total_train_sample_count: 187311
total_episode_count: 1134
total_duration: 367.3708320740961
[2022-12-21 15:26:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1157
train_sample_count: 1157
avg_envstep_per_episode: 115.7
avg_sample_per_episode: 115.7
avg_envstep_per_sec: 493.8122468292392
avg_train_sample_per_sec: 493.8122468292392
avg_episode_per_sec: 4.268040162741912
collect_time: 2.3429957588720796
reward_mean: 611.2000122070312
reward_std: 376.2230224609375
reward_max: 1304.0
reward_min: 231.0
total_envstep_count: 188352
total_train_sample_count: 188312
total_episode_count: 1144
total_duration: 369.71382783296815
[2022-12-21 15:26:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 878
train_sample_count: 878
avg_envstep_per_episode: 175.6
avg_sample_per_episode: 175.6
avg_envstep_per_sec: 501.40806000914915
avg_train_sample_per_sec: 501.40806000914915
avg_episode_per_sec: 2.855398974995155
collect_time: 1.7510687801547888
reward_mean: 835.7999877929688
reward_std: 285.87017822265625
reward_max: 1314.0
reward_min: 602.0
total_envstep_count: 189309
total_train_sample_count: 189298
total_episode_count: 1149
total_duration: 371.46489661312296
[2022-12-21 15:26:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 922
train_sample_count: 922
avg_envstep_per_episode: 184.4
avg_sample_per_episode: 184.4
avg_envstep_per_sec: 500.5262000842565
avg_train_sample_per_sec: 500.5262000842565
avg_episode_per_sec: 2.714350325836532
collect_time: 1.8420614142572242
reward_mean: 873.7999877929688
reward_std: 526.9422607421875
reward_max: 1316.0
reward_min: 226.0
total_envstep_count: 190322
total_train_sample_count: 190280
total_episode_count: 1154
total_duration: 373.3069580273802
[2022-12-21 15:26:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1191
train_sample_count: 1191
avg_envstep_per_episode: 170.14285714285714
avg_sample_per_episode: 170.14285714285714
avg_envstep_per_sec: 504.4469213420631
avg_train_sample_per_sec: 504.4469213420631
avg_episode_per_sec: 2.964843366410111
collect_time: 2.3610016229881765
reward_mean: 777.2857055664062
reward_std: 421.99822998046875
reward_max: 1318.0
reward_min: 223.0
total_envstep_count: 191331
total_train_sample_count: 191279
total_episode_count: 1161
total_duration: 375.66795965036835
[2022-12-21 15:26:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 554
train_sample_count: 554
avg_envstep_per_episode: 110.8
avg_sample_per_episode: 110.8
avg_envstep_per_sec: 494.49377124673754
avg_train_sample_per_sec: 494.49377124673754
avg_episode_per_sec: 4.462940173707017
collect_time: 1.1203376709947892
reward_mean: 564.7999877929688
reward_std: 307.8560791015625
reward_max: 1035.0
reward_min: 223.0
total_envstep_count: 192303
total_train_sample_count: 192265
total_episode_count: 1166
total_duration: 376.78829732136313
[2022-12-21 15:26:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1378
train_sample_count: 1378
avg_envstep_per_episode: 196.85714285714286
avg_sample_per_episode: 196.85714285714286
avg_envstep_per_sec: 497.30392328678494
avg_train_sample_per_sec: 497.30392328678494
avg_episode_per_sec: 2.526217317131709
collect_time: 2.770941340845477
reward_mean: 983.0
reward_std: 332.30450439453125
reward_max: 1550.0
reward_min: 609.0
total_envstep_count: 193305
total_train_sample_count: 193283
total_episode_count: 1173
total_duration: 379.5592386622086
[2022-12-21 15:27:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 871
train_sample_count: 871
avg_envstep_per_episode: 174.2
avg_sample_per_episode: 174.2
avg_envstep_per_sec: 519.2211045509536
avg_train_sample_per_sec: 519.2211045509536
avg_episode_per_sec: 2.980603355631192
collect_time: 1.6775127057928068
reward_mean: 825.7999877929688
reward_std: 180.7411346435547
reward_max: 1040.0
reward_min: 628.0
total_envstep_count: 194309
total_train_sample_count: 194262
total_episode_count: 1178
total_duration: 381.2367513680014
[2022-12-21 15:27:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1024
train_sample_count: 1024
avg_envstep_per_episode: 170.66666666666666
avg_sample_per_episode: 170.66666666666666
avg_envstep_per_sec: 499.4568310860065
avg_train_sample_per_sec: 499.4568310860065
avg_episode_per_sec: 2.9265048696445692
collect_time: 2.0502272394061363
reward_mean: 749.5
reward_std: 272.6100769042969
reward_max: 1035.0
reward_min: 231.0
total_envstep_count: 195296
total_train_sample_count: 195262
total_episode_count: 1184
total_duration: 383.28697860740755
[2022-12-21 15:27:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 703
train_sample_count: 703
avg_envstep_per_episode: 140.6
avg_sample_per_episode: 140.6
avg_envstep_per_sec: 487.0043090931699
avg_train_sample_per_sec: 487.0043090931699
avg_episode_per_sec: 3.463757532668349
collect_time: 1.4435190549114987
reward_mean: 765.2000122070312
reward_std: 372.563232421875
reward_max: 1311.0
reward_min: 231.0
total_envstep_count: 196293
total_train_sample_count: 196241
total_episode_count: 1189
total_duration: 384.73049766231907
[2022-12-21 15:27:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1176
train_sample_count: 1176
avg_envstep_per_episode: 235.2
avg_sample_per_episode: 235.2
avg_envstep_per_sec: 486.7509167752889
avg_train_sample_per_sec: 486.7509167752889
avg_episode_per_sec: 2.069519203976568
collect_time: 2.416020102829938
reward_mean: 1133.199951171875
reward_std: 285.6917419433594
reward_max: 1403.0
reward_min: 626.0
total_envstep_count: 197296
total_train_sample_count: 197249
total_episode_count: 1194
total_duration: 387.146517765149
[2022-12-21 15:27:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 846
train_sample_count: 846
avg_envstep_per_episode: 169.2
avg_sample_per_episode: 169.2
avg_envstep_per_sec: 496.90067437919134
avg_train_sample_per_sec: 496.90067437919134
avg_episode_per_sec: 2.936765215007041
collect_time: 1.702553535587288
reward_mean: 823.0
reward_std: 493.728271484375
reward_max: 1313.0
reward_min: 231.0
total_envstep_count: 198276
total_train_sample_count: 198227
total_episode_count: 1199
total_duration: 388.8490713007363
[2022-12-21 15:27:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1135
train_sample_count: 1135
avg_envstep_per_episode: 189.16666666666666
avg_sample_per_episode: 189.16666666666666
avg_envstep_per_sec: 503.3495336532536
avg_train_sample_per_sec: 503.3495336532536
avg_episode_per_sec: 2.6608785919995785
collect_time: 2.2548943112399433
reward_mean: 821.1666870117188
reward_std: 318.8810729980469
reward_max: 1290.0
reward_min: 231.0
total_envstep_count: 199255
total_train_sample_count: 199230
total_episode_count: 1205
total_duration: 391.1039656119762
[2022-12-21 15:27:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1172
train_sample_count: 1172
avg_envstep_per_episode: 167.42857142857142
avg_sample_per_episode: 167.42857142857142
avg_envstep_per_sec: 487.4162861300698
avg_train_sample_per_sec: 487.4162861300698
avg_episode_per_sec: 2.9111894222785737
collect_time: 2.4045154693235777
reward_mean: 798.5714111328125
reward_std: 324.318115234375
reward_max: 1290.0
reward_min: 231.0
total_envstep_count: 200282
total_train_sample_count: 200234
total_episode_count: 1212
total_duration: 393.5084810812998
[2022-12-21 15:27:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 979
train_sample_count: 979
avg_envstep_per_episode: 122.375
avg_sample_per_episode: 122.375
avg_envstep_per_sec: 499.715280260754
avg_train_sample_per_sec: 499.715280260754
avg_episode_per_sec: 4.083475221742627
collect_time: 1.9591155977642964
reward_mean: 599.25
reward_std: 322.91900634765625
reward_max: 1038.0
reward_min: 231.0
total_envstep_count: 201251
total_train_sample_count: 201213
total_episode_count: 1220
total_duration: 395.4675966790641
[2022-12-21 15:27:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1239
train_sample_count: 1239
avg_envstep_per_episode: 112.63636363636364
avg_sample_per_episode: 112.63636363636364
avg_envstep_per_sec: 514.5845491588883
avg_train_sample_per_sec: 514.5845491588883
avg_episode_per_sec: 4.568547248383996
collect_time: 2.407767590428437
reward_mean: 558.3636474609375
reward_std: 355.3076477050781
reward_max: 1300.0
reward_min: 231.0
total_envstep_count: 202222
total_train_sample_count: 202188
total_episode_count: 1231
total_duration: 397.87536426949254
[2022-12-21 15:27:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 483
train_sample_count: 483
avg_envstep_per_episode: 80.5
avg_sample_per_episode: 80.5
avg_envstep_per_sec: 509.38183019241944
avg_train_sample_per_sec: 509.38183019241944
avg_episode_per_sec: 6.327724598663596
collect_time: 0.9482081444042602
reward_mean: 386.8333435058594
reward_std: 228.18881225585938
reward_max: 801.0
reward_min: 231.0
total_envstep_count: 203210
total_train_sample_count: 203175
total_episode_count: 1237
total_duration: 398.8235724138968
[2022-12-21 15:27:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1057
train_sample_count: 1057
avg_envstep_per_episode: 176.16666666666666
avg_sample_per_episode: 176.16666666666666
avg_envstep_per_sec: 501.6422933229311
avg_train_sample_per_sec: 501.6422933229311
avg_episode_per_sec: 2.8475437653146516
collect_time: 2.1070791160735696
reward_mean: 777.8333129882812
reward_std: 297.1511535644531
reward_max: 1037.0
reward_min: 218.0
total_envstep_count: 204221
total_train_sample_count: 204160
total_episode_count: 1243
total_duration: 400.93065152997036
[2022-12-21 15:27:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 959
train_sample_count: 959
avg_envstep_per_episode: 191.8
avg_sample_per_episode: 191.8
avg_envstep_per_sec: 495.1692660725213
avg_train_sample_per_sec: 495.1692660725213
avg_episode_per_sec: 2.5816958606492246
collect_time: 1.936711475666479
reward_mean: 836.7999877929688
reward_std: 377.6190490722656
reward_max: 1295.0
reward_min: 231.0
total_envstep_count: 205193
total_train_sample_count: 205167
total_episode_count: 1248
total_duration: 402.86736300563683
[2022-12-21 15:27:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1355
train_sample_count: 1355
avg_envstep_per_episode: 135.5
avg_sample_per_episode: 135.5
avg_envstep_per_sec: 499.6510986927978
avg_train_sample_per_sec: 499.6510986927978
avg_episode_per_sec: 3.6874619829726774
collect_time: 2.711892365582687
reward_mean: 681.9000244140625
reward_std: 377.4778137207031
reward_max: 1400.0
reward_min: 215.0
total_envstep_count: 206218
total_train_sample_count: 206174
total_episode_count: 1258
total_duration: 405.5792553712195
[2022-12-21 15:27:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 442
train_sample_count: 442
avg_envstep_per_episode: 147.33333333333334
avg_sample_per_episode: 147.33333333333334
avg_envstep_per_sec: 498.98087666293867
avg_train_sample_per_sec: 498.98087666293867
avg_episode_per_sec: 3.386748031648905
collect_time: 0.8858054900941039
reward_mean: 746.6666870117188
reward_std: 208.1735382080078
reward_max: 1041.0
reward_min: 594.0
total_envstep_count: 207177
total_train_sample_count: 207144
total_episode_count: 1261
total_duration: 406.46506086131365
[2022-12-21 15:27:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1624
train_sample_count: 1624
avg_envstep_per_episode: 180.44444444444446
avg_sample_per_episode: 180.44444444444446
avg_envstep_per_sec: 511.39230639324666
avg_train_sample_per_sec: 511.39230639324666
avg_episode_per_sec: 2.8340706635093715
collect_time: 3.1756441770776047
reward_mean: 968.4444580078125
reward_std: 405.8697509765625
reward_max: 1551.0
reward_min: 223.0
total_envstep_count: 208250
total_train_sample_count: 208204
total_episode_count: 1270
total_duration: 409.6407050383913
[2022-12-21 15:27:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 688
train_sample_count: 688
avg_envstep_per_episode: 86.0
avg_sample_per_episode: 86.0
avg_envstep_per_sec: 516.9783215315894
avg_train_sample_per_sec: 516.9783215315894
avg_episode_per_sec: 6.011375831762667
collect_time: 1.3308101545955453
reward_mean: 467.125
reward_std: 188.72164916992188
reward_max: 627.0
reward_min: 215.0
total_envstep_count: 209221
total_train_sample_count: 209192
total_episode_count: 1278
total_duration: 410.97151519298683
[2022-12-21 15:27:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1322
train_sample_count: 1322
avg_envstep_per_episode: 132.2
avg_sample_per_episode: 132.2
avg_envstep_per_sec: 510.7099423726553
avg_train_sample_per_sec: 510.7099423726553
avg_episode_per_sec: 3.863161440035214
collect_time: 2.5885534827425816
reward_mean: 659.5
reward_std: 413.1523132324219
reward_max: 1305.0
reward_min: 226.0
total_envstep_count: 210270
total_train_sample_count: 210226
total_episode_count: 1288
total_duration: 413.5600686757294
[2022-12-21 15:27:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 771
train_sample_count: 771
avg_envstep_per_episode: 154.2
avg_sample_per_episode: 154.2
avg_envstep_per_sec: 511.70843193790535
avg_train_sample_per_sec: 511.70843193790535
avg_episode_per_sec: 3.3184723212574925
collect_time: 1.5067174036591977
reward_mean: 781.2000122070312
reward_std: 211.44493103027344
reward_max: 1041.0
reward_min: 595.0
total_envstep_count: 211250
total_train_sample_count: 211213
total_episode_count: 1293
total_duration: 415.0667860793886
[2022-12-21 15:28:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 926
train_sample_count: 926
avg_envstep_per_episode: 132.28571428571428
avg_sample_per_episode: 132.28571428571428
avg_envstep_per_sec: 502.209415191933
avg_train_sample_per_sec: 502.209415191933
avg_episode_per_sec: 3.7963994668936616
collect_time: 1.84385232930391
reward_mean: 646.2857055664062
reward_std: 375.1706848144531
reward_max: 1046.0
reward_min: 223.0
total_envstep_count: 212268
total_train_sample_count: 212223
total_episode_count: 1300
total_duration: 416.9106384086925
[2022-12-21 15:28:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1170
train_sample_count: 1170
avg_envstep_per_episode: 167.14285714285714
avg_sample_per_episode: 167.14285714285714
avg_envstep_per_sec: 509.0697629076049
avg_train_sample_per_sec: 509.0697629076049
avg_episode_per_sec: 3.0457165302164397
collect_time: 2.298309750941449
reward_mean: 862.7142944335938
reward_std: 513.3098754882812
reward_max: 1809.0
reward_min: 231.0
total_envstep_count: 213262
total_train_sample_count: 213225
total_episode_count: 1307
total_duration: 419.2089481596339
[2022-12-21 15:28:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 996
train_sample_count: 996
avg_envstep_per_episode: 166.0
avg_sample_per_episode: 166.0
avg_envstep_per_sec: 493.80541399169044
avg_train_sample_per_sec: 493.80541399169044
avg_episode_per_sec: 2.9747314095884967
collect_time: 2.0169888214647242
reward_mean: 859.5
reward_std: 458.2298278808594
reward_max: 1311.0
reward_min: 231.0
total_envstep_count: 214281
total_train_sample_count: 214233
total_episode_count: 1313
total_duration: 421.22593698109864
[2022-12-21 15:28:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1050
train_sample_count: 1050
avg_envstep_per_episode: 175.0
avg_sample_per_episode: 175.0
avg_envstep_per_sec: 477.5978463341495
avg_train_sample_per_sec: 477.5978463341495
avg_episode_per_sec: 2.7291305504808543
collect_time: 2.1985023761295848
reward_mean: 923.8333129882812
reward_std: 386.84942626953125
reward_max: 1309.0
reward_min: 223.0
total_envstep_count: 215267
total_train_sample_count: 215235
total_episode_count: 1319
total_duration: 423.4244393572282
[2022-12-21 15:28:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 913
train_sample_count: 913
avg_envstep_per_episode: 182.6
avg_sample_per_episode: 182.6
avg_envstep_per_sec: 488.6593955743983
avg_train_sample_per_sec: 488.6593955743983
avg_episode_per_sec: 2.6761193624008666
collect_time: 1.8683770500857912
reward_mean: 859.7999877929688
reward_std: 372.7220764160156
reward_max: 1311.0
reward_min: 218.0
total_envstep_count: 216247
total_train_sample_count: 216208
total_episode_count: 1324
total_duration: 425.292816407314
[2022-12-21 15:28:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1153
train_sample_count: 1153
avg_envstep_per_episode: 192.16666666666666
avg_sample_per_episode: 192.16666666666666
avg_envstep_per_sec: 494.82329418532817
avg_train_sample_per_sec: 494.82329418532817
avg_episode_per_sec: 2.574969440686877
collect_time: 2.330124740587015
reward_mean: 963.5
reward_std: 304.18511962890625
reward_max: 1549.0
reward_min: 585.0
total_envstep_count: 217260
total_train_sample_count: 217217
total_episode_count: 1330
total_duration: 427.622941147901
[2022-12-21 15:28:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 596
train_sample_count: 596
avg_envstep_per_episode: 149.0
avg_sample_per_episode: 149.0
avg_envstep_per_sec: 515.0992581744271
avg_train_sample_per_sec: 515.0992581744271
avg_episode_per_sec: 3.4570420011706515
collect_time: 1.1570585485063496
reward_mean: 659.0
reward_std: 293.8605041503906
reward_max: 1035.0
reward_min: 217.0
total_envstep_count: 218218
total_train_sample_count: 218197
total_episode_count: 1334
total_duration: 428.77999969640734
[2022-12-21 15:28:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1537
train_sample_count: 1537
avg_envstep_per_episode: 153.7
avg_sample_per_episode: 153.7
avg_envstep_per_sec: 506.4844738488164
avg_train_sample_per_sec: 506.4844738488164
avg_episode_per_sec: 3.2952795956331578
collect_time: 3.034643862466727
reward_mean: 704.2999877929688
reward_std: 271.2817687988281
reward_max: 1299.0
reward_min: 231.0
total_envstep_count: 219229
total_train_sample_count: 219206
total_episode_count: 1344
total_duration: 431.8146435588741
[2022-12-21 15:28:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 331
train_sample_count: 331
avg_envstep_per_episode: 165.5
avg_sample_per_episode: 165.5
avg_envstep_per_sec: 501.9184180941596
avg_train_sample_per_sec: 501.9184180941596
avg_episode_per_sec: 3.0327396863695446
collect_time: 0.6594697227028329
reward_mean: 705.0
reward_std: 94.0
reward_max: 799.0
reward_min: 611.0
total_envstep_count: 220188
total_train_sample_count: 220173
total_episode_count: 1346
total_duration: 432.47411328157693
[2022-12-21 15:29:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1372
train_sample_count: 1372
avg_envstep_per_episode: 152.44444444444446
avg_sample_per_episode: 152.44444444444446
avg_envstep_per_sec: 495.5929321273526
avg_train_sample_per_sec: 495.5929321273526
avg_episode_per_sec: 3.2509740445671818
collect_time: 2.768401062764626
reward_mean: 754.5555419921875
reward_std: 402.8890075683594
reward_max: 1298.0
reward_min: 231.0
total_envstep_count: 221203
total_train_sample_count: 221161
total_episode_count: 1355
total_duration: 435.24251434434154
[2022-12-21 15:29:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 693
train_sample_count: 693
avg_envstep_per_episode: 138.6
avg_sample_per_episode: 138.6
avg_envstep_per_sec: 497.431847083956
avg_train_sample_per_sec: 497.431847083956
avg_episode_per_sec: 3.5889743656851083
collect_time: 1.3931556736113766
reward_mean: 685.4000244140625
reward_std: 428.0301818847656
reward_max: 1297.0
reward_min: 231.0
total_envstep_count: 222183
total_train_sample_count: 222154
total_episode_count: 1360
total_duration: 436.6356700179529
[2022-12-21 15:29:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1423
train_sample_count: 1423
avg_envstep_per_episode: 177.875
avg_sample_per_episode: 177.875
avg_envstep_per_sec: 493.27848629708404
avg_train_sample_per_sec: 493.27848629708404
avg_episode_per_sec: 2.77317490539471
collect_time: 2.8847801790061807
reward_mean: 910.625
reward_std: 467.5758972167969
reward_max: 1540.0
reward_min: 231.0
total_envstep_count: 223192
total_train_sample_count: 223157
total_episode_count: 1368
total_duration: 439.5204501969591
[2022-12-21 15:29:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 884
train_sample_count: 884
avg_envstep_per_episode: 110.5
avg_sample_per_episode: 110.5
avg_envstep_per_sec: 494.5400870160916
avg_train_sample_per_sec: 494.5400870160916
avg_episode_per_sec: 4.475475900598114
collect_time: 1.7875194007705102
reward_mean: 614.5
reward_std: 372.72039794921875
reward_max: 1306.0
reward_min: 223.0
total_envstep_count: 224233
total_train_sample_count: 224197
total_episode_count: 1376
total_duration: 441.3079695977296
[2022-12-21 15:29:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 759
train_sample_count: 759
avg_envstep_per_episode: 151.8
avg_sample_per_episode: 151.8
avg_envstep_per_sec: 510.3373599179532
avg_train_sample_per_sec: 510.3373599179532
avg_episode_per_sec: 3.3619061918178734
collect_time: 1.487251492075799
reward_mean: 794.0
reward_std: 263.5169982910156
reward_max: 1300.0
reward_min: 614.0
total_envstep_count: 225212
total_train_sample_count: 225172
total_episode_count: 1381
total_duration: 442.7952210898054
[2022-12-21 15:29:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1338
train_sample_count: 1338
avg_envstep_per_episode: 223.0
avg_sample_per_episode: 223.0
avg_envstep_per_sec: 499.2872290201587
avg_train_sample_per_sec: 499.2872290201587
avg_episode_per_sec: 2.2389561839469
collect_time: 2.679820196133994
reward_mean: 1117.1666259765625
reward_std: 338.5470886230469
reward_max: 1828.0
reward_min: 720.0
total_envstep_count: 226199
total_train_sample_count: 226162
total_episode_count: 1387
total_duration: 445.4750412859394
[2022-12-21 15:29:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 976
train_sample_count: 976
avg_envstep_per_episode: 162.66666666666666
avg_sample_per_episode: 162.66666666666666
avg_envstep_per_sec: 484.48475853362663
avg_train_sample_per_sec: 484.48475853362663
avg_episode_per_sec: 2.9783899090181962
collect_time: 2.0145112571838704
reward_mean: 722.5
reward_std: 278.2958679199219
reward_max: 1035.0
reward_min: 226.0
total_envstep_count: 227177
total_train_sample_count: 227150
total_episode_count: 1393
total_duration: 447.4895525431233
[2022-12-21 15:29:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 749
train_sample_count: 749
avg_envstep_per_episode: 124.83333333333333
avg_sample_per_episode: 124.83333333333333
avg_envstep_per_sec: 496.52615304487387
avg_train_sample_per_sec: 496.52615304487387
avg_episode_per_sec: 3.977512574458269
collect_time: 1.5084804605092144
reward_mean: 644.1666870117188
reward_std: 238.72677612304688
reward_max: 1037.0
reward_min: 231.0
total_envstep_count: 228197
total_train_sample_count: 228151
total_episode_count: 1399
total_duration: 448.9980330036325
[2022-12-21 15:29:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1110
train_sample_count: 1110
avg_envstep_per_episode: 185.0
avg_sample_per_episode: 185.0
avg_envstep_per_sec: 498.51926311643444
avg_train_sample_per_sec: 498.51926311643444
avg_episode_per_sec: 2.6946987195482945
collect_time: 2.226593999720223
reward_mean: 950.0
reward_std: 292.34912109375
reward_max: 1314.0
reward_min: 601.0
total_envstep_count: 229184
total_train_sample_count: 229153
total_episode_count: 1405
total_duration: 451.22462700335274
[2022-12-21 15:29:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 545
train_sample_count: 545
avg_envstep_per_episode: 181.66666666666666
avg_sample_per_episode: 181.66666666666666
avg_envstep_per_sec: 500.1038512638763
avg_train_sample_per_sec: 500.1038512638763
avg_episode_per_sec: 2.7528652363149155
collect_time: 1.0897736512579554
reward_mean: 1043.3333740234375
reward_std: 2.8674418926239014
reward_max: 1047.0
reward_min: 1040.0
total_envstep_count: 230157
total_train_sample_count: 230130
total_episode_count: 1408
total_duration: 452.31440065461067
[2022-12-21 15:29:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1603
train_sample_count: 1603
avg_envstep_per_episode: 178.11111111111111
avg_sample_per_episode: 178.11111111111111
avg_envstep_per_sec: 497.6978817917745
avg_train_sample_per_sec: 497.6978817917745
avg_episode_per_sec: 2.794311251482202
collect_time: 3.220829460292256
reward_mean: 787.3333129882812
reward_std: 366.1678466796875
reward_max: 1403.0
reward_min: 231.0
total_envstep_count: 231149
total_train_sample_count: 231109
total_episode_count: 1417
total_duration: 455.5352301149029
[2022-12-21 15:29:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 908
train_sample_count: 908
avg_envstep_per_episode: 181.6
avg_sample_per_episode: 181.6
avg_envstep_per_sec: 495.73028195166796
avg_train_sample_per_sec: 495.73028195166796
avg_episode_per_sec: 2.7297923014959693
collect_time: 1.831641182832819
reward_mean: 989.4000244140625
reward_std: 296.1929016113281
reward_max: 1306.0
reward_min: 589.0
total_envstep_count: 232145
total_train_sample_count: 232089
total_episode_count: 1422
total_duration: 457.3668712977357
[2022-12-21 15:29:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 520
train_sample_count: 520
avg_envstep_per_episode: 173.33333333333334
avg_sample_per_episode: 173.33333333333334
avg_envstep_per_sec: 501.5435234789425
avg_train_sample_per_sec: 501.5435234789425
avg_episode_per_sec: 2.8935203277631296
collect_time: 1.03679935171535
reward_mean: 801.6666870117188
reward_std: 187.90127563476562
reward_max: 1041.0
reward_min: 582.0
total_envstep_count: 233104
total_train_sample_count: 233065
total_episode_count: 1425
total_duration: 458.40367064945104
[2022-12-21 15:29:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1166
train_sample_count: 1166
avg_envstep_per_episode: 166.57142857142858
avg_sample_per_episode: 166.57142857142858
avg_envstep_per_sec: 501.24650323239075
avg_train_sample_per_sec: 501.24650323239075
avg_episode_per_sec: 3.009198561429447
collect_time: 2.3262007664508584
reward_mean: 818.0
reward_std: 198.3755340576172
reward_max: 1046.0
reward_min: 586.0
total_envstep_count: 234057
total_train_sample_count: 234039
total_episode_count: 1432
total_duration: 460.7298714159019
[2022-12-21 15:29:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 840
train_sample_count: 840
avg_envstep_per_episode: 168.0
avg_sample_per_episode: 168.0
avg_envstep_per_sec: 501.0563632667342
avg_train_sample_per_sec: 501.0563632667342
avg_episode_per_sec: 2.98247835277818
collect_time: 1.6764581024846326
reward_mean: 898.2000122070312
reward_std: 418.4138488769531
reward_max: 1311.0
reward_min: 231.0
total_envstep_count: 235070
total_train_sample_count: 235023
total_episode_count: 1437
total_duration: 462.40632951838654
[2022-12-21 15:29:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1305
train_sample_count: 1305
avg_envstep_per_episode: 186.42857142857142
avg_sample_per_episode: 186.42857142857142
avg_envstep_per_sec: 500.2862464265289
avg_train_sample_per_sec: 500.2862464265289
avg_episode_per_sec: 2.6835277586097335
collect_time: 2.6085066485865305
reward_mean: 858.7142944335938
reward_std: 329.5874938964844
reward_max: 1311.0
reward_min: 231.0
total_envstep_count: 236064
total_train_sample_count: 236016
total_episode_count: 1444
total_duration: 465.01483616697305
[2022-12-21 15:29:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 829
train_sample_count: 829
avg_envstep_per_episode: 138.16666666666666
avg_sample_per_episode: 138.16666666666666
avg_envstep_per_sec: 493.908258782328
avg_train_sample_per_sec: 493.908258782328
avg_episode_per_sec: 3.5747280490880193
collect_time: 1.6784493582751598
reward_mean: 644.0
reward_std: 244.40403747558594
reward_max: 1028.0
reward_min: 222.0
total_envstep_count: 237067
total_train_sample_count: 237025
total_episode_count: 1450
total_duration: 466.6932855252482
[2022-12-21 15:29:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1292
train_sample_count: 1292
avg_envstep_per_episode: 215.33333333333334
avg_sample_per_episode: 215.33333333333334
avg_envstep_per_sec: 486.6100458794396
avg_train_sample_per_sec: 486.6100458794396
avg_episode_per_sec: 2.25979897467232
collect_time: 2.655103426122239
reward_mean: 951.3333129882812
reward_std: 365.0852355957031
reward_max: 1314.0
reward_min: 231.0
total_envstep_count: 238053
total_train_sample_count: 238005
total_episode_count: 1456
total_duration: 469.34838895137045
[2022-12-21 15:30:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 547
train_sample_count: 547
avg_envstep_per_episode: 136.75
avg_sample_per_episode: 136.75
avg_envstep_per_sec: 478.4067886201774
avg_train_sample_per_sec: 478.4067886201774
avg_episode_per_sec: 3.4984043043523028
collect_time: 1.1433784239928104
reward_mean: 654.5
reward_std: 286.64306640625
reward_max: 1027.0
reward_min: 231.0
total_envstep_count: 239025
total_train_sample_count: 238996
total_episode_count: 1460
total_duration: 470.4917673753633
[2022-12-21 15:30:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1416
train_sample_count: 1416
avg_envstep_per_episode: 177.0
avg_sample_per_episode: 177.0
avg_envstep_per_sec: 492.00608244062806
avg_train_sample_per_sec: 492.00608244062806
avg_episode_per_sec: 2.7796953810204976
collect_time: 2.8780132005194736
reward_mean: 938.0
reward_std: 384.7684326171875
reward_max: 1827.0
reward_min: 605.0
total_envstep_count: 240068
total_train_sample_count: 240040
total_episode_count: 1468
total_duration: 473.36978057588277
[2022-12-21 15:30:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 774
train_sample_count: 774
avg_envstep_per_episode: 96.75
avg_sample_per_episode: 96.75
avg_envstep_per_sec: 501.0967705191925
avg_train_sample_per_sec: 501.0967705191925
avg_episode_per_sec: 5.1792947857280875
collect_time: 1.5446118305612888
reward_mean: 504.875
reward_std: 354.54669189453125
reward_max: 1322.0
reward_min: 223.0
total_envstep_count: 241095
total_train_sample_count: 241066
total_episode_count: 1476
total_duration: 474.91439240644405
[2022-12-21 15:30:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1368
train_sample_count: 1368
avg_envstep_per_episode: 136.8
avg_sample_per_episode: 136.8
avg_envstep_per_sec: 495.5512169901719
avg_train_sample_per_sec: 495.5512169901719
avg_episode_per_sec: 3.6224504165948237
collect_time: 2.760562285183796
reward_mean: 681.7999877929688
reward_std: 340.396484375
reward_max: 1047.0
reward_min: 215.0
total_envstep_count: 242128
total_train_sample_count: 242086
total_episode_count: 1486
total_duration: 477.6749546916279
[2022-12-21 15:30:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 811
train_sample_count: 811
avg_envstep_per_episode: 202.75
avg_sample_per_episode: 202.75
avg_envstep_per_sec: 502.24274691669956
avg_train_sample_per_sec: 502.24274691669956
avg_episode_per_sec: 2.477152882449813
collect_time: 1.6147570173562107
reward_mean: 1066.75
reward_std: 276.1062927246094
reward_max: 1310.0
reward_min: 626.0
total_envstep_count: 243126
total_train_sample_count: 243101
total_episode_count: 1490
total_duration: 479.2897117089841
[2022-12-21 15:30:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 822
train_sample_count: 822
avg_envstep_per_episode: 137.0
avg_sample_per_episode: 137.0
avg_envstep_per_sec: 505.9820244366913
avg_train_sample_per_sec: 505.9820244366913
avg_episode_per_sec: 3.6932994484430024
collect_time: 1.6245636411987774
reward_mean: 615.8333129882812
reward_std: 183.26702880859375
reward_max: 773.0
reward_min: 231.0
total_envstep_count: 244154
total_train_sample_count: 244115
total_episode_count: 1496
total_duration: 480.9142753501829
[2022-12-21 15:30:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1540
train_sample_count: 1540
avg_envstep_per_episode: 192.5
avg_sample_per_episode: 192.5
avg_envstep_per_sec: 509.552620519965
avg_train_sample_per_sec: 509.552620519965
avg_episode_per_sec: 2.647026600103714
collect_time: 3.022259013070193
reward_mean: 919.625
reward_std: 269.6933288574219
reward_max: 1309.0
reward_min: 595.0
total_envstep_count: 245162
total_train_sample_count: 245127
total_episode_count: 1504
total_duration: 483.9365343632531
[2022-12-21 15:30:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 372
train_sample_count: 372
avg_envstep_per_episode: 186.0
avg_sample_per_episode: 186.0
avg_envstep_per_sec: 504.5878384898268
avg_train_sample_per_sec: 504.5878384898268
avg_episode_per_sec: 2.712837841343155
collect_time: 0.7372353664197557
reward_mean: 1041.0
reward_std: 2.0
reward_max: 1043.0
reward_min: 1039.0
total_envstep_count: 246136
total_train_sample_count: 246111
total_episode_count: 1506
total_duration: 484.67376972967287
[2022-12-21 15:30:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 867
train_sample_count: 867
avg_envstep_per_episode: 216.75
avg_sample_per_episode: 216.75
avg_envstep_per_sec: 504.38014353232995
avg_train_sample_per_sec: 504.38014353232995
avg_episode_per_sec: 2.3270133496301266
collect_time: 1.7189415783264805
reward_mean: 969.0
reward_std: 224.10153198242188
reward_max: 1311.0
reward_min: 764.0
total_envstep_count: 247132
total_train_sample_count: 247086
total_episode_count: 1510
total_duration: 486.3927113079994
[2022-12-21 15:30:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1044
train_sample_count: 1044
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 507.3545223728597
avg_train_sample_per_sec: 507.3545223728597
avg_episode_per_sec: 1.9438870588998456
collect_time: 2.0577327173852495
reward_mean: 1049.0
reward_std: 276.3177490234375
reward_max: 1296.0
reward_min: 612.0
total_envstep_count: 248104
total_train_sample_count: 248070
total_episode_count: 1514
total_duration: 488.4504440253846
[2022-12-21 15:30:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1074
train_sample_count: 1074
avg_envstep_per_episode: 214.8
avg_sample_per_episode: 214.8
avg_envstep_per_sec: 495.0767689214536
avg_train_sample_per_sec: 495.0767689214536
avg_episode_per_sec: 2.304826670956488
collect_time: 2.1693605263275755
reward_mean: 1078.5999755859375
reward_std: 309.669921875
reward_max: 1542.0
reward_min: 707.0
total_envstep_count: 249109
total_train_sample_count: 249084
total_episode_count: 1519
total_duration: 490.6198045517122
[2022-12-21 15:31:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 935
train_sample_count: 935
avg_envstep_per_episode: 311.6666666666667
avg_sample_per_episode: 311.6666666666667
avg_envstep_per_sec: 493.6928666493404
avg_train_sample_per_sec: 493.6928666493404
avg_episode_per_sec: 1.5840412833668676
collect_time: 1.8938900339917424
reward_mean: 1639.3333740234375
reward_std: 1003.9907836914062
reward_max: 3003.0
reward_min: 615.0
total_envstep_count: 250116
total_train_sample_count: 250079
total_episode_count: 1522
total_duration: 492.51369458570394
[2022-12-21 15:31:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1579
train_sample_count: 1579
avg_envstep_per_episode: 175.44444444444446
avg_sample_per_episode: 175.44444444444446
avg_envstep_per_sec: 496.7621976933044
avg_train_sample_per_sec: 496.7621976933044
avg_episode_per_sec: 2.8314501451803293
collect_time: 3.178583248347044
reward_mean: 820.2222290039062
reward_std: 408.15814208984375
reward_max: 1302.0
reward_min: 231.0
total_envstep_count: 251142
total_train_sample_count: 251094
total_episode_count: 1531
total_duration: 495.69227783405097
[2022-12-21 15:31:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 694
train_sample_count: 694
avg_envstep_per_episode: 138.8
avg_sample_per_episode: 138.8
avg_envstep_per_sec: 510.20241635894126
avg_train_sample_per_sec: 510.20241635894126
avg_episode_per_sec: 3.6758099161307007
collect_time: 1.360244439751442
reward_mean: 626.7999877929688
reward_std: 358.8612060546875
reward_max: 1042.0
reward_min: 231.0
total_envstep_count: 252122
total_train_sample_count: 252076
total_episode_count: 1536
total_duration: 497.0525222738024
[2022-12-21 15:31:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1404
train_sample_count: 1404
avg_envstep_per_episode: 156.0
avg_sample_per_episode: 156.0
avg_envstep_per_sec: 509.84150120339586
avg_train_sample_per_sec: 509.84150120339586
avg_episode_per_sec: 3.2682147513038196
collect_time: 2.753797006885654
reward_mean: 754.5555419921875
reward_std: 249.82351684570312
reward_max: 1036.0
reward_min: 223.0
total_envstep_count: 253075
total_train_sample_count: 253048
total_episode_count: 1545
total_duration: 499.80631928068806
[2022-12-21 15:31:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 464
train_sample_count: 464
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 499.4042213026433
avg_train_sample_per_sec: 499.4042213026433
avg_episode_per_sec: 4.305208804333132
collect_time: 0.9291070844169176
reward_mean: 629.25
reward_std: 283.5633850097656
reward_max: 1033.0
reward_min: 231.0
total_envstep_count: 254056
total_train_sample_count: 254028
total_episode_count: 1549
total_duration: 500.73542636510496
[2022-12-21 15:31:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1228
train_sample_count: 1228
avg_envstep_per_episode: 204.66666666666666
avg_sample_per_episode: 204.66666666666666
avg_envstep_per_sec: 510.2197329787473
avg_train_sample_per_sec: 510.2197329787473
avg_episode_per_sec: 2.492930291427104
collect_time: 2.4068061672776406
reward_mean: 1031.6666259765625
reward_std: 170.2259979248047
reward_max: 1315.0
reward_min: 726.0
total_envstep_count: 255042
total_train_sample_count: 255004
total_episode_count: 1555
total_duration: 503.1422325323826
[2022-12-21 15:31:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 875
train_sample_count: 875
avg_envstep_per_episode: 125.0
avg_sample_per_episode: 125.0
avg_envstep_per_sec: 526.0660383606127
avg_train_sample_per_sec: 526.0660383606127
avg_episode_per_sec: 4.208528306884901
collect_time: 1.6632892758612121
reward_mean: 619.7142944335938
reward_std: 305.18927001953125
reward_max: 1033.0
reward_min: 223.0
total_envstep_count: 256045
total_train_sample_count: 255999
total_episode_count: 1562
total_duration: 504.8055218082438
[2022-12-21 15:31:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1040
train_sample_count: 1040
avg_envstep_per_episode: 173.33333333333334
avg_sample_per_episode: 173.33333333333334
avg_envstep_per_sec: 514.7804304915388
avg_train_sample_per_sec: 514.7804304915388
avg_episode_per_sec: 2.969887098989647
collect_time: 2.020278818693544
reward_mean: 847.0
reward_std: 305.7558898925781
reward_max: 1042.0
reward_min: 215.0
total_envstep_count: 257039
total_train_sample_count: 256991
total_episode_count: 1568
total_duration: 506.82580062693734
[2022-12-21 15:31:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1011
train_sample_count: 1011
avg_envstep_per_episode: 144.42857142857142
avg_sample_per_episode: 144.42857142857142
avg_envstep_per_sec: 508.0162008404796
avg_train_sample_per_sec: 508.0162008404796
avg_episode_per_sec: 3.517421766452381
collect_time: 1.990094013394389
reward_mean: 727.7142944335938
reward_std: 195.03237915039062
reward_max: 1041.0
reward_min: 591.0
total_envstep_count: 258018
total_train_sample_count: 257990
total_episode_count: 1575
total_duration: 508.81589464033175
[2022-12-21 15:32:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 623
train_sample_count: 623
avg_envstep_per_episode: 155.75
avg_sample_per_episode: 155.75
avg_envstep_per_sec: 493.7116156534524
avg_train_sample_per_sec: 493.7116156534524
avg_episode_per_sec: 3.1698980138263395
collect_time: 1.2618702502581955
reward_mean: 836.0
reward_std: 353.91876220703125
reward_max: 1042.0
reward_min: 223.0
total_envstep_count: 259031
total_train_sample_count: 258985
total_episode_count: 1579
total_duration: 510.07776489058995
[2022-12-21 15:32:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1393
train_sample_count: 1393
avg_envstep_per_episode: 174.125
avg_sample_per_episode: 174.125
avg_envstep_per_sec: 497.5030091503908
avg_train_sample_per_sec: 497.5030091503908
avg_episode_per_sec: 2.8571601386957117
collect_time: 2.7999830641806396
reward_mean: 846.125
reward_std: 408.06903076171875
reward_max: 1309.0
reward_min: 231.0
total_envstep_count: 259983
total_train_sample_count: 259970
total_episode_count: 1587
total_duration: 512.8777479547706
[2022-12-21 15:32:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 483
train_sample_count: 483
avg_envstep_per_episode: 120.75
avg_sample_per_episode: 120.75
avg_envstep_per_sec: 507.2416789323033
avg_train_sample_per_sec: 507.2416789323033
avg_episode_per_sec: 4.200759245816176
collect_time: 0.9522088189138366
reward_mean: 628.25
reward_std: 405.3019714355469
reward_max: 1038.0
reward_min: 215.0
total_envstep_count: 261005
total_train_sample_count: 260957
total_episode_count: 1591
total_duration: 513.8299567736844
[2022-12-21 15:32:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1865
train_sample_count: 1865
avg_envstep_per_episode: 155.41666666666666
avg_sample_per_episode: 155.41666666666666
avg_envstep_per_sec: 492.8129002255053
avg_train_sample_per_sec: 492.8129002255053
avg_episode_per_sec: 3.170914103327648
collect_time: 3.784397687533338
reward_mean: 790.5833129882812
reward_std: 383.81036376953125
reward_max: 1305.0
reward_min: 223.0
total_envstep_count: 262011
total_train_sample_count: 261970
total_episode_count: 1603
total_duration: 517.6143544612178
[2022-12-21 15:32:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 521
train_sample_count: 521
avg_envstep_per_episode: 86.83333333333333
avg_sample_per_episode: 86.83333333333333
avg_envstep_per_sec: 499.03200585575996
avg_train_sample_per_sec: 499.03200585575996
avg_episode_per_sec: 5.747009664365757
collect_time: 1.044021212840985
reward_mean: 486.3333435058594
reward_std: 180.753662109375
reward_max: 628.0
reward_min: 231.0
total_envstep_count: 263005
total_train_sample_count: 262983
total_episode_count: 1609
total_duration: 518.6583756740588
[2022-12-21 15:32:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 767
train_sample_count: 767
avg_envstep_per_episode: 127.83333333333333
avg_sample_per_episode: 127.83333333333333
avg_envstep_per_sec: 507.09266788824436
avg_train_sample_per_sec: 507.09266788824436
avg_episode_per_sec: 3.9668266066877003
collect_time: 1.512544054707246
reward_mean: 667.8333129882812
reward_std: 392.70745849609375
reward_max: 1304.0
reward_min: 231.0
total_envstep_count: 264002
total_train_sample_count: 263966
total_episode_count: 1615
total_duration: 520.1709197287661
[2022-12-21 15:32:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1213
train_sample_count: 1213
avg_envstep_per_episode: 151.625
avg_sample_per_episode: 151.625
avg_envstep_per_sec: 514.7920763097529
avg_train_sample_per_sec: 514.7920763097529
avg_episode_per_sec: 3.3951662081434653
collect_time: 2.35629112377816
reward_mean: 729.5
reward_std: 331.52301025390625
reward_max: 1034.0
reward_min: 231.0
total_envstep_count: 265003
total_train_sample_count: 264951
total_episode_count: 1623
total_duration: 522.5272108525443
[2022-12-21 15:32:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 799
train_sample_count: 799
avg_envstep_per_episode: 266.3333333333333
avg_sample_per_episode: 266.3333333333333
avg_envstep_per_sec: 515.787087163815
avg_train_sample_per_sec: 515.787087163815
avg_episode_per_sec: 1.936622354807816
collect_time: 1.5490888001743168
reward_mean: 1390.6666259765625
reward_std: 329.6809997558594
reward_max: 1824.0
reward_min: 1025.0
total_envstep_count: 265960
total_train_sample_count: 265930
total_episode_count: 1626
total_duration: 524.0762996527186
[2022-12-21 15:32:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 976
train_sample_count: 976
avg_envstep_per_episode: 139.42857142857142
avg_sample_per_episode: 139.42857142857142
avg_envstep_per_sec: 512.1692753502907
avg_train_sample_per_sec: 512.1692753502907
avg_episode_per_sec: 3.6733452125533144
collect_time: 1.905619971702674
reward_mean: 688.4285888671875
reward_std: 425.5647888183594
reward_max: 1306.0
reward_min: 222.0
total_envstep_count: 267010
total_train_sample_count: 266954
total_episode_count: 1633
total_duration: 525.9819196244213
[2022-12-21 15:32:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1684
train_sample_count: 1684
avg_envstep_per_episode: 210.5
avg_sample_per_episode: 210.5
avg_envstep_per_sec: 496.806876764024
avg_train_sample_per_sec: 496.806876764024
avg_episode_per_sec: 2.360127680589188
collect_time: 3.3896471219738675
reward_mean: 1070.625
reward_std: 377.384033203125
reward_max: 1883.0
reward_min: 599.0
total_envstep_count: 268052
total_train_sample_count: 267990
total_episode_count: 1641
total_duration: 529.3715667463952
[2022-12-21 15:32:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 442
train_sample_count: 442
avg_envstep_per_episode: 221.0
avg_sample_per_episode: 221.0
avg_envstep_per_sec: 505.47272798174555
avg_train_sample_per_sec: 505.47272798174555
avg_episode_per_sec: 2.28720691394455
collect_time: 0.8744289761483675
reward_mean: 1034.0
reward_std: 7.0
reward_max: 1041.0
reward_min: 1027.0
total_envstep_count: 269011
total_train_sample_count: 268960
total_episode_count: 1643
total_duration: 530.2459957225435
[2022-12-21 15:32:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1274
train_sample_count: 1274
avg_envstep_per_episode: 182.0
avg_sample_per_episode: 182.0
avg_envstep_per_sec: 508.02830550467166
avg_train_sample_per_sec: 508.02830550467166
avg_episode_per_sec: 2.7913643159597346
collect_time: 2.507734286054037
reward_mean: 941.4285888671875
reward_std: 432.4761962890625
reward_max: 1408.0
reward_min: 231.0
total_envstep_count: 270005
total_train_sample_count: 269958
total_episode_count: 1650
total_duration: 532.7537300085976
[2022-12-21 15:32:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 545
train_sample_count: 545
avg_envstep_per_episode: 136.25
avg_sample_per_episode: 136.25
avg_envstep_per_sec: 485.4686338460743
avg_train_sample_per_sec: 485.4686338460743
avg_episode_per_sec: 3.563072541989536
collect_time: 1.122626596248443
reward_mean: 592.0
reward_std: 433.4576110839844
reward_max: 1287.0
reward_min: 222.0
total_envstep_count: 270969
total_train_sample_count: 270923
total_episode_count: 1654
total_duration: 533.876356604846
[2022-12-21 15:32:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1305
train_sample_count: 1305
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 485.74432678264486
avg_train_sample_per_sec: 485.74432678264486
avg_episode_per_sec: 1.861089374646149
collect_time: 2.686598541754963
reward_mean: 1402.199951171875
reward_std: 475.53228759765625
reward_max: 2323.0
reward_min: 1034.0
total_envstep_count: 271940
total_train_sample_count: 271904
total_episode_count: 1659
total_duration: 536.562955146601
[2022-12-21 15:32:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 952
train_sample_count: 952
avg_envstep_per_episode: 136.0
avg_sample_per_episode: 136.0
avg_envstep_per_sec: 500.21585810847637
avg_train_sample_per_sec: 500.21585810847637
avg_episode_per_sec: 3.678057780209385
collect_time: 1.9031783670351974
reward_mean: 711.7142944335938
reward_std: 373.6796569824219
reward_max: 1325.0
reward_min: 218.0
total_envstep_count: 272942
total_train_sample_count: 272904
total_episode_count: 1666
total_duration: 538.4661335136362
[2022-12-21 15:32:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1142
train_sample_count: 1142
avg_envstep_per_episode: 126.88888888888889
avg_sample_per_episode: 126.88888888888889
avg_envstep_per_sec: 490.5565200898359
avg_train_sample_per_sec: 490.5565200898359
avg_episode_per_sec: 3.8660321197973055
collect_time: 2.3279682426621604
reward_mean: 708.0
reward_std: 411.3717041015625
reward_max: 1664.0
reward_min: 223.0
total_envstep_count: 273952
total_train_sample_count: 273914
total_episode_count: 1675
total_duration: 540.7941017562983
[2022-12-21 15:32:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 960
train_sample_count: 960
avg_envstep_per_episode: 106.66666666666667
avg_sample_per_episode: 106.66666666666667
avg_envstep_per_sec: 497.9074217861009
avg_train_sample_per_sec: 497.9074217861009
avg_episode_per_sec: 4.667882079244696
collect_time: 1.9280692715048788
reward_mean: 576.7777709960938
reward_std: 228.7860565185547
reward_max: 1041.0
reward_min: 222.0
total_envstep_count: 274947
total_train_sample_count: 274910
total_episode_count: 1684
total_duration: 542.7221710278033
[2022-12-21 15:32:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1038
train_sample_count: 1038
avg_envstep_per_episode: 148.28571428571428
avg_sample_per_episode: 148.28571428571428
avg_envstep_per_sec: 485.7971414214271
avg_train_sample_per_sec: 485.7971414214271
avg_episode_per_sec: 3.276088622302495
collect_time: 2.1366943349292766
reward_mean: 739.4285888671875
reward_std: 316.18206787109375
reward_max: 1295.0
reward_min: 231.0
total_envstep_count: 275966
total_train_sample_count: 275924
total_episode_count: 1691
total_duration: 544.8588653627326
[2022-12-21 15:32:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 631
train_sample_count: 631
avg_envstep_per_episode: 157.75
avg_sample_per_episode: 157.75
avg_envstep_per_sec: 505.95445165563274
avg_train_sample_per_sec: 505.95445165563274
avg_episode_per_sec: 3.2073182355349146
collect_time: 1.24714783699438
reward_mean: 896.0
reward_std: 293.6043395996094
reward_max: 1312.0
reward_min: 613.0
total_envstep_count: 276946
total_train_sample_count: 276915
total_episode_count: 1695
total_duration: 546.1060131997269
[2022-12-21 15:33:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1079
train_sample_count: 1079
avg_envstep_per_episode: 215.8
avg_sample_per_episode: 215.8
avg_envstep_per_sec: 497.96960521127403
avg_train_sample_per_sec: 497.96960521127403
avg_episode_per_sec: 2.3075514606639205
collect_time: 2.1667989144482256
reward_mean: 1072.199951171875
reward_std: 469.4202575683594
reward_max: 1888.0
reward_min: 602.0
total_envstep_count: 277967
total_train_sample_count: 277922
total_episode_count: 1700
total_duration: 548.2728121141752
[2022-12-21 15:33:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1110
train_sample_count: 1110
avg_envstep_per_episode: 185.0
avg_sample_per_episode: 185.0
avg_envstep_per_sec: 492.2554127217679
avg_train_sample_per_sec: 492.2554127217679
avg_episode_per_sec: 2.660840068766313
collect_time: 2.2549269572529678
reward_mean: 903.3333129882812
reward_std: 279.59832763671875
reward_max: 1394.0
reward_min: 607.0
total_envstep_count: 278980
total_train_sample_count: 278948
total_episode_count: 1706
total_duration: 550.5277390714282
[2022-12-21 15:33:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1234
train_sample_count: 1234
avg_envstep_per_episode: 154.25
avg_sample_per_episode: 154.25
avg_envstep_per_sec: 496.21500364146493
avg_train_sample_per_sec: 496.21500364146493
avg_episode_per_sec: 3.2169530219868063
collect_time: 2.486825249023736
reward_mean: 687.5
reward_std: 313.110595703125
reward_max: 1039.0
reward_min: 231.0
total_envstep_count: 279952
total_train_sample_count: 279930
total_episode_count: 1714
total_duration: 553.0145643204519
[2022-12-21 15:33:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 724
train_sample_count: 724
avg_envstep_per_episode: 120.66666666666667
avg_sample_per_episode: 120.66666666666667
avg_envstep_per_sec: 497.06780196795563
avg_train_sample_per_sec: 497.06780196795563
avg_episode_per_sec: 4.1193464251488034
collect_time: 1.456541737633358
reward_mean: 642.5
reward_std: 235.1947784423828
reward_max: 1037.0
reward_min: 231.0
total_envstep_count: 280962
total_train_sample_count: 280930
total_episode_count: 1720
total_duration: 554.4711060580852
[2022-12-21 15:33:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1076
train_sample_count: 1076
avg_envstep_per_episode: 179.33333333333334
avg_sample_per_episode: 179.33333333333334
avg_envstep_per_sec: 496.0763288266986
avg_train_sample_per_sec: 496.0763288266986
avg_episode_per_sec: 2.7662248819332635
collect_time: 2.169021050742162
reward_mean: 1016.6666870117188
reward_std: 468.1903381347656
reward_max: 1889.0
reward_min: 614.0
total_envstep_count: 282013
total_train_sample_count: 281970
total_episode_count: 1726
total_duration: 556.6401271088273
[2022-12-21 15:33:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1133
train_sample_count: 1133
avg_envstep_per_episode: 141.625
avg_sample_per_episode: 141.625
avg_envstep_per_sec: 500.7625181623834
avg_train_sample_per_sec: 500.7625181623834
avg_episode_per_sec: 3.5358341970865554
collect_time: 2.2625495297805007
reward_mean: 674.5
reward_std: 317.9783935546875
reward_max: 1042.0
reward_min: 223.0
total_envstep_count: 283049
total_train_sample_count: 282995
total_episode_count: 1734
total_duration: 558.9026766386078
[2022-12-21 15:33:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1250
train_sample_count: 1250
avg_envstep_per_episode: 178.57142857142858
avg_sample_per_episode: 178.57142857142858
avg_envstep_per_sec: 488.3644120382014
avg_train_sample_per_sec: 488.3644120382014
avg_episode_per_sec: 2.7348407074139276
collect_time: 2.5595640656596843
reward_mean: 874.0
reward_std: 374.0202331542969
reward_max: 1310.0
reward_min: 226.0
total_envstep_count: 284067
total_train_sample_count: 284017
total_episode_count: 1741
total_duration: 561.4622407042674
[2022-12-21 15:33:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1015
train_sample_count: 1015
avg_envstep_per_episode: 169.16666666666666
avg_sample_per_episode: 169.16666666666666
avg_envstep_per_sec: 507.02721258874504
avg_train_sample_per_sec: 507.02721258874504
avg_episode_per_sec: 2.997205197568936
collect_time: 2.0018649389993923
reward_mean: 910.6666870117188
reward_std: 246.6621551513672
reward_max: 1313.0
reward_min: 577.0
total_envstep_count: 285037
total_train_sample_count: 284996
total_episode_count: 1747
total_duration: 563.4641056432667
[2022-12-21 15:33:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 671
train_sample_count: 671
avg_envstep_per_episode: 134.2
avg_sample_per_episode: 134.2
avg_envstep_per_sec: 499.78476306629466
avg_train_sample_per_sec: 499.78476306629466
avg_episode_per_sec: 3.724178562341987
collect_time: 1.342577944720164
reward_mean: 646.2000122070312
reward_std: 262.05145263671875
reward_max: 1030.0
reward_min: 231.0
total_envstep_count: 286004
total_train_sample_count: 285979
total_episode_count: 1752
total_duration: 564.8066835879869
[2022-12-21 15:34:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 901
train_sample_count: 901
avg_envstep_per_episode: 100.11111111111111
avg_sample_per_episode: 100.11111111111111
avg_envstep_per_sec: 496.34098580176817
avg_train_sample_per_sec: 496.34098580176817
avg_episode_per_sec: 4.957901079040969
collect_time: 1.8152843020702045
reward_mean: 522.5555419921875
reward_std: 337.7514343261719
reward_max: 1321.0
reward_min: 217.0
total_envstep_count: 286997
total_train_sample_count: 286976
total_episode_count: 1761
total_duration: 566.621967890057
[2022-12-21 15:34:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1293
train_sample_count: 1293
avg_envstep_per_episode: 143.66666666666666
avg_sample_per_episode: 143.66666666666666
avg_envstep_per_sec: 494.70548160167243
avg_train_sample_per_sec: 494.70548160167243
avg_episode_per_sec: 3.44342562599772
collect_time: 2.613676314670593
reward_mean: 814.6666870117188
reward_std: 415.5606689453125
reward_max: 1672.0
reward_min: 231.0
total_envstep_count: 288014
total_train_sample_count: 287957
total_episode_count: 1770
total_duration: 569.2356442047276
[2022-12-21 15:34:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 729
train_sample_count: 729
avg_envstep_per_episode: 182.25
avg_sample_per_episode: 182.25
avg_envstep_per_sec: 488.7541426937102
avg_train_sample_per_sec: 488.7541426937102
avg_episode_per_sec: 2.6817785607336635
collect_time: 1.4915474597968692
reward_mean: 1004.25
reward_std: 254.77281188964844
reward_max: 1324.0
reward_min: 611.0
total_envstep_count: 288979
total_train_sample_count: 288926
total_episode_count: 1774
total_duration: 570.7271916645244
[2022-12-21 15:34:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1253
train_sample_count: 1253
avg_envstep_per_episode: 156.625
avg_sample_per_episode: 156.625
avg_envstep_per_sec: 502.4094481826988
avg_train_sample_per_sec: 502.4094481826988
avg_episode_per_sec: 3.207721935723536
collect_time: 2.493981760359635
reward_mean: 795.875
reward_std: 282.2243957519531
reward_max: 1047.0
reward_min: 223.0
total_envstep_count: 289967
total_train_sample_count: 289927
total_episode_count: 1782
total_duration: 573.221173424884
[2022-12-21 15:34:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 951
train_sample_count: 951
avg_envstep_per_episode: 118.875
avg_sample_per_episode: 118.875
avg_envstep_per_sec: 485.72263073755335
avg_train_sample_per_sec: 485.72263073755335
avg_episode_per_sec: 4.0859947906418785
collect_time: 1.957907537797732
reward_mean: 655.0
reward_std: 354.80169677734375
reward_max: 1047.0
reward_min: 231.0
total_envstep_count: 290953
total_train_sample_count: 290902
total_episode_count: 1790
total_duration: 575.1790809626817
[2022-12-21 15:34:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1066
train_sample_count: 1066
avg_envstep_per_episode: 118.44444444444444
avg_sample_per_episode: 118.44444444444444
avg_envstep_per_sec: 501.803731717679
avg_train_sample_per_sec: 501.803731717679
avg_episode_per_sec: 4.2366168719128625
collect_time: 2.1243365336305327
reward_mean: 644.111083984375
reward_std: 277.3431396484375
reward_max: 1047.0
reward_min: 223.0
total_envstep_count: 291944
total_train_sample_count: 291908
total_episode_count: 1799
total_duration: 577.3034174963122
[2022-12-21 15:34:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1002
train_sample_count: 1002
avg_envstep_per_episode: 143.14285714285714
avg_sample_per_episode: 143.14285714285714
avg_envstep_per_sec: 510.61755514558104
avg_train_sample_per_sec: 510.61755514558104
avg_episode_per_sec: 3.567188509001065
collect_time: 1.962329712135185
reward_mean: 767.0
reward_std: 173.96141052246094
reward_max: 1038.0
reward_min: 607.0
total_envstep_count: 292954
total_train_sample_count: 292922
total_episode_count: 1806
total_duration: 579.2657472084475
[2022-12-21 15:34:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 602
train_sample_count: 602
avg_envstep_per_episode: 120.4
avg_sample_per_episode: 120.4
avg_envstep_per_sec: 502.1046460154997
avg_train_sample_per_sec: 502.1046460154997
avg_episode_per_sec: 4.170304368899499
collect_time: 1.1989532556155964
reward_mean: 622.4000244140625
reward_std: 254.87298583984375
reward_max: 1036.0
reward_min: 231.0
total_envstep_count: 293943
total_train_sample_count: 293908
total_episode_count: 1811
total_duration: 580.4647004640631
[2022-12-21 15:34:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1191
train_sample_count: 1191
avg_envstep_per_episode: 198.5
avg_sample_per_episode: 198.5
avg_envstep_per_sec: 504.7097527729222
avg_train_sample_per_sec: 504.7097527729222
avg_episode_per_sec: 2.542618401878701
collect_time: 2.3597721134900516
reward_mean: 1081.3333740234375
reward_std: 327.7665100097656
reward_max: 1324.0
reward_min: 609.0
total_envstep_count: 294931
total_train_sample_count: 294895
total_episode_count: 1817
total_duration: 582.8244725775531
[2022-12-21 15:34:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 414
train_sample_count: 414
avg_envstep_per_episode: 138.0
avg_sample_per_episode: 138.0
avg_envstep_per_sec: 505.7923297352235
avg_train_sample_per_sec: 505.7923297352235
avg_episode_per_sec: 3.6651618096755327
collect_time: 0.8185177505889112
reward_mean: 755.3333129882812
reward_std: 195.63967895507812
reward_max: 1032.0
reward_min: 615.0
total_envstep_count: 295944
total_train_sample_count: 295909
total_episode_count: 1820
total_duration: 583.6429903281421
[2022-12-21 15:34:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1507
train_sample_count: 1507
avg_envstep_per_episode: 167.44444444444446
avg_sample_per_episode: 167.44444444444446
avg_envstep_per_sec: 511.95941631180733
avg_train_sample_per_sec: 511.95941631180733
avg_episode_per_sec: 3.057488219513116
collect_time: 2.9435926989223815
reward_mean: 818.7777709960938
reward_std: 378.21502685546875
reward_max: 1302.0
reward_min: 231.0
total_envstep_count: 296986
total_train_sample_count: 296936
total_episode_count: 1829
total_duration: 586.5865830270645
[2022-12-21 15:34:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1007
train_sample_count: 1007
avg_envstep_per_episode: 251.75
avg_sample_per_episode: 251.75
avg_envstep_per_sec: 512.5989559344492
avg_train_sample_per_sec: 512.5989559344492
avg_episode_per_sec: 2.0361428239700072
collect_time: 1.964498734033267
reward_mean: 1235.0
reward_std: 797.18408203125
reward_max: 2592.0
reward_min: 626.0
total_envstep_count: 297975
total_train_sample_count: 297943
total_episode_count: 1833
total_duration: 588.5510817610977
[2022-12-21 15:34:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 959
train_sample_count: 959
avg_envstep_per_episode: 159.83333333333334
avg_sample_per_episode: 159.83333333333334
avg_envstep_per_sec: 504.03829289280236
avg_train_sample_per_sec: 504.03829289280236
avg_episode_per_sec: 3.15352425167551
collect_time: 1.9026332195834925
reward_mean: 849.0
reward_std: 300.9136047363281
reward_max: 1045.0
reward_min: 231.0
total_envstep_count: 298962
total_train_sample_count: 298914
total_episode_count: 1839
total_duration: 590.4537149806813
[2022-12-21 15:34:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 910
train_sample_count: 910
avg_envstep_per_episode: 182.0
avg_sample_per_episode: 182.0
avg_envstep_per_sec: 497.77799188556094
avg_train_sample_per_sec: 497.77799188556094
avg_episode_per_sec: 2.735043911459126
collect_time: 1.8281242136739722
reward_mean: 896.4000244140625
reward_std: 418.6342468261719
reward_max: 1310.0
reward_min: 231.0
total_envstep_count: 299918
total_train_sample_count: 299884
total_episode_count: 1844
total_duration: 592.2818391943553
[2022-12-21 15:34:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1326
train_sample_count: 1326
avg_envstep_per_episode: 189.42857142857142
avg_sample_per_episode: 189.42857142857142
avg_envstep_per_sec: 496.26350667530045
avg_train_sample_per_sec: 496.26350667530045
avg_episode_per_sec: 2.619792267516669
collect_time: 2.6719675780383074
reward_mean: 937.0
reward_std: 163.74195861816406
reward_max: 1044.0
reward_min: 606.0
total_envstep_count: 300913
total_train_sample_count: 300874
total_episode_count: 1851
total_duration: 594.9538067723936
[2022-12-21 15:34:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 687
train_sample_count: 687
avg_envstep_per_episode: 171.75
avg_sample_per_episode: 171.75
avg_envstep_per_sec: 502.691738347628
avg_train_sample_per_sec: 502.691738347628
avg_episode_per_sec: 2.9268805726208327
collect_time: 1.3666427108155828
reward_mean: 792.75
reward_std: 150.56622314453125
reward_max: 1035.0
reward_min: 621.0
total_envstep_count: 301917
total_train_sample_count: 301873
total_episode_count: 1855
total_duration: 596.3204494832091
[2022-12-21 15:34:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1288
train_sample_count: 1288
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 496.67612344548246
avg_train_sample_per_sec: 496.67612344548246
avg_episode_per_sec: 3.0849448661210093
collect_time: 2.593239214047657
reward_mean: 809.625
reward_std: 326.8355712890625
reward_max: 1301.0
reward_min: 231.0
total_envstep_count: 302917
total_train_sample_count: 302873
total_episode_count: 1863
total_duration: 598.9136886972568
[2022-12-21 15:34:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 917
train_sample_count: 917
avg_envstep_per_episode: 131.0
avg_sample_per_episode: 131.0
avg_envstep_per_sec: 505.98173030694363
avg_train_sample_per_sec: 505.98173030694363
avg_episode_per_sec: 3.862455956541554
collect_time: 1.8123184001993915
reward_mean: 628.7142944335938
reward_std: 336.75201416015625
reward_max: 1295.0
reward_min: 231.0
total_envstep_count: 303880
total_train_sample_count: 303850
total_episode_count: 1870
total_duration: 600.7260070974562
[2022-12-21 15:35:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1072
train_sample_count: 1072
avg_envstep_per_episode: 178.66666666666666
avg_sample_per_episode: 178.66666666666666
avg_envstep_per_sec: 490.6789949198035
avg_train_sample_per_sec: 490.6789949198035
avg_episode_per_sec: 2.7463376581332284
collect_time: 2.184727716284671
reward_mean: 879.6666870117188
reward_std: 393.39788818359375
reward_max: 1545.0
reward_min: 571.0
total_envstep_count: 304876
total_train_sample_count: 304838
total_episode_count: 1876
total_duration: 602.9107348137409
[2022-12-21 15:35:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 699
train_sample_count: 699
avg_envstep_per_episode: 139.8
avg_sample_per_episode: 139.8
avg_envstep_per_sec: 493.15370649283057
avg_train_sample_per_sec: 493.15370649283057
avg_episode_per_sec: 3.5275658547412774
collect_time: 1.4174079821301353
reward_mean: 772.4000244140625
reward_std: 452.28912353515625
reward_max: 1308.0
reward_min: 231.0
total_envstep_count: 305871
total_train_sample_count: 305825
total_episode_count: 1881
total_duration: 604.328142795871
[2022-12-21 15:35:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1328
train_sample_count: 1328
avg_envstep_per_episode: 147.55555555555554
avg_sample_per_episode: 147.55555555555554
avg_envstep_per_sec: 502.5961177679577
avg_train_sample_per_sec: 502.5961177679577
avg_episode_per_sec: 3.406148388487665
collect_time: 2.642280656479565
reward_mean: 836.7777709960938
reward_std: 318.46392822265625
reward_max: 1311.0
reward_min: 231.0
total_envstep_count: 306888
total_train_sample_count: 306841
total_episode_count: 1890
total_duration: 606.9704234523506
[2022-12-21 15:35:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 554
train_sample_count: 554
avg_envstep_per_episode: 138.5
avg_sample_per_episode: 138.5
avg_envstep_per_sec: 512.9371063584615
avg_train_sample_per_sec: 512.9371063584615
avg_episode_per_sec: 3.7035170134184945
collect_time: 1.0800544416313724
reward_mean: 756.5
reward_std: 171.4854278564453
reward_max: 1044.0
reward_min: 625.0
total_envstep_count: 307868
total_train_sample_count: 307815
total_episode_count: 1894
total_duration: 608.0504778939819
[2022-12-21 15:35:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1371
train_sample_count: 1371
avg_envstep_per_episode: 152.33333333333334
avg_sample_per_episode: 152.33333333333334
avg_envstep_per_sec: 491.93513953922206
avg_train_sample_per_sec: 491.93513953922206
avg_episode_per_sec: 3.2293335199511293
collect_time: 2.786952770408242
reward_mean: 833.7777709960938
reward_std: 456.96893310546875
reward_max: 1549.0
reward_min: 223.0
total_envstep_count: 308868
total_train_sample_count: 308814
total_episode_count: 1903
total_duration: 610.8374306643901
[2022-12-21 15:35:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 763
train_sample_count: 763
avg_envstep_per_episode: 152.6
avg_sample_per_episode: 152.6
avg_envstep_per_sec: 487.7127795350483
avg_train_sample_per_sec: 487.7127795350483
avg_episode_per_sec: 3.1960208357473676
collect_time: 1.5644453703415184
reward_mean: 736.2000122070312
reward_std: 342.93756103515625
reward_max: 1300.0
reward_min: 231.0
total_envstep_count: 309831
total_train_sample_count: 309793
total_episode_count: 1908
total_duration: 612.4018760347317
[2022-12-21 15:35:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 222.5
avg_sample_per_episode: 222.5
avg_envstep_per_sec: 493.77640583815634
avg_train_sample_per_sec: 493.77640583815634
avg_episode_per_sec: 2.2192198015198037
collect_time: 1.8024352510105814
reward_mean: 1031.5
reward_std: 203.3967742919922
reward_max: 1325.0
reward_min: 750.0
total_envstep_count: 310819
total_train_sample_count: 310779
total_episode_count: 1912
total_duration: 614.2043112857423
[2022-12-21 15:35:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1360
train_sample_count: 1360
avg_envstep_per_episode: 194.28571428571428
avg_sample_per_episode: 194.28571428571428
avg_envstep_per_sec: 500.7424329157448
avg_train_sample_per_sec: 500.7424329157448
avg_episode_per_sec: 2.577350757654569
collect_time: 2.7159671531748026
reward_mean: 1056.7142333984375
reward_std: 218.8931427001953
reward_max: 1318.0
reward_min: 605.0
total_envstep_count: 311830
total_train_sample_count: 311791
total_episode_count: 1919
total_duration: 616.9202784389171
[2022-12-21 15:35:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 639
train_sample_count: 639
avg_envstep_per_episode: 127.8
avg_sample_per_episode: 127.8
avg_envstep_per_sec: 501.3911517611853
avg_train_sample_per_sec: 501.3911517611853
avg_episode_per_sec: 3.923248448835566
collect_time: 1.2744540819187777
reward_mean: 647.4000244140625
reward_std: 261.50152587890625
reward_max: 1034.0
reward_min: 231.0
total_envstep_count: 312833
total_train_sample_count: 312790
total_episode_count: 1924
total_duration: 618.1947325208358
[2022-12-21 15:35:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1284
train_sample_count: 1284
avg_envstep_per_episode: 160.5
avg_sample_per_episode: 160.5
avg_envstep_per_sec: 493.66864194905776
avg_train_sample_per_sec: 493.66864194905776
avg_episode_per_sec: 3.0758170837947523
collect_time: 2.600934900241238
reward_mean: 837.25
reward_std: 374.4401550292969
reward_max: 1306.0
reward_min: 231.0
total_envstep_count: 313833
total_train_sample_count: 313786
total_episode_count: 1932
total_duration: 620.795667421077
[2022-12-21 15:35:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 414
train_sample_count: 414
avg_envstep_per_episode: 103.5
avg_sample_per_episode: 103.5
avg_envstep_per_sec: 496.04929054747083
avg_train_sample_per_sec: 496.04929054747083
avg_episode_per_sec: 4.792746768574597
collect_time: 0.8345944806071265
reward_mean: 520.25
reward_std: 167.37887573242188
reward_max: 635.0
reward_min: 231.0
total_envstep_count: 314797
total_train_sample_count: 314764
total_episode_count: 1936
total_duration: 621.6302619016842
[2022-12-21 15:35:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1967
train_sample_count: 1967
avg_envstep_per_episode: 151.30769230769232
avg_sample_per_episode: 151.30769230769232
avg_envstep_per_sec: 506.9730495498967
avg_train_sample_per_sec: 506.9730495498967
avg_episode_per_sec: 3.350609885179795
collect_time: 3.8798906603543357
reward_mean: 706.7692260742188
reward_std: 388.4909973144531
reward_max: 1310.0
reward_min: 226.0
total_envstep_count: 315834
total_train_sample_count: 315795
total_episode_count: 1949
total_duration: 625.5101525620386
[2022-12-21 15:35:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 142
train_sample_count: 142
avg_envstep_per_episode: 71.0
avg_sample_per_episode: 71.0
avg_envstep_per_sec: 528.5072119875493
avg_train_sample_per_sec: 528.5072119875493
avg_episode_per_sec: 7.443763549120413
collect_time: 0.2686812909628663
reward_mean: 424.5
reward_std: 201.5
reward_max: 626.0
reward_min: 223.0
total_envstep_count: 316809
total_train_sample_count: 316765
total_episode_count: 1951
total_duration: 625.7788338530014
[2022-12-21 15:35:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1436
train_sample_count: 1436
avg_envstep_per_episode: 239.33333333333334
avg_sample_per_episode: 239.33333333333334
avg_envstep_per_sec: 514.9679557666585
avg_train_sample_per_sec: 514.9679557666585
avg_episode_per_sec: 2.1516766954038657
collect_time: 2.788523021519184
reward_mean: 1166.0
reward_std: 200.2922821044922
reward_max: 1552.0
reward_min: 1026.0
total_envstep_count: 317803
total_train_sample_count: 317769
total_episode_count: 1957
total_duration: 628.5673568745206
[2022-12-21 15:36:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 560
train_sample_count: 560
avg_envstep_per_episode: 140.0
avg_sample_per_episode: 140.0
avg_envstep_per_sec: 514.7793157585947
avg_train_sample_per_sec: 514.7793157585947
avg_episode_per_sec: 3.676995112561391
collect_time: 1.0878447965120095
reward_mean: 762.0
reward_std: 561.2357177734375
reward_max: 1550.0
reward_min: 231.0
total_envstep_count: 318783
total_train_sample_count: 318749
total_episode_count: 1961
total_duration: 629.6552016710326
[2022-12-21 15:36:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1609
train_sample_count: 1609
avg_envstep_per_episode: 160.9
avg_sample_per_episode: 160.9
avg_envstep_per_sec: 493.64121816293823
avg_train_sample_per_sec: 493.64121816293823
avg_episode_per_sec: 3.0680001128833947
collect_time: 3.259452292067132
reward_mean: 781.2999877929688
reward_std: 392.199951171875
reward_max: 1303.0
reward_min: 231.0
total_envstep_count: 319793
total_train_sample_count: 319758
total_episode_count: 1971
total_duration: 632.9146539630998
[2022-12-21 15:36:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 464
train_sample_count: 464
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 500.7038576358275
avg_train_sample_per_sec: 500.7038576358275
avg_episode_per_sec: 4.316412565826099
collect_time: 0.9266954766253809
reward_mean: 574.5
reward_std: 352.1963195800781
reward_max: 1028.0
reward_min: 231.0
total_envstep_count: 320790
total_train_sample_count: 320750
total_episode_count: 1975
total_duration: 633.8413494397251
[2022-12-21 15:36:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1026
train_sample_count: 1026
avg_envstep_per_episode: 205.2
avg_sample_per_episode: 205.2
avg_envstep_per_sec: 505.15341745086585
avg_train_sample_per_sec: 505.15341745086585
avg_episode_per_sec: 2.461761293620204
collect_time: 2.031066136654999
reward_mean: 1029.0
reward_std: 189.9842071533203
reward_max: 1311.0
reward_min: 712.0
total_envstep_count: 321762
total_train_sample_count: 321740
total_episode_count: 1980
total_duration: 635.8724155763801
[2022-12-21 15:36:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1180
train_sample_count: 1180
avg_envstep_per_episode: 196.66666666666666
avg_sample_per_episode: 196.66666666666666
avg_envstep_per_sec: 495.745306369481
avg_train_sample_per_sec: 495.745306369481
avg_episode_per_sec: 2.5207388459465134
collect_time: 2.3802545073831545
reward_mean: 934.6666870117188
reward_std: 137.84129333496094
reward_max: 1039.0
reward_min: 733.0
total_envstep_count: 322734
total_train_sample_count: 322716
total_episode_count: 1986
total_duration: 638.2526700837633
[2022-12-21 15:36:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 929
train_sample_count: 929
avg_envstep_per_episode: 185.8
avg_sample_per_episode: 185.8
avg_envstep_per_sec: 490.82375142859996
avg_train_sample_per_sec: 490.82375142859996
avg_episode_per_sec: 2.641677887129171
collect_time: 1.8927364401091773
reward_mean: 927.5999755859375
reward_std: 399.2345275878906
reward_max: 1300.0
reward_min: 231.0
total_envstep_count: 323738
total_train_sample_count: 323693
total_episode_count: 1991
total_duration: 640.1454065238725
[2022-12-21 15:36:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 915
train_sample_count: 915
avg_envstep_per_episode: 152.5
avg_sample_per_episode: 152.5
avg_envstep_per_sec: 485.05904673682716
avg_train_sample_per_sec: 485.05904673682716
avg_episode_per_sec: 3.1807150605693586
collect_time: 1.8863682806362354
reward_mean: 776.8333129882812
reward_std: 336.632568359375
reward_max: 1310.0
reward_min: 231.0
total_envstep_count: 324740
total_train_sample_count: 324692
total_episode_count: 1997
total_duration: 642.0317748045087
[2022-12-21 15:36:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1346
train_sample_count: 1346
avg_envstep_per_episode: 168.25
avg_sample_per_episode: 168.25
avg_envstep_per_sec: 498.84798736419486
avg_train_sample_per_sec: 498.84798736419486
avg_episode_per_sec: 2.9649211730412772
collect_time: 2.6982167596024063
reward_mean: 828.875
reward_std: 344.048828125
reward_max: 1308.0
reward_min: 231.0
total_envstep_count: 325740
total_train_sample_count: 325702
total_episode_count: 2005
total_duration: 644.7299915641111
[2022-12-21 15:36:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 655
train_sample_count: 655
avg_envstep_per_episode: 163.75
avg_sample_per_episode: 163.75
avg_envstep_per_sec: 510.58244216244964
avg_train_sample_per_sec: 510.58244216244964
avg_episode_per_sec: 3.1180607154958757
collect_time: 1.2828486565771913
reward_mean: 849.25
reward_std: 268.6302185058594
reward_max: 1305.0
reward_min: 609.0
total_envstep_count: 326760
total_train_sample_count: 326705
total_episode_count: 2009
total_duration: 646.0128402206883
[2022-12-21 15:36:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 941
train_sample_count: 941
avg_envstep_per_episode: 235.25
avg_sample_per_episode: 235.25
avg_envstep_per_sec: 519.7210504804694
avg_train_sample_per_sec: 519.7210504804694
avg_episode_per_sec: 2.209228694922293
collect_time: 1.8105866582276557
reward_mean: 1193.0
reward_std: 160.24200439453125
reward_max: 1402.0
reward_min: 1026.0
total_envstep_count: 327732
total_train_sample_count: 327682
total_episode_count: 2013
total_duration: 647.8234268789159
[2022-12-21 15:36:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1120
train_sample_count: 1120
avg_envstep_per_episode: 224.0
avg_sample_per_episode: 224.0
avg_envstep_per_sec: 520.3707988062273
avg_train_sample_per_sec: 520.3707988062273
avg_episode_per_sec: 2.323083923242086
collect_time: 2.1523113952000585
reward_mean: 1211.800048828125
reward_std: 387.8785400390625
reward_max: 1907.0
reward_min: 760.0
total_envstep_count: 328696
total_train_sample_count: 328658
total_episode_count: 2018
total_duration: 649.975738274116
[2022-12-21 15:36:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1098
train_sample_count: 1098
avg_envstep_per_episode: 183.0
avg_sample_per_episode: 183.0
avg_envstep_per_sec: 519.6998717590075
avg_train_sample_per_sec: 519.6998717590075
avg_episode_per_sec: 2.8398900096120627
collect_time: 2.1127578813587986
reward_mean: 897.1666870117188
reward_std: 340.7621154785156
reward_max: 1304.0
reward_min: 231.0
total_envstep_count: 329702
total_train_sample_count: 329660
total_episode_count: 2024
total_duration: 652.0884961554748
[2022-12-21 15:36:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 976
train_sample_count: 976
avg_envstep_per_episode: 162.66666666666666
avg_sample_per_episode: 162.66666666666666
avg_envstep_per_sec: 524.5599252500459
avg_train_sample_per_sec: 524.5599252500459
avg_episode_per_sec: 3.2247536388322495
collect_time: 1.8606072500387114
reward_mean: 781.6666870117188
reward_std: 337.7018737792969
reward_max: 1309.0
reward_min: 231.0
total_envstep_count: 330720
total_train_sample_count: 330672
total_episode_count: 2030
total_duration: 653.9491034055135
[2022-12-21 15:36:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1122
train_sample_count: 1122
avg_envstep_per_episode: 140.25
avg_sample_per_episode: 140.25
avg_envstep_per_sec: 506.34244356198735
avg_train_sample_per_sec: 506.34244356198735
avg_episode_per_sec: 3.610284802581015
collect_time: 2.215891664358654
reward_mean: 752.125
reward_std: 269.5182800292969
reward_max: 1048.0
reward_min: 231.0
total_envstep_count: 331722
total_train_sample_count: 331686
total_episode_count: 2038
total_duration: 656.1649950698721
[2022-12-21 15:36:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1046
train_sample_count: 1046
avg_envstep_per_episode: 130.75
avg_sample_per_episode: 130.75
avg_envstep_per_sec: 495.5448887093959
avg_train_sample_per_sec: 495.5448887093959
avg_episode_per_sec: 3.7900182692879225
collect_time: 2.110807767030384
reward_mean: 678.25
reward_std: 343.55047607421875
reward_max: 1311.0
reward_min: 231.0
total_envstep_count: 332710
total_train_sample_count: 332672
total_episode_count: 2046
total_duration: 658.2758028369025
[2022-12-21 15:37:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 893
train_sample_count: 893
avg_envstep_per_episode: 148.83333333333334
avg_sample_per_episode: 148.83333333333334
avg_envstep_per_sec: 511.99489220891445
avg_train_sample_per_sec: 511.99489220891445
avg_episode_per_sec: 3.4400552668012168
collect_time: 1.744158024989867
reward_mean: 718.3333129882812
reward_std: 277.66326904296875
reward_max: 1041.0
reward_min: 231.0
total_envstep_count: 333689
total_train_sample_count: 333649
total_episode_count: 2052
total_duration: 660.0199608618923
[2022-12-21 15:37:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 749
train_sample_count: 749
avg_envstep_per_episode: 187.25
avg_sample_per_episode: 187.25
avg_envstep_per_sec: 509.13170012664614
avg_train_sample_per_sec: 509.13170012664614
avg_episode_per_sec: 2.7189943931997123
collect_time: 1.4711321251724983
reward_mean: 974.25
reward_std: 225.0359649658203
reward_max: 1309.0
reward_min: 734.0
total_envstep_count: 334686
total_train_sample_count: 334638
total_episode_count: 2056
total_duration: 661.4910929870648
[2022-12-21 15:37:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1427
train_sample_count: 1427
avg_envstep_per_episode: 203.85714285714286
avg_sample_per_episode: 203.85714285714286
avg_envstep_per_sec: 490.96629849798927
avg_train_sample_per_sec: 490.96629849798927
avg_episode_per_sec: 2.4083840851337945
collect_time: 2.9065131443148213
reward_mean: 1036.857177734375
reward_std: 4.453845024108887
reward_max: 1043.0
reward_min: 1029.0
total_envstep_count: 335667
total_train_sample_count: 335633
total_episode_count: 2063
total_duration: 664.3976061313796
[2022-12-21 15:37:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 463
train_sample_count: 463
avg_envstep_per_episode: 154.33333333333334
avg_sample_per_episode: 154.33333333333334
avg_envstep_per_sec: 488.5687770108734
avg_train_sample_per_sec: 488.5687770108734
avg_episode_per_sec: 3.165672421236761
collect_time: 0.9476659618584173
reward_mean: 850.6666870117188
reward_std: 321.9951477050781
reward_max: 1306.0
reward_min: 618.0
total_envstep_count: 336649
total_train_sample_count: 336624
total_episode_count: 2066
total_duration: 665.345272093238
[2022-12-21 15:37:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1415
train_sample_count: 1415
avg_envstep_per_episode: 141.5
avg_sample_per_episode: 141.5
avg_envstep_per_sec: 493.1584250578269
avg_train_sample_per_sec: 493.1584250578269
avg_episode_per_sec: 3.4852185516454197
collect_time: 2.869260521776708
reward_mean: 703.2999877929688
reward_std: 284.6208190917969
reward_max: 1037.0
reward_min: 231.0
total_envstep_count: 337683
total_train_sample_count: 337655
total_episode_count: 2076
total_duration: 668.2145326150147
[2022-12-21 15:37:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 997
train_sample_count: 997
avg_envstep_per_episode: 124.625
avg_sample_per_episode: 124.625
avg_envstep_per_sec: 509.36177627870114
avg_train_sample_per_sec: 509.36177627870114
avg_episode_per_sec: 4.087155677261394
collect_time: 1.9573514276707011
reward_mean: 636.625
reward_std: 373.54345703125
reward_max: 1298.0
reward_min: 231.0
total_envstep_count: 338692
total_train_sample_count: 338664
total_episode_count: 2084
total_duration: 670.1718840426854
[2022-12-21 15:37:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 628
train_sample_count: 628
avg_envstep_per_episode: 157.0
avg_sample_per_episode: 157.0
avg_envstep_per_sec: 496.6193591762118
avg_train_sample_per_sec: 496.6193591762118
avg_episode_per_sec: 3.1631806316956164
collect_time: 1.2645499785624978
reward_mean: 870.75
reward_std: 398.09820556640625
reward_max: 1555.0
reward_min: 583.0
total_envstep_count: 339680
total_train_sample_count: 339652
total_episode_count: 2088
total_duration: 671.4364340212479
[2022-12-21 15:37:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1276
train_sample_count: 1276
avg_envstep_per_episode: 141.77777777777777
avg_sample_per_episode: 141.77777777777777
avg_envstep_per_sec: 497.71402578219937
avg_train_sample_per_sec: 497.71402578219937
avg_episode_per_sec: 3.5105221254230363
collect_time: 2.5637212011348463
reward_mean: 753.6666870117188
reward_std: 406.3197937011719
reward_max: 1326.0
reward_min: 231.0
total_envstep_count: 340727
total_train_sample_count: 340676
total_episode_count: 2097
total_duration: 674.0001552223828
[2022-12-21 15:37:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 711
train_sample_count: 711
avg_envstep_per_episode: 177.75
avg_sample_per_episode: 177.75
avg_envstep_per_sec: 513.0014934595581
avg_train_sample_per_sec: 513.0014934595581
avg_episode_per_sec: 2.886084351389919
collect_time: 1.3859608774336851
reward_mean: 1003.5
reward_std: 243.45277404785156
reward_max: 1308.0
reward_min: 627.0
total_envstep_count: 341692
total_train_sample_count: 341651
total_episode_count: 2101
total_duration: 675.3861160998165
[2022-12-21 15:38:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1376
train_sample_count: 1376
avg_envstep_per_episode: 152.88888888888889
avg_sample_per_episode: 152.88888888888889
avg_envstep_per_sec: 510.8121203054401
avg_train_sample_per_sec: 510.8121203054401
avg_episode_per_sec: 3.3410676473466285
collect_time: 2.6937497081651487
reward_mean: 821.6666870117188
reward_std: 509.7677001953125
reward_max: 1547.0
reward_min: 231.0
total_envstep_count: 342685
total_train_sample_count: 342655
total_episode_count: 2110
total_duration: 678.0798658079816
[2022-12-21 15:38:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1140
train_sample_count: 1140
avg_envstep_per_episode: 142.5
avg_sample_per_episode: 142.5
avg_envstep_per_sec: 505.9685894933801
avg_train_sample_per_sec: 505.9685894933801
avg_episode_per_sec: 3.550656768374597
collect_time: 2.2531042908048255
reward_mean: 725.375
reward_std: 269.5417175292969
reward_max: 1046.0
reward_min: 231.0
total_envstep_count: 343703
total_train_sample_count: 343663
total_episode_count: 2118
total_duration: 680.3329700987864
[2022-12-21 15:38:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 730
train_sample_count: 730
avg_envstep_per_episode: 146.0
avg_sample_per_episode: 146.0
avg_envstep_per_sec: 505.1920484965346
avg_train_sample_per_sec: 505.1920484965346
avg_episode_per_sec: 3.4602195102502367
collect_time: 1.444995031439034
reward_mean: 852.2000122070312
reward_std: 379.8996887207031
reward_max: 1313.0
reward_min: 231.0
total_envstep_count: 344675
total_train_sample_count: 344645
total_episode_count: 2123
total_duration: 681.7779651302254
[2022-12-21 15:38:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 964
train_sample_count: 964
avg_envstep_per_episode: 137.71428571428572
avg_sample_per_episode: 137.71428571428572
avg_envstep_per_sec: 495.6032942235431
avg_train_sample_per_sec: 495.6032942235431
avg_episode_per_sec: 3.598779107432367
collect_time: 1.9451041008722298
reward_mean: 727.7142944335938
reward_std: 385.03497314453125
reward_max: 1308.0
reward_min: 231.0
total_envstep_count: 345663
total_train_sample_count: 345633
total_episode_count: 2130
total_duration: 683.7230692310976
[2022-12-21 15:38:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 720
train_sample_count: 720
avg_envstep_per_episode: 180.0
avg_sample_per_episode: 180.0
avg_envstep_per_sec: 505.59924619545814
avg_train_sample_per_sec: 505.59924619545814
avg_episode_per_sec: 2.8088847010858786
collect_time: 1.4240527560471428
reward_mean: 995.75
reward_std: 434.68572998046875
reward_max: 1690.0
reward_min: 627.0
total_envstep_count: 346644
total_train_sample_count: 346605
total_episode_count: 2134
total_duration: 685.1471219871447
[2022-12-21 15:38:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1420
train_sample_count: 1420
avg_envstep_per_episode: 177.5
avg_sample_per_episode: 177.5
avg_envstep_per_sec: 501.48993913592733
avg_train_sample_per_sec: 501.48993913592733
avg_episode_per_sec: 2.8252954317517034
collect_time: 2.8315622890594287
reward_mean: 976.875
reward_std: 276.0110778808594
reward_max: 1406.0
reward_min: 626.0
total_envstep_count: 347654
total_train_sample_count: 347617
total_episode_count: 2142
total_duration: 687.9786842762041
[2022-12-21 15:38:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 919
train_sample_count: 919
avg_envstep_per_episode: 183.8
avg_sample_per_episode: 183.8
avg_envstep_per_sec: 498.928480334386
avg_train_sample_per_sec: 498.928480334386
avg_episode_per_sec: 2.7145183913731556
collect_time: 1.841947365650641
reward_mean: 901.7999877929688
reward_std: 240.66525268554688
reward_max: 1309.0
reward_min: 626.0
total_envstep_count: 348634
total_train_sample_count: 348596
total_episode_count: 2147
total_duration: 689.8206316418548
[2022-12-21 15:38:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 455
train_sample_count: 455
avg_envstep_per_episode: 151.66666666666666
avg_sample_per_episode: 151.66666666666666
avg_envstep_per_sec: 503.2568366582604
avg_train_sample_per_sec: 503.2568366582604
avg_episode_per_sec: 3.318176944999519
collect_time: 0.9041109168457666
reward_mean: 771.6666870117188
reward_std: 446.7134094238281
reward_max: 1325.0
reward_min: 231.0
total_envstep_count: 349624
total_train_sample_count: 349567
total_episode_count: 2150
total_duration: 690.7247425587005
[2022-12-21 15:38:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1521
train_sample_count: 1521
avg_envstep_per_episode: 190.125
avg_sample_per_episode: 190.125
avg_envstep_per_sec: 503.2001238709804
avg_train_sample_per_sec: 503.2001238709804
avg_episode_per_sec: 2.6466804674344795
collect_time: 3.0226542638729192
reward_mean: 968.5
reward_std: 405.8266296386719
reward_max: 1672.0
reward_min: 226.0
total_envstep_count: 350624
total_train_sample_count: 350596
total_episode_count: 2158
total_duration: 693.7473968225735
[2022-12-21 15:38:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1251
train_sample_count: 1251
avg_envstep_per_episode: 125.1
avg_sample_per_episode: 125.1
avg_envstep_per_sec: 512.9407268336074
avg_train_sample_per_sec: 512.9407268336074
avg_episode_per_sec: 4.10024561817432
collect_time: 2.4388782846752024
reward_mean: 699.5
reward_std: 373.6044006347656
reward_max: 1306.0
reward_min: 231.0
total_envstep_count: 351655
total_train_sample_count: 351607
total_episode_count: 2168
total_duration: 696.1862751072487
[2022-12-21 15:38:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 444
train_sample_count: 444
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 510.4975859620502
avg_train_sample_per_sec: 510.4975859620502
avg_episode_per_sec: 2.299538675504731
collect_time: 0.8697396661793547
reward_mean: 1171.0
reward_std: 135.0
reward_max: 1306.0
reward_min: 1036.0
total_envstep_count: 352621
total_train_sample_count: 352579
total_episode_count: 2170
total_duration: 697.056014773428
[2022-12-21 15:38:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1467
train_sample_count: 1467
avg_envstep_per_episode: 163.0
avg_sample_per_episode: 163.0
avg_envstep_per_sec: 439.7617363973512
avg_train_sample_per_sec: 439.7617363973512
avg_episode_per_sec: 2.697924763173934
collect_time: 3.335897324806079
reward_mean: 750.7777709960938
reward_std: 336.6593322753906
reward_max: 1298.0
reward_min: 231.0
total_envstep_count: 353605
total_train_sample_count: 353578
total_episode_count: 2179
total_duration: 700.3919120982341
[2022-12-21 15:38:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 783
train_sample_count: 783
avg_envstep_per_episode: 130.5
avg_sample_per_episode: 130.5
avg_envstep_per_sec: 505.3288603288406
avg_train_sample_per_sec: 505.3288603288406
avg_episode_per_sec: 3.8722518032861353
collect_time: 1.5494860109324966
reward_mean: 688.3333129882812
reward_std: 154.4524383544922
reward_max: 1033.0
reward_min: 599.0
total_envstep_count: 354616
total_train_sample_count: 354565
total_episode_count: 2185
total_duration: 701.9413981091666
[2022-12-21 15:38:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 891
train_sample_count: 891
avg_envstep_per_episode: 178.2
avg_sample_per_episode: 178.2
avg_envstep_per_sec: 497.63024941410083
avg_train_sample_per_sec: 497.63024941410083
avg_episode_per_sec: 2.7925378755000048
collect_time: 1.7904860105450668
reward_mean: 878.7999877929688
reward_std: 252.4293212890625
reward_max: 1298.0
reward_min: 630.0
total_envstep_count: 355612
total_train_sample_count: 355576
total_episode_count: 2190
total_duration: 703.7318841197117
[2022-12-21 15:38:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 904
train_sample_count: 904
avg_envstep_per_episode: 180.8
avg_sample_per_episode: 180.8
avg_envstep_per_sec: 500.7084621058514
avg_train_sample_per_sec: 500.7084621058514
avg_episode_per_sec: 2.7694052107624523
collect_time: 1.8054418257642537
reward_mean: 971.5999755859375
reward_std: 345.6163330078125
reward_max: 1548.0
reward_min: 599.0
total_envstep_count: 356578
total_train_sample_count: 356540
total_episode_count: 2195
total_duration: 705.5373259454759
[2022-12-21 15:38:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1294
train_sample_count: 1294
avg_envstep_per_episode: 161.75
avg_sample_per_episode: 161.75
avg_envstep_per_sec: 495.45776144961656
avg_train_sample_per_sec: 495.45776144961656
avg_episode_per_sec: 3.0631082624396697
collect_time: 2.611726166553529
reward_mean: 868.0
reward_std: 252.5480194091797
reward_max: 1311.0
reward_min: 626.0
total_envstep_count: 357618
total_train_sample_count: 357582
total_episode_count: 2203
total_duration: 708.1490521120295
[2022-12-21 15:38:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 812
train_sample_count: 812
avg_envstep_per_episode: 162.4
avg_sample_per_episode: 162.4
avg_envstep_per_sec: 499.9724291234562
avg_train_sample_per_sec: 499.9724291234562
avg_episode_per_sec: 3.0786479625828584
collect_time: 1.624089555145242
reward_mean: 885.5999755859375
reward_std: 367.62786865234375
reward_max: 1547.0
reward_min: 608.0
total_envstep_count: 358589
total_train_sample_count: 358562
total_episode_count: 2208
total_duration: 709.7731416671747
[2022-12-21 15:38:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1032
train_sample_count: 1032
avg_envstep_per_episode: 172.0
avg_sample_per_episode: 172.0
avg_envstep_per_sec: 500.9099777297164
avg_train_sample_per_sec: 500.9099777297164
avg_episode_per_sec: 2.9122673123820717
collect_time: 2.0602504359712555
reward_mean: 834.6666870117188
reward_std: 308.8055725097656
reward_max: 1041.0
reward_min: 231.0
total_envstep_count: 359608
total_train_sample_count: 359570
total_episode_count: 2214
total_duration: 711.833392103146
[2022-12-21 15:38:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1287
train_sample_count: 1287
avg_envstep_per_episode: 160.875
avg_sample_per_episode: 160.875
avg_envstep_per_sec: 500.24782496776265
avg_train_sample_per_sec: 500.24782496776265
avg_episode_per_sec: 3.109543589543202
collect_time: 2.57272482910433
reward_mean: 824.125
reward_std: 320.73406982421875
reward_max: 1304.0
reward_min: 231.0
total_envstep_count: 360612
total_train_sample_count: 360569
total_episode_count: 2222
total_duration: 714.4061169322504
[2022-12-21 15:39:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 792
train_sample_count: 792
avg_envstep_per_episode: 158.4
avg_sample_per_episode: 158.4
avg_envstep_per_sec: 496.91984135255984
avg_train_sample_per_sec: 496.91984135255984
avg_episode_per_sec: 3.1371202105590896
collect_time: 1.5938184272221154
reward_mean: 805.4000244140625
reward_std: 362.1980895996094
reward_max: 1309.0
reward_min: 231.0
total_envstep_count: 361567
total_train_sample_count: 361541
total_episode_count: 2227
total_duration: 715.9999353594725
[2022-12-21 15:39:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 774
train_sample_count: 774
avg_envstep_per_episode: 154.8
avg_sample_per_episode: 154.8
avg_envstep_per_sec: 508.993660034674
avg_train_sample_per_sec: 508.993660034674
avg_episode_per_sec: 3.28807273924208
collect_time: 1.5206476244660356
reward_mean: 755.5999755859375
reward_std: 156.11610412597656
reward_max: 1036.0
reward_min: 602.0
total_envstep_count: 362594
total_train_sample_count: 362543
total_episode_count: 2232
total_duration: 717.5205829839385
[2022-12-21 15:39:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 863
train_sample_count: 863
avg_envstep_per_episode: 215.75
avg_sample_per_episode: 215.75
avg_envstep_per_sec: 509.9755361891342
avg_train_sample_per_sec: 509.9755361891342
avg_episode_per_sec: 2.3637336555695674
collect_time: 1.6922380364534584
reward_mean: 1202.25
reward_std: 162.0484161376953
reward_max: 1407.0
reward_min: 1043.0
total_envstep_count: 363574
total_train_sample_count: 363514
total_episode_count: 2236
total_duration: 719.212821020392
[2022-12-21 15:39:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1190
train_sample_count: 1190
avg_envstep_per_episode: 170.0
avg_sample_per_episode: 170.0
avg_envstep_per_sec: 498.37835591115777
avg_train_sample_per_sec: 498.37835591115777
avg_episode_per_sec: 2.931637387712693
collect_time: 2.3877441423482133
reward_mean: 879.7142944335938
reward_std: 288.4335632324219
reward_max: 1049.0
reward_min: 231.0
total_envstep_count: 364546
total_train_sample_count: 364488
total_episode_count: 2243
total_duration: 721.6005651627402
[2022-12-21 15:39:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 883
train_sample_count: 883
avg_envstep_per_episode: 176.6
avg_sample_per_episode: 176.6
avg_envstep_per_sec: 499.85553778803694
avg_train_sample_per_sec: 499.85553778803694
avg_episode_per_sec: 2.830439058822406
collect_time: 1.7665103879962114
reward_mean: 917.7999877929688
reward_std: 405.93072509765625
reward_max: 1307.0
reward_min: 231.0
total_envstep_count: 365535
total_train_sample_count: 365491
total_episode_count: 2248
total_duration: 723.3670755507363
[2022-12-21 15:39:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1172
train_sample_count: 1172
avg_envstep_per_episode: 146.5
avg_sample_per_episode: 146.5
avg_envstep_per_sec: 502.9872862806876
avg_train_sample_per_sec: 502.9872862806876
avg_episode_per_sec: 3.4333603159091304
collect_time: 2.3300787752833494
reward_mean: 690.125
reward_std: 314.0479431152344
reward_max: 1037.0
reward_min: 231.0
total_envstep_count: 366575
total_train_sample_count: 366531
total_episode_count: 2256
total_duration: 725.6971543260197
[2022-12-21 15:39:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1062
train_sample_count: 1062
avg_envstep_per_episode: 151.71428571428572
avg_sample_per_episode: 151.71428571428572
avg_envstep_per_sec: 506.4055508592061
avg_train_sample_per_sec: 506.4055508592061
avg_episode_per_sec: 3.3378896949288532
collect_time: 2.0971334105602324
reward_mean: 783.5714111328125
reward_std: 465.9598083496094
reward_max: 1550.0
reward_min: 231.0
total_envstep_count: 367561
total_train_sample_count: 367521
total_episode_count: 2263
total_duration: 727.7942877365799
[2022-12-21 15:39:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1073
train_sample_count: 1073
avg_envstep_per_episode: 153.28571428571428
avg_sample_per_episode: 153.28571428571428
avg_envstep_per_sec: 499.72961029078715
avg_train_sample_per_sec: 499.72961029078715
avg_episode_per_sec: 3.260118613267018
collect_time: 2.1471611405528543
reward_mean: 840.5714111328125
reward_std: 263.0360412597656
reward_max: 1307.0
reward_min: 620.0
total_envstep_count: 368556
total_train_sample_count: 368510
total_episode_count: 2270
total_duration: 729.9414488771328
[2022-12-21 15:39:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 963
train_sample_count: 963
avg_envstep_per_episode: 160.5
avg_sample_per_episode: 160.5
avg_envstep_per_sec: 485.773464026968
avg_train_sample_per_sec: 485.773464026968
avg_episode_per_sec: 3.0266259440932584
collect_time: 1.9824055270885248
reward_mean: 844.0
reward_std: 246.72048950195312
reward_max: 1297.0
reward_min: 618.0
total_envstep_count: 369576
total_train_sample_count: 369533
total_episode_count: 2276
total_duration: 731.9238544042213
[2022-12-21 15:39:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 860
train_sample_count: 860
avg_envstep_per_episode: 143.33333333333334
avg_sample_per_episode: 143.33333333333334
avg_envstep_per_sec: 497.08846406500936
avg_train_sample_per_sec: 497.08846406500936
avg_episode_per_sec: 3.4680590516163443
collect_time: 1.7300743472645324
reward_mean: 699.0
reward_std: 278.46246337890625
reward_max: 1043.0
reward_min: 231.0
total_envstep_count: 370548
total_train_sample_count: 370525
total_episode_count: 2282
total_duration: 733.6539287514859
[2022-12-21 15:39:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1102
train_sample_count: 1102
avg_envstep_per_episode: 137.75
avg_sample_per_episode: 137.75
avg_envstep_per_sec: 502.7035607806552
avg_train_sample_per_sec: 502.7035607806552
avg_episode_per_sec: 3.6493906408759
collect_time: 2.1921467957949
reward_mean: 773.75
reward_std: 341.123046875
reward_max: 1401.0
reward_min: 231.0
total_envstep_count: 371582
total_train_sample_count: 371543
total_episode_count: 2290
total_duration: 735.8460755472807
[2022-12-21 15:39:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 566
train_sample_count: 566
avg_envstep_per_episode: 188.66666666666666
avg_sample_per_episode: 188.66666666666666
avg_envstep_per_sec: 504.89808056756755
avg_train_sample_per_sec: 504.89808056756755
avg_episode_per_sec: 2.6761382362238564
collect_time: 1.1210183238639893
reward_mean: 896.0
reward_std: 190.9624786376953
reward_max: 1036.0
reward_min: 626.0
total_envstep_count: 372572
total_train_sample_count: 372517
total_episode_count: 2293
total_duration: 736.9670938711447
[2022-12-21 15:39:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1628
train_sample_count: 1628
avg_envstep_per_episode: 180.88888888888889
avg_sample_per_episode: 180.88888888888889
avg_envstep_per_sec: 500.59104093524536
avg_train_sample_per_sec: 500.59104093524536
avg_episode_per_sec: 2.76739518944546
collect_time: 3.2521556857238925
reward_mean: 955.0
reward_std: 347.33428955078125
reward_max: 1313.0
reward_min: 231.0
total_envstep_count: 373535
total_train_sample_count: 373509
total_episode_count: 2302
total_duration: 740.2192495568686
[2022-12-21 15:39:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 746
train_sample_count: 746
avg_envstep_per_episode: 124.33333333333333
avg_sample_per_episode: 124.33333333333333
avg_envstep_per_sec: 492.2392090895409
avg_train_sample_per_sec: 492.2392090895409
avg_episode_per_sec: 3.95902849133679
collect_time: 1.5155233192004798
reward_mean: 701.1666870117188
reward_std: 153.89218139648438
reward_max: 1034.0
reward_min: 601.0
total_envstep_count: 374523
total_train_sample_count: 374495
total_episode_count: 2308
total_duration: 741.7347728760691
[2022-12-21 15:39:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1225
train_sample_count: 1225
avg_envstep_per_episode: 153.125
avg_sample_per_episode: 153.125
avg_envstep_per_sec: 488.6866187233502
avg_train_sample_per_sec: 488.6866187233502
avg_episode_per_sec: 3.191422816152491
collect_time: 2.5067189341099665
reward_mean: 807.875
reward_std: 402.0520324707031
reward_max: 1655.0
reward_min: 231.0
total_envstep_count: 375526
total_train_sample_count: 375480
total_episode_count: 2316
total_duration: 744.241491810179
[2022-12-21 15:39:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 722
train_sample_count: 722
avg_envstep_per_episode: 144.4
avg_sample_per_episode: 144.4
avg_envstep_per_sec: 508.3664776180018
avg_train_sample_per_sec: 508.3664776180018
avg_episode_per_sec: 3.5205434738088766
collect_time: 1.4202352668551197
reward_mean: 665.7999877929688
reward_std: 73.91725158691406
reward_max: 763.0
reward_min: 588.0
total_envstep_count: 376523
total_train_sample_count: 376490
total_episode_count: 2321
total_duration: 745.6617270770341
[2022-12-21 15:39:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1025
train_sample_count: 1025
avg_envstep_per_episode: 146.42857142857142
avg_sample_per_episode: 146.42857142857142
avg_envstep_per_sec: 509.2148182361554
avg_train_sample_per_sec: 509.2148182361554
avg_episode_per_sec: 3.4775646123444757
collect_time: 2.01290293073255
reward_mean: 685.5714111328125
reward_std: 227.6531524658203
reward_max: 1041.0
reward_min: 226.0
total_envstep_count: 377540
total_train_sample_count: 377491
total_episode_count: 2328
total_duration: 747.6746300077667
[2022-12-21 15:39:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1220
train_sample_count: 1220
avg_envstep_per_episode: 174.28571428571428
avg_sample_per_episode: 174.28571428571428
avg_envstep_per_sec: 508.00597632913156
avg_train_sample_per_sec: 508.00597632913156
avg_episode_per_sec: 2.914788388773706
collect_time: 2.401546550329509
reward_mean: 996.7142944335938
reward_std: 262.18353271484375
reward_max: 1310.0
reward_min: 616.0
total_envstep_count: 378551
total_train_sample_count: 378531
total_episode_count: 2335
total_duration: 750.0761765580962
[2022-12-21 15:40:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 752
train_sample_count: 752
avg_envstep_per_episode: 188.0
avg_sample_per_episode: 188.0
avg_envstep_per_sec: 500.234638449856
avg_train_sample_per_sec: 500.234638449856
avg_episode_per_sec: 2.6608225449460425
collect_time: 1.503294538599572
reward_mean: 991.5
reward_std: 257.903564453125
reward_max: 1308.0
reward_min: 589.0
total_envstep_count: 379563
total_train_sample_count: 379511
total_episode_count: 2339
total_duration: 751.5794710966958
[2022-12-21 15:40:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 838
train_sample_count: 838
avg_envstep_per_episode: 209.5
avg_sample_per_episode: 209.5
avg_envstep_per_sec: 502.0680682300459
avg_train_sample_per_sec: 502.0680682300459
avg_episode_per_sec: 2.396506292267522
collect_time: 1.6690963895677013
reward_mean: 1068.25
reward_std: 277.29620361328125
reward_max: 1307.0
reward_min: 628.0
total_envstep_count: 380535
total_train_sample_count: 380481
total_episode_count: 2343
total_duration: 753.2485674862635
[2022-12-21 15:40:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1047
train_sample_count: 1047
avg_envstep_per_episode: 209.4
avg_sample_per_episode: 209.4
avg_envstep_per_sec: 495.19449498539194
avg_train_sample_per_sec: 495.19449498539194
avg_episode_per_sec: 2.3648256685071245
collect_time: 2.114320758010216
reward_mean: 1175.4000244140625
reward_std: 425.8077392578125
reward_max: 1894.0
reward_min: 595.0
total_envstep_count: 381500
total_train_sample_count: 381492
total_episode_count: 2348
total_duration: 755.3628882442737
[2022-12-21 15:40:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1062
train_sample_count: 1062
avg_envstep_per_episode: 132.75
avg_sample_per_episode: 132.75
avg_envstep_per_sec: 497.13842843258647
avg_train_sample_per_sec: 497.13842843258647
avg_episode_per_sec: 3.7449222480797473
collect_time: 2.136225926747102
reward_mean: 690.0
reward_std: 340.555419921875
reward_max: 1303.0
reward_min: 231.0
total_envstep_count: 382518
total_train_sample_count: 382470
total_episode_count: 2356
total_duration: 757.4991141710208
[2022-12-21 15:40:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 690
train_sample_count: 690
avg_envstep_per_episode: 172.5
avg_sample_per_episode: 172.5
avg_envstep_per_sec: 508.0282123577924
avg_train_sample_per_sec: 508.0282123577924
avg_episode_per_sec: 2.94509108613213
collect_time: 1.3581922877819412
reward_mean: 993.75
reward_std: 268.16168212890625
reward_max: 1413.0
reward_min: 718.0
total_envstep_count: 383498
total_train_sample_count: 383460
total_episode_count: 2360
total_duration: 758.8573064588027
[2022-12-21 15:40:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1526
train_sample_count: 1526
avg_envstep_per_episode: 190.75
avg_sample_per_episode: 190.75
avg_envstep_per_sec: 511.0304693184085
avg_train_sample_per_sec: 511.0304693184085
avg_episode_per_sec: 2.6790588168723906
collect_time: 2.98612331674727
reward_mean: 921.625
reward_std: 206.36007690429688
reward_max: 1303.0
reward_min: 628.0
total_envstep_count: 384492
total_train_sample_count: 384446
total_episode_count: 2368
total_duration: 761.8434297755499
[2022-12-21 15:40:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 148.33333333333334
avg_sample_per_episode: 148.33333333333334
avg_envstep_per_sec: 509.4570661962252
avg_train_sample_per_sec: 509.4570661962252
avg_episode_per_sec: 3.4345420193003946
collect_time: 1.7469578087218107
reward_mean: 781.6666870117188
reward_std: 420.6866149902344
reward_max: 1307.0
reward_min: 231.0
total_envstep_count: 385463
total_train_sample_count: 385432
total_episode_count: 2374
total_duration: 763.5903875842718
[2022-12-21 15:40:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1233
train_sample_count: 1233
avg_envstep_per_episode: 176.14285714285714
avg_sample_per_episode: 176.14285714285714
avg_envstep_per_sec: 501.4960809443937
avg_train_sample_per_sec: 501.4960809443937
avg_episode_per_sec: 2.8470985941693074
collect_time: 2.4586433410966495
reward_mean: 900.0
reward_std: 333.57415771484375
reward_max: 1312.0
reward_min: 231.0
total_envstep_count: 386482
total_train_sample_count: 386449
total_episode_count: 2381
total_duration: 766.0490309253684
[2022-12-21 15:40:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 781
train_sample_count: 781
avg_envstep_per_episode: 130.16666666666666
avg_sample_per_episode: 130.16666666666666
avg_envstep_per_sec: 504.8177400678375
avg_train_sample_per_sec: 504.8177400678375
avg_episode_per_sec: 3.87824128093089
collect_time: 1.5470930159765166
reward_mean: 697.6666870117188
reward_std: 399.0065612792969
reward_max: 1321.0
reward_min: 231.0
total_envstep_count: 387447
total_train_sample_count: 387422
total_episode_count: 2387
total_duration: 767.5961239413449
[2022-12-21 15:40:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 772
train_sample_count: 772
avg_envstep_per_episode: 154.4
avg_sample_per_episode: 154.4
avg_envstep_per_sec: 491.979695369135
avg_train_sample_per_sec: 491.979695369135
avg_episode_per_sec: 3.1863969907327396
collect_time: 1.5691704500543753
reward_mean: 704.5999755859375
reward_std: 263.486328125
reward_max: 1043.0
reward_min: 231.0
total_envstep_count: 388443
total_train_sample_count: 388410
total_episode_count: 2392
total_duration: 769.1652943913992
[2022-12-21 15:40:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1115
train_sample_count: 1115
avg_envstep_per_episode: 185.83333333333334
avg_sample_per_episode: 185.83333333333334
avg_envstep_per_sec: 490.31298609391484
avg_train_sample_per_sec: 490.31298609391484
avg_episode_per_sec: 2.6384555305502144
collect_time: 2.2740576562792327
reward_mean: 941.0
reward_std: 250.21591186523438
reward_max: 1313.0
reward_min: 606.0
total_envstep_count: 389438
total_train_sample_count: 389381
total_episode_count: 2398
total_duration: 771.4393520476784
[2022-12-21 15:40:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 179.25
avg_sample_per_episode: 179.25
avg_envstep_per_sec: 508.07552150633876
avg_train_sample_per_sec: 508.07552150633876
avg_episode_per_sec: 2.834452002824763
collect_time: 1.4112075265390536
reward_mean: 939.75
reward_std: 151.75205993652344
reward_max: 1129.0
reward_min: 771.0
total_envstep_count: 390411
total_train_sample_count: 390374
total_episode_count: 2402
total_duration: 772.8505595742175
[2022-12-21 15:40:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1062
train_sample_count: 1062
avg_envstep_per_episode: 212.4
avg_sample_per_episode: 212.4
avg_envstep_per_sec: 417.17149388810867
avg_train_sample_per_sec: 417.17149388810867
avg_episode_per_sec: 1.9640842461775363
collect_time: 2.5457156482624947
reward_mean: 1150.199951171875
reward_std: 134.28834533691406
reward_max: 1323.0
reward_min: 1036.0
total_envstep_count: 391390
total_train_sample_count: 391352
total_episode_count: 2407
total_duration: 775.39627522248
[2022-12-21 15:40:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 683
train_sample_count: 683
avg_envstep_per_episode: 170.75
avg_sample_per_episode: 170.75
avg_envstep_per_sec: 478.1743411024309
avg_train_sample_per_sec: 478.1743411024309
avg_episode_per_sec: 2.8004353798092585
collect_time: 1.4283493305503252
reward_mean: 972.75
reward_std: 443.16552734375
reward_max: 1320.0
reward_min: 231.0
total_envstep_count: 392386
total_train_sample_count: 392335
total_episode_count: 2411
total_duration: 776.8246245530303
[2022-12-21 15:40:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 644
train_sample_count: 644
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 471.99179048902994
avg_train_sample_per_sec: 471.99179048902994
avg_episode_per_sec: 2.9316260278821735
collect_time: 1.3644305112441737
reward_mean: 847.5
reward_std: 397.2987060546875
reward_max: 1307.0
reward_min: 231.0
total_envstep_count: 393342
total_train_sample_count: 393303
total_episode_count: 2415
total_duration: 778.1890550642745
[2022-12-21 15:40:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1132
train_sample_count: 1132
avg_envstep_per_episode: 188.66666666666666
avg_sample_per_episode: 188.66666666666666
avg_envstep_per_sec: 494.3042412457925
avg_train_sample_per_sec: 494.3042412457925
avg_episode_per_sec: 2.619987144412328
collect_time: 2.2900875726799876
reward_mean: 990.1666870117188
reward_std: 279.1758117675781
reward_max: 1311.0
reward_min: 627.0
total_envstep_count: 394337
total_train_sample_count: 394291
total_episode_count: 2421
total_duration: 780.4791426369545
[2022-12-21 15:40:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1591
train_sample_count: 1591
avg_envstep_per_episode: 227.28571428571428
avg_sample_per_episode: 227.28571428571428
avg_envstep_per_sec: 499.49761360185556
avg_train_sample_per_sec: 499.49761360185556
avg_episode_per_sec: 2.1976639190527902
collect_time: 3.1852004027153766
reward_mean: 857.8571166992188
reward_std: 644.6209106445312
reward_max: 2255.0
reward_min: 231.0
total_envstep_count: 395333
total_train_sample_count: 395306
total_episode_count: 2428
total_duration: 783.6643430396699
[2022-12-21 15:40:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1013
train_sample_count: 1013
avg_envstep_per_episode: 202.6
avg_sample_per_episode: 202.6
avg_envstep_per_sec: 501.12331456595524
avg_train_sample_per_sec: 501.12331456595524
avg_episode_per_sec: 2.4734615723887226
collect_time: 2.0214585323722236
reward_mean: 1052.4000244140625
reward_std: 419.0926208496094
reward_max: 1821.0
reward_min: 610.0
total_envstep_count: 396313
total_train_sample_count: 396295
total_episode_count: 2433
total_duration: 785.6858015720421
[2022-12-21 15:40:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 848
train_sample_count: 848
avg_envstep_per_episode: 212.0
avg_sample_per_episode: 212.0
avg_envstep_per_sec: 509.0838891945553
avg_train_sample_per_sec: 509.0838891945553
avg_episode_per_sec: 2.4013390999743174
collect_time: 1.665737254702087
reward_mean: 1110.25
reward_std: 271.0326232910156
reward_max: 1551.0
reward_min: 811.0
total_envstep_count: 397304
total_train_sample_count: 397263
total_episode_count: 2437
total_duration: 787.3515388267442
[2022-12-21 15:41:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1334
train_sample_count: 1334
avg_envstep_per_episode: 166.75
avg_sample_per_episode: 166.75
avg_envstep_per_sec: 508.22414626373944
avg_train_sample_per_sec: 508.22414626373944
avg_episode_per_sec: 3.047820967098887
collect_time: 2.6248260925952343
reward_mean: 934.25
reward_std: 378.56463623046875
reward_max: 1317.0
reward_min: 217.0
total_envstep_count: 398329
total_train_sample_count: 398285
total_episode_count: 2445
total_duration: 789.9763649193394
[2022-12-21 15:41:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 585
train_sample_count: 585
avg_envstep_per_episode: 195.0
avg_sample_per_episode: 195.0
avg_envstep_per_sec: 495.0033258788156
avg_train_sample_per_sec: 495.0033258788156
avg_episode_per_sec: 2.5384785942503365
collect_time: 1.1818102412976856
reward_mean: 1036.0
reward_std: 8.164965629577637
reward_max: 1046.0
reward_min: 1026.0
total_envstep_count: 399302
total_train_sample_count: 399254
total_episode_count: 2448
total_duration: 791.1581751606371
[2022-12-21 15:41:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1452
train_sample_count: 1452
avg_envstep_per_episode: 207.42857142857142
avg_sample_per_episode: 207.42857142857142
avg_envstep_per_sec: 493.57648029965617
avg_train_sample_per_sec: 493.57648029965617
avg_episode_per_sec: 2.379500938083742
collect_time: 2.941793334881908
reward_mean: 1152.4285888671875
reward_std: 370.9535217285156
reward_max: 1890.0
reward_min: 718.0
total_envstep_count: 400287
total_train_sample_count: 400262
total_episode_count: 2455
total_duration: 794.0999684955191
[2022-12-21 15:41:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 677
train_sample_count: 677
avg_envstep_per_episode: 169.25
avg_sample_per_episode: 169.25
avg_envstep_per_sec: 482.2454835559838
avg_train_sample_per_sec: 482.2454835559838
avg_episode_per_sec: 2.849308617760613
collect_time: 1.4038493321035057
reward_mean: 928.75
reward_std: 268.1803283691406
reward_max: 1312.0
reward_min: 626.0
total_envstep_count: 401293
total_train_sample_count: 401239
total_episode_count: 2459
total_duration: 795.5038178276226
[2022-12-21 15:41:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 987
train_sample_count: 987
avg_envstep_per_episode: 197.4
avg_sample_per_episode: 197.4
avg_envstep_per_sec: 489.3183883966378
avg_train_sample_per_sec: 489.3183883966378
avg_episode_per_sec: 2.478816557227142
collect_time: 2.0170915776006875
reward_mean: 962.5999755859375
reward_std: 238.5712432861328
reward_max: 1394.0
reward_min: 757.0
total_envstep_count: 402252
total_train_sample_count: 402214
total_episode_count: 2464
total_duration: 797.5209094052233
[2022-12-21 15:41:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 911
train_sample_count: 911
avg_envstep_per_episode: 182.2
avg_sample_per_episode: 182.2
avg_envstep_per_sec: 495.89112487905385
avg_train_sample_per_sec: 495.89112487905385
avg_episode_per_sec: 2.7216856469761463
collect_time: 1.837096802694724
reward_mean: 998.2000122070312
reward_std: 93.63845825195312
reward_max: 1048.0
reward_min: 811.0
total_envstep_count: 403271
total_train_sample_count: 403233
total_episode_count: 2469
total_duration: 799.358006207918
[2022-12-21 15:41:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1270
train_sample_count: 1270
avg_envstep_per_episode: 211.66666666666666
avg_sample_per_episode: 211.66666666666666
avg_envstep_per_sec: 503.67086661872446
avg_train_sample_per_sec: 503.67086661872446
avg_episode_per_sec: 2.3795474013483044
collect_time: 2.521487908414964
reward_mean: 1152.8333740234375
reward_std: 389.02630615234375
reward_max: 1894.0
reward_min: 614.0
total_envstep_count: 404266
total_train_sample_count: 404227
total_episode_count: 2475
total_duration: 801.879494116333
[2022-12-21 15:41:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 745
train_sample_count: 745
avg_envstep_per_episode: 186.25
avg_sample_per_episode: 186.25
avg_envstep_per_sec: 504.5447307436696
avg_train_sample_per_sec: 504.5447307436696
avg_episode_per_sec: 2.7089649972814476
collect_time: 1.4765786948204043
reward_mean: 968.75
reward_std: 122.34454345703125
reward_max: 1045.0
reward_min: 757.0
total_envstep_count: 405255
total_train_sample_count: 405224
total_episode_count: 2479
total_duration: 803.3560728111535
[2022-12-21 15:41:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1119
train_sample_count: 1119
avg_envstep_per_episode: 186.5
avg_sample_per_episode: 186.5
avg_envstep_per_sec: 494.4839723309797
avg_train_sample_per_sec: 494.4839723309797
avg_episode_per_sec: 2.6513885915870223
collect_time: 2.262965156838298
reward_mean: 950.5
reward_std: 338.5797424316406
reward_max: 1325.0
reward_min: 231.0
total_envstep_count: 406257
total_train_sample_count: 406211
total_episode_count: 2485
total_duration: 805.6190379679917
[2022-12-21 15:41:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1348
train_sample_count: 1348
avg_envstep_per_episode: 149.77777777777777
avg_sample_per_episode: 149.77777777777777
avg_envstep_per_sec: 491.90257421927225
avg_train_sample_per_sec: 491.90257421927225
avg_episode_per_sec: 3.2842159999803044
collect_time: 2.7403800481009695
reward_mean: 716.888916015625
reward_std: 340.29217529296875
reward_max: 1280.0
reward_min: 231.0
total_envstep_count: 407266
total_train_sample_count: 407235
total_episode_count: 2494
total_duration: 808.3594180160927
[2022-12-21 15:42:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 567
train_sample_count: 567
avg_envstep_per_episode: 189.0
avg_sample_per_episode: 189.0
avg_envstep_per_sec: 493.11323829505824
avg_train_sample_per_sec: 493.11323829505824
avg_episode_per_sec: 2.609064752883906
collect_time: 1.1498373111223006
reward_mean: 1036.6666259765625
reward_std: 8.956686019897461
reward_max: 1049.0
reward_min: 1028.0
total_envstep_count: 408247
total_train_sample_count: 408210
total_episode_count: 2497
total_duration: 809.509255327215
[2022-12-21 15:42:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1161
train_sample_count: 1161
avg_envstep_per_episode: 165.85714285714286
avg_sample_per_episode: 165.85714285714286
avg_envstep_per_sec: 493.79708375246963
avg_train_sample_per_sec: 493.79708375246963
avg_episode_per_sec: 2.9772433990243647
collect_time: 2.3511681988425543
reward_mean: 901.2857055664062
reward_std: 333.5675964355469
reward_max: 1310.0
reward_min: 222.0
total_envstep_count: 409225
total_train_sample_count: 409191
total_episode_count: 2504
total_duration: 811.8604235260575
[2022-12-21 15:42:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 784
train_sample_count: 784
avg_envstep_per_episode: 196.0
avg_sample_per_episode: 196.0
avg_envstep_per_sec: 485.51886272572654
avg_train_sample_per_sec: 485.51886272572654
avg_episode_per_sec: 2.4771370547230944
collect_time: 1.6147673348849638
reward_mean: 962.75
reward_std: 131.60618591308594
reward_max: 1045.0
reward_min: 735.0
total_envstep_count: 410197
total_train_sample_count: 410167
total_episode_count: 2508
total_duration: 813.4751908609425
[2022-12-21 15:42:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 996
train_sample_count: 996
avg_envstep_per_episode: 199.2
avg_sample_per_episode: 199.2
avg_envstep_per_sec: 495.48097359752956
avg_train_sample_per_sec: 495.48097359752956
avg_episode_per_sec: 2.4873542851281605
collect_time: 2.0101680045721255
reward_mean: 1009.5999755859375
reward_std: 217.50088500976562
reward_max: 1304.0
reward_min: 626.0
total_envstep_count: 411176
total_train_sample_count: 411151
total_episode_count: 2513
total_duration: 815.4853588655146
[2022-12-21 15:42:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 926
train_sample_count: 926
avg_envstep_per_episode: 154.33333333333334
avg_sample_per_episode: 154.33333333333334
avg_envstep_per_sec: 502.0828373624253
avg_train_sample_per_sec: 502.0828373624253
avg_episode_per_sec: 3.253236527186341
collect_time: 1.844317174561322
reward_mean: 826.6666870117188
reward_std: 210.8219451904297
reward_max: 1047.0
reward_min: 604.0
total_envstep_count: 412187
total_train_sample_count: 412137
total_episode_count: 2519
total_duration: 817.3296760400759
[2022-12-21 15:42:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1054
train_sample_count: 1054
avg_envstep_per_episode: 175.66666666666666
avg_sample_per_episode: 175.66666666666666
avg_envstep_per_sec: 491.43278252434425
avg_train_sample_per_sec: 491.43278252434425
avg_episode_per_sec: 2.7975300712960776
collect_time: 2.1447490633122093
reward_mean: 859.8333129882812
reward_std: 242.3897705078125
reward_max: 1305.0
reward_min: 618.0
total_envstep_count: 413142
total_train_sample_count: 413107
total_episode_count: 2525
total_duration: 819.4744251033882
[2022-12-21 15:42:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1104
train_sample_count: 1104
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 501.8513267710657
avg_train_sample_per_sec: 501.8513267710657
avg_episode_per_sec: 2.7274528628862265
collect_time: 2.1998547002021223
reward_mean: 858.1666870117188
reward_std: 208.29339599609375
reward_max: 1125.0
reward_min: 617.0
total_envstep_count: 414130
total_train_sample_count: 414091
total_episode_count: 2531
total_duration: 821.6742798035903
[2022-12-21 15:42:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 922
train_sample_count: 922
avg_envstep_per_episode: 115.25
avg_sample_per_episode: 115.25
avg_envstep_per_sec: 500.34824057058853
avg_train_sample_per_sec: 500.34824057058853
avg_episode_per_sec: 4.341416404083198
collect_time: 1.842716582651649
reward_mean: 549.75
reward_std: 353.38177490234375
reward_max: 1115.0
reward_min: 226.0
total_envstep_count: 415123
total_train_sample_count: 415085
total_episode_count: 2539
total_duration: 823.5169963862419
[2022-12-21 15:42:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 960
train_sample_count: 960
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 511.2054505421878
avg_train_sample_per_sec: 511.2054505421878
avg_episode_per_sec: 3.195034065888674
collect_time: 1.8779142495093075
reward_mean: 736.6666870117188
reward_std: 344.725830078125
reward_max: 1305.0
reward_min: 231.0
total_envstep_count: 416133
total_train_sample_count: 416093
total_episode_count: 2545
total_duration: 825.3949106357512
[2022-12-21 15:42:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1099
train_sample_count: 1099
avg_envstep_per_episode: 219.8
avg_sample_per_episode: 219.8
avg_envstep_per_sec: 513.4716669384295
avg_train_sample_per_sec: 513.4716669384295
avg_episode_per_sec: 2.3360858368445383
collect_time: 2.1403323119127062
reward_mean: 1215.0
reward_std: 320.7054748535156
reward_max: 1551.0
reward_min: 602.0
total_envstep_count: 417092
total_train_sample_count: 417060
total_episode_count: 2550
total_duration: 827.535242947664
[2022-12-21 15:42:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 839
train_sample_count: 839
avg_envstep_per_episode: 209.75
avg_sample_per_episode: 209.75
avg_envstep_per_sec: 505.5891103726656
avg_train_sample_per_sec: 505.5891103726656
avg_episode_per_sec: 2.410436759822005
collect_time: 1.659450298250253
reward_mean: 1100.25
reward_std: 112.81705474853516
reward_max: 1295.0
reward_min: 1023.0
total_envstep_count: 418073
total_train_sample_count: 418043
total_episode_count: 2554
total_duration: 829.1946932459142
[2022-12-21 15:42:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1046
train_sample_count: 1046
avg_envstep_per_episode: 174.33333333333334
avg_sample_per_episode: 174.33333333333334
avg_envstep_per_sec: 501.60381901654745
avg_train_sample_per_sec: 501.60381901654745
avg_episode_per_sec: 2.877268560324364
collect_time: 2.085311076878969
reward_mean: 922.1666870117188
reward_std: 308.94573974609375
reward_max: 1311.0
reward_min: 614.0
total_envstep_count: 419093
total_train_sample_count: 419053
total_episode_count: 2560
total_duration: 831.2800043227932
[2022-12-21 15:42:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1039
train_sample_count: 1039
avg_envstep_per_episode: 207.8
avg_sample_per_episode: 207.8
avg_envstep_per_sec: 478.85396990127316
avg_train_sample_per_sec: 478.85396990127316
avg_episode_per_sec: 2.3043983152130565
collect_time: 2.169763780415591
reward_mean: 1067.800048828125
reward_std: 646.9266967773438
reward_max: 2324.0
reward_min: 613.0
total_envstep_count: 420090
total_train_sample_count: 420044
total_episode_count: 2565
total_duration: 833.4497681032087
[2022-12-21 15:42:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 910
train_sample_count: 910
avg_envstep_per_episode: 182.0
avg_sample_per_episode: 182.0
avg_envstep_per_sec: 491.1943549089622
avg_train_sample_per_sec: 491.1943549089622
avg_episode_per_sec: 2.698870081917375
collect_time: 1.852627154415606
reward_mean: 890.2000122070312
reward_std: 247.77684020996094
reward_max: 1307.0
reward_min: 626.0
total_envstep_count: 421110
total_train_sample_count: 421074
total_episode_count: 2570
total_duration: 835.3023952576243
[2022-12-21 15:42:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1155
train_sample_count: 1155
avg_envstep_per_episode: 192.5
avg_sample_per_episode: 192.5
avg_envstep_per_sec: 499.6957563345686
avg_train_sample_per_sec: 499.6957563345686
avg_episode_per_sec: 2.595822110828928
collect_time: 2.3114064615483265
reward_mean: 1030.6666259765625
reward_std: 309.9654235839844
reward_max: 1306.0
reward_min: 605.0
total_envstep_count: 422130
total_train_sample_count: 422085
total_episode_count: 2576
total_duration: 837.6138017191727
[2022-12-21 15:42:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 817
train_sample_count: 817
avg_envstep_per_episode: 163.4
avg_sample_per_episode: 163.4
avg_envstep_per_sec: 485.2054524076705
avg_train_sample_per_sec: 485.2054524076705
avg_episode_per_sec: 2.9694336132660375
collect_time: 1.6838227928930096
reward_mean: 842.2000122070312
reward_std: 378.0589294433594
reward_max: 1306.0
reward_min: 231.0
total_envstep_count: 423167
total_train_sample_count: 423118
total_episode_count: 2581
total_duration: 839.2976245120657
[2022-12-21 15:42:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1028
train_sample_count: 1028
avg_envstep_per_episode: 171.33333333333334
avg_sample_per_episode: 171.33333333333334
avg_envstep_per_sec: 481.6572223453757
avg_train_sample_per_sec: 481.6572223453757
avg_episode_per_sec: 2.8112289241948
collect_time: 2.134297903796126
reward_mean: 954.0
reward_std: 488.73577880859375
reward_max: 1549.0
reward_min: 231.0
total_envstep_count: 424155
total_train_sample_count: 424110
total_episode_count: 2587
total_duration: 841.4319224158618
[2022-12-21 15:42:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1012
train_sample_count: 1012
avg_envstep_per_episode: 168.66666666666666
avg_sample_per_episode: 168.66666666666666
avg_envstep_per_sec: 484.41400063129703
avg_train_sample_per_sec: 484.41400063129703
avg_episode_per_sec: 2.8720197665887177
collect_time: 2.089122111832324
reward_mean: 873.6666870117188
reward_std: 472.416748046875
reward_max: 1394.0
reward_min: 231.0
total_envstep_count: 425127
total_train_sample_count: 425110
total_episode_count: 2593
total_duration: 843.5210445276941
[2022-12-21 15:43:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 937
train_sample_count: 937
avg_envstep_per_episode: 156.16666666666666
avg_sample_per_episode: 156.16666666666666
avg_envstep_per_sec: 495.2510226127418
avg_train_sample_per_sec: 495.2510226127418
avg_episode_per_sec: 3.1712979036034694
collect_time: 1.891969844013186
reward_mean: 850.1666870117188
reward_std: 323.368408203125
reward_max: 1122.0
reward_min: 231.0
total_envstep_count: 426108
total_train_sample_count: 426083
total_episode_count: 2599
total_duration: 845.4130143717073
[2022-12-21 15:43:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1417
train_sample_count: 1417
avg_envstep_per_episode: 202.42857142857142
avg_sample_per_episode: 202.42857142857142
avg_envstep_per_sec: 497.58078424964987
avg_train_sample_per_sec: 497.58078424964987
avg_episode_per_sec: 2.458056097210691
collect_time: 2.847778782568606
reward_mean: 1098.0
reward_std: 230.69522094726562
reward_max: 1316.0
reward_min: 626.0
total_envstep_count: 427127
total_train_sample_count: 427092
total_episode_count: 2606
total_duration: 848.2607931542759
[2022-12-21 15:43:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 715
train_sample_count: 715
avg_envstep_per_episode: 178.75
avg_sample_per_episode: 178.75
avg_envstep_per_sec: 502.2091778372321
avg_train_sample_per_sec: 502.2091778372321
avg_episode_per_sec: 2.8095618340544455
collect_time: 1.4237095448537067
reward_mean: 936.0
reward_std: 177.8468475341797
reward_max: 1041.0
reward_min: 628.0
total_envstep_count: 428100
total_train_sample_count: 428071
total_episode_count: 2610
total_duration: 849.6845026991297
[2022-12-21 15:43:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1245
train_sample_count: 1245
avg_envstep_per_episode: 155.625
avg_sample_per_episode: 155.625
avg_envstep_per_sec: 433.6218817722122
avg_train_sample_per_sec: 433.6218817722122
avg_episode_per_sec: 2.786325344721042
collect_time: 2.87116506877302
reward_mean: 829.625
reward_std: 320.93023681640625
reward_max: 1309.0
reward_min: 231.0
total_envstep_count: 429094
total_train_sample_count: 429064
total_episode_count: 2618
total_duration: 852.5556677679027
[2022-12-21 15:43:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 601
train_sample_count: 601
avg_envstep_per_episode: 100.16666666666667
avg_sample_per_episode: 100.16666666666667
avg_envstep_per_sec: 486.18178629262434
avg_train_sample_per_sec: 486.18178629262434
avg_episode_per_sec: 4.853728315733354
collect_time: 1.2361631326893612
reward_mean: 516.1666870117188
reward_std: 211.2442626953125
reward_max: 773.0
reward_min: 223.0
total_envstep_count: 430122
total_train_sample_count: 430085
total_episode_count: 2624
total_duration: 853.7918309005921
[2022-12-21 15:43:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1381
train_sample_count: 1381
avg_envstep_per_episode: 172.625
avg_sample_per_episode: 172.625
avg_envstep_per_sec: 499.33874155618247
avg_train_sample_per_sec: 499.33874155618247
avg_episode_per_sec: 2.89262124000685
collect_time: 2.765657628919663
reward_mean: 814.375
reward_std: 401.95330810546875
reward_max: 1308.0
reward_min: 231.0
total_envstep_count: 431131
total_train_sample_count: 431094
total_episode_count: 2632
total_duration: 856.5574885295118
[2022-12-21 15:43:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1186
train_sample_count: 1186
avg_envstep_per_episode: 148.25
avg_sample_per_episode: 148.25
avg_envstep_per_sec: 485.55680967406016
avg_train_sample_per_sec: 485.55680967406016
avg_episode_per_sec: 3.2752567263005745
collect_time: 2.4425566202976876
reward_mean: 810.25
reward_std: 213.41494750976562
reward_max: 1127.0
reward_min: 606.0
total_envstep_count: 432142
total_train_sample_count: 432112
total_episode_count: 2640
total_duration: 859.0000451498095
[2022-12-21 15:43:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1018
train_sample_count: 1018
avg_envstep_per_episode: 127.25
avg_sample_per_episode: 127.25
avg_envstep_per_sec: 486.5582954426003
avg_train_sample_per_sec: 486.5582954426003
avg_episode_per_sec: 3.8236408286255426
collect_time: 2.0922467246683585
reward_mean: 729.75
reward_std: 275.5829162597656
reward_max: 1048.0
reward_min: 223.0
total_envstep_count: 433151
total_train_sample_count: 433118
total_episode_count: 2648
total_duration: 861.0922918744778
[2022-12-21 15:43:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 945
train_sample_count: 945
avg_envstep_per_episode: 135.0
avg_sample_per_episode: 135.0
avg_envstep_per_sec: 490.1949251411189
avg_train_sample_per_sec: 490.1949251411189
avg_episode_per_sec: 3.6310735195638437
collect_time: 1.927804535569091
reward_mean: 684.2857055664062
reward_std: 148.50657653808594
reward_max: 1027.0
reward_min: 589.0
total_envstep_count: 434147
total_train_sample_count: 434111
total_episode_count: 2655
total_duration: 863.0200964100469
[2022-12-21 15:43:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 219
train_sample_count: 219
avg_envstep_per_episode: 109.5
avg_sample_per_episode: 109.5
avg_envstep_per_sec: 481.23482330209026
avg_train_sample_per_sec: 481.23482330209026
avg_episode_per_sec: 4.394838568968861
collect_time: 0.45507928644333573
reward_mean: 626.5
reward_std: 0.5
reward_max: 627.0
reward_min: 626.0
total_envstep_count: 435122
total_train_sample_count: 435086
total_episode_count: 2657
total_duration: 863.4751756964903
[2022-12-21 15:43:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1296
train_sample_count: 1296
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 490.0418303239289
avg_train_sample_per_sec: 490.0418303239289
avg_episode_per_sec: 2.2687121774255967
collect_time: 2.6446721887870557
reward_mean: 1171.8333740234375
reward_std: 294.3764343261719
reward_max: 1830.0
reward_min: 1035.0
total_envstep_count: 436117
total_train_sample_count: 436082
total_episode_count: 2663
total_duration: 866.1198478852773
[2022-12-21 15:43:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1226
train_sample_count: 1226
avg_envstep_per_episode: 175.14285714285714
avg_sample_per_episode: 175.14285714285714
avg_envstep_per_sec: 498.6586310949572
avg_train_sample_per_sec: 498.6586310949572
avg_episode_per_sec: 2.847153684881485
collect_time: 2.4585957678260635
reward_mean: 898.5714111328125
reward_std: 330.064453125
reward_max: 1293.0
reward_min: 231.0
total_envstep_count: 437081
total_train_sample_count: 437056
total_episode_count: 2670
total_duration: 868.5784436531034
[2022-12-21 15:43:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1110
train_sample_count: 1110
avg_envstep_per_episode: 138.75
avg_sample_per_episode: 138.75
avg_envstep_per_sec: 493.01631084868757
avg_train_sample_per_sec: 493.01631084868757
avg_episode_per_sec: 3.55327070881937
collect_time: 2.2514468093139253
reward_mean: 672.625
reward_std: 339.6512451171875
reward_max: 1291.0
reward_min: 223.0
total_envstep_count: 438082
total_train_sample_count: 438034
total_episode_count: 2678
total_duration: 870.8298904624173
[2022-12-21 15:43:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 820
train_sample_count: 820
avg_envstep_per_episode: 164.0
avg_sample_per_episode: 164.0
avg_envstep_per_sec: 495.6534280076158
avg_train_sample_per_sec: 495.6534280076158
avg_episode_per_sec: 3.0222770000464374
collect_time: 1.6543817790107176
reward_mean: 696.7999877929688
reward_std: 169.2659454345703
reward_max: 1035.0
reward_min: 600.0
total_envstep_count: 439047
total_train_sample_count: 439010
total_episode_count: 2683
total_duration: 872.484272241428
[2022-12-21 15:43:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 937
train_sample_count: 937
avg_envstep_per_episode: 187.4
avg_sample_per_episode: 187.4
avg_envstep_per_sec: 494.77616439364346
avg_train_sample_per_sec: 494.77616439364346
avg_episode_per_sec: 2.640214324405781
collect_time: 1.8937856498166385
reward_mean: 930.7999877929688
reward_std: 365.18017578125
reward_max: 1308.0
reward_min: 231.0
total_envstep_count: 440036
total_train_sample_count: 439995
total_episode_count: 2688
total_duration: 874.3780578912447
[2022-12-21 15:43:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 919
train_sample_count: 919
avg_envstep_per_episode: 183.8
avg_sample_per_episode: 183.8
avg_envstep_per_sec: 500.92255252654826
avg_train_sample_per_sec: 500.92255252654826
avg_episode_per_sec: 2.7253675327886193
collect_time: 1.8346149426987401
reward_mean: 1010.0
reward_std: 219.0205535888672
reward_max: 1310.0
reward_min: 626.0
total_envstep_count: 441039
total_train_sample_count: 440986
total_episode_count: 2693
total_duration: 876.2126728339434
[2022-12-21 15:43:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1119
train_sample_count: 1119
avg_envstep_per_episode: 186.5
avg_sample_per_episode: 186.5
avg_envstep_per_sec: 509.3837795817486
avg_train_sample_per_sec: 509.3837795817486
avg_episode_per_sec: 2.731280319473183
collect_time: 2.1967719524143523
reward_mean: 982.5
reward_std: 167.71876525878906
reward_max: 1129.0
reward_min: 615.0
total_envstep_count: 441985
total_train_sample_count: 441949
total_episode_count: 2699
total_duration: 878.4094447863578
[2022-12-21 15:43:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 899
train_sample_count: 899
avg_envstep_per_episode: 149.83333333333334
avg_sample_per_episode: 149.83333333333334
avg_envstep_per_sec: 508.4901950486214
avg_train_sample_per_sec: 508.4901950486214
avg_episode_per_sec: 3.393705417454648
collect_time: 1.7679790264471833
reward_mean: 820.8333129882812
reward_std: 263.1320495605469
reward_max: 1303.0
reward_min: 590.0
total_envstep_count: 443013
total_train_sample_count: 442980
total_episode_count: 2705
total_duration: 880.1774238128049
[2022-12-21 15:43:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1105
train_sample_count: 1105
avg_envstep_per_episode: 157.85714285714286
avg_sample_per_episode: 157.85714285714286
avg_envstep_per_sec: 499.4290969206805
avg_train_sample_per_sec: 499.4290969206805
avg_episode_per_sec: 3.1638042338866637
collect_time: 2.212526276128234
reward_mean: 838.4285888671875
reward_std: 343.9962158203125
reward_max: 1301.0
reward_min: 217.0
total_envstep_count: 444057
total_train_sample_count: 444001
total_episode_count: 2712
total_duration: 882.3899500889331
[2022-12-21 15:44:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1086
train_sample_count: 1086
avg_envstep_per_episode: 135.75
avg_sample_per_episode: 135.75
avg_envstep_per_sec: 507.08105786022395
avg_train_sample_per_sec: 507.08105786022395
avg_episode_per_sec: 3.735403741143455
collect_time: 2.14166942970162
reward_mean: 739.0
reward_std: 410.8953552246094
reward_max: 1323.0
reward_min: 217.0
total_envstep_count: 445036
total_train_sample_count: 445003
total_episode_count: 2720
total_duration: 884.5316195186348
[2022-12-21 15:44:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 985
train_sample_count: 985
avg_envstep_per_episode: 140.71428571428572
avg_sample_per_episode: 140.71428571428572
avg_envstep_per_sec: 496.5937188168638
avg_train_sample_per_sec: 496.5937188168638
avg_episode_per_sec: 3.5290924179878647
collect_time: 1.9835128046862247
reward_mean: 707.1428833007812
reward_std: 279.8287353515625
reward_max: 1132.0
reward_min: 231.0
total_envstep_count: 446087
total_train_sample_count: 446060
total_episode_count: 2727
total_duration: 886.515132323321
[2022-12-21 15:44:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 668
train_sample_count: 668
avg_envstep_per_episode: 167.0
avg_sample_per_episode: 167.0
avg_envstep_per_sec: 491.53992125506414
avg_train_sample_per_sec: 491.53992125506414
avg_episode_per_sec: 2.9433528218866116
collect_time: 1.3589943992633902
reward_mean: 801.5
reward_std: 337.5355529785156
reward_max: 1386.0
reward_min: 599.0
total_envstep_count: 447068
total_train_sample_count: 447028
total_episode_count: 2731
total_duration: 887.8741267225844
[2022-12-21 15:44:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1152
train_sample_count: 1152
avg_envstep_per_episode: 164.57142857142858
avg_sample_per_episode: 164.57142857142858
avg_envstep_per_sec: 497.04375228582046
avg_train_sample_per_sec: 497.04375228582046
avg_episode_per_sec: 3.0202311336812007
collect_time: 2.31770341082077
reward_mean: 843.4285888671875
reward_std: 337.15399169921875
reward_max: 1304.0
reward_min: 231.0
total_envstep_count: 448073
total_train_sample_count: 448036
total_episode_count: 2738
total_duration: 890.1918301334051
[2022-12-21 15:44:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1188
train_sample_count: 1188
avg_envstep_per_episode: 148.5
avg_sample_per_episode: 148.5
avg_envstep_per_sec: 513.7058920915091
avg_train_sample_per_sec: 513.7058920915091
avg_episode_per_sec: 3.459298936643159
collect_time: 2.312607307584425
reward_mean: 743.5
reward_std: 360.7190856933594
reward_max: 1308.0
reward_min: 231.0
total_envstep_count: 449114
total_train_sample_count: 449068
total_episode_count: 2746
total_duration: 892.5044374409896
[2022-12-21 15:44:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 188.33333333333334
avg_sample_per_episode: 188.33333333333334
avg_envstep_per_sec: 518.8068642529797
avg_train_sample_per_sec: 518.8068642529797
avg_episode_per_sec: 2.75472671284768
collect_time: 2.1780744971966897
reward_mean: 1015.0
reward_std: 204.19189453125
reward_max: 1309.0
reward_min: 614.0
total_envstep_count: 450087
total_train_sample_count: 450054
total_episode_count: 2752
total_duration: 894.6825119381863
[2022-12-21 15:44:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 581
train_sample_count: 581
avg_envstep_per_episode: 145.25
avg_sample_per_episode: 145.25
avg_envstep_per_sec: 506.8259332007107
avg_train_sample_per_sec: 506.8259332007107
avg_episode_per_sec: 3.4893351683353577
collect_time: 1.1463501804867495
reward_mean: 871.0
reward_std: 464.0210266113281
reward_max: 1317.0
reward_min: 231.0
total_envstep_count: 451084
total_train_sample_count: 451031
total_episode_count: 2756
total_duration: 895.828862118673
[2022-12-21 15:44:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1147
train_sample_count: 1147
avg_envstep_per_episode: 191.16666666666666
avg_sample_per_episode: 191.16666666666666
avg_envstep_per_sec: 500.5610983534071
avg_train_sample_per_sec: 500.5610983534071
avg_episode_per_sec: 2.6184538710727483
collect_time: 2.291428566408876
reward_mean: 993.3333129882812
reward_std: 361.119384765625
reward_max: 1308.0
reward_min: 231.0
total_envstep_count: 452079
total_train_sample_count: 452046
total_episode_count: 2762
total_duration: 898.1202906850818
[2022-12-21 15:44:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1177
train_sample_count: 1177
avg_envstep_per_episode: 130.77777777777777
avg_sample_per_episode: 130.77777777777777
avg_envstep_per_sec: 507.76881560987124
avg_train_sample_per_sec: 507.76881560987124
avg_episode_per_sec: 3.882684231511335
collect_time: 2.317984019137387
reward_mean: 708.2222290039062
reward_std: 393.3951416015625
reward_max: 1312.0
reward_min: 223.0
total_envstep_count: 453087
total_train_sample_count: 453055
total_episode_count: 2771
total_duration: 900.4382747042192
[2022-12-21 15:44:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 786
train_sample_count: 786
avg_envstep_per_episode: 157.2
avg_sample_per_episode: 157.2
avg_envstep_per_sec: 510.1765194680138
avg_train_sample_per_sec: 510.1765194680138
avg_episode_per_sec: 3.2453977065395283
collect_time: 1.5406432283861298
reward_mean: 847.7999877929688
reward_std: 163.8272247314453
reward_max: 1037.0
reward_min: 626.0
total_envstep_count: 454091
total_train_sample_count: 454045
total_episode_count: 2776
total_duration: 901.9789179326053
[2022-12-21 15:44:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 183
train_sample_count: 183
avg_envstep_per_episode: 183.0
avg_sample_per_episode: 183.0
avg_envstep_per_sec: 509.2836528924214
avg_train_sample_per_sec: 509.2836528924214
avg_episode_per_sec: 2.782970780832904
collect_time: 0.3593282426417406
reward_mean: 1046.0
reward_std: 0.0
reward_max: 1046.0
reward_min: 1046.0
total_envstep_count: 455050
total_train_sample_count: 455008
total_episode_count: 2777
total_duration: 902.338246175247
[2022-12-21 15:44:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1481
train_sample_count: 1481
avg_envstep_per_episode: 211.57142857142858
avg_sample_per_episode: 211.57142857142858
avg_envstep_per_sec: 504.7788514507303
avg_train_sample_per_sec: 504.7788514507303
avg_episode_per_sec: 2.3858554761344446
collect_time: 2.9339581001534
reward_mean: 1103.2857666015625
reward_std: 248.84230041503906
reward_max: 1410.0
reward_min: 604.0
total_envstep_count: 456036
total_train_sample_count: 456009
total_episode_count: 2784
total_duration: 905.2722042754004
[2022-12-21 15:44:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 644
train_sample_count: 644
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 494.86816614370355
avg_train_sample_per_sec: 494.86816614370355
avg_episode_per_sec: 3.0737153176627547
collect_time: 1.3013566926691147
reward_mean: 836.25
reward_std: 349.5213623046875
reward_max: 1046.0
reward_min: 231.0
total_envstep_count: 457041
total_train_sample_count: 456989
total_episode_count: 2788
total_duration: 906.5735609680695
[2022-12-21 15:44:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1911
train_sample_count: 1911
avg_envstep_per_episode: 212.33333333333334
avg_sample_per_episode: 212.33333333333334
avg_envstep_per_sec: 498.280712421346
avg_train_sample_per_sec: 498.280712421346
avg_episode_per_sec: 2.346690953318741
collect_time: 3.8351875807387446
reward_mean: 947.6666870117188
reward_std: 571.0166625976562
reward_max: 2265.0
reward_min: 231.0
total_envstep_count: 458024
total_train_sample_count: 457988
total_episode_count: 2797
total_duration: 910.4087485488083
[2022-12-21 15:44:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 549
train_sample_count: 549
avg_envstep_per_episode: 183.0
avg_sample_per_episode: 183.0
avg_envstep_per_sec: 500.23878277430595
avg_train_sample_per_sec: 500.23878277430595
avg_episode_per_sec: 2.733545261061781
collect_time: 1.0974758833276903
reward_mean: 945.3333129882812
reward_std: 132.52755737304688
reward_max: 1044.0
reward_min: 758.0
total_envstep_count: 459029
total_train_sample_count: 458993
total_episode_count: 2800
total_duration: 911.5062244321359
[2022-12-21 15:44:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1146
train_sample_count: 1146
avg_envstep_per_episode: 229.2
avg_sample_per_episode: 229.2
avg_envstep_per_sec: 500.8638917312346
avg_train_sample_per_sec: 500.8638917312346
avg_episode_per_sec: 2.18527003373139
collect_time: 2.2880467506628483
reward_mean: 1331.4000244140625
reward_std: 373.19732666015625
reward_max: 1896.0
reward_min: 722.0
total_envstep_count: 460018
total_train_sample_count: 459983
total_episode_count: 2805
total_duration: 913.7942711827988
[2022-12-21 15:44:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 864
train_sample_count: 864
avg_envstep_per_episode: 288.0
avg_sample_per_episode: 288.0
avg_envstep_per_sec: 497.9341603933671
avg_train_sample_per_sec: 497.9341603933671
avg_episode_per_sec: 1.7289380569214137
collect_time: 1.735169162359621
reward_mean: 1423.3333740234375
reward_std: 165.2681427001953
reward_max: 1657.0
reward_min: 1302.0
total_envstep_count: 461007
total_train_sample_count: 460967
total_episode_count: 2808
total_duration: 915.5294403451584
[2022-12-21 15:44:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1592
train_sample_count: 1592
avg_envstep_per_episode: 176.88888888888889
avg_sample_per_episode: 176.88888888888889
avg_envstep_per_sec: 511.39452888069496
avg_train_sample_per_sec: 511.39452888069496
avg_episode_per_sec: 2.891049472315487
collect_time: 3.113056378378665
reward_mean: 994.3333129882812
reward_std: 339.38671875
reward_max: 1312.0
reward_min: 231.0
total_envstep_count: 462008
total_train_sample_count: 461971
total_episode_count: 2817
total_duration: 918.6424967235371
[2022-12-21 15:44:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 414
train_sample_count: 414
avg_envstep_per_episode: 103.5
avg_sample_per_episode: 103.5
avg_envstep_per_sec: 505.6120392288954
avg_train_sample_per_sec: 505.6120392288954
avg_episode_per_sec: 4.885140475641502
collect_time: 0.8188096166210517
reward_mean: 584.75
reward_std: 379.801513671875
reward_max: 1134.0
reward_min: 231.0
total_envstep_count: 463004
total_train_sample_count: 462961
total_episode_count: 2821
total_duration: 919.4613063401581
[2022-12-21 15:45:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1170
train_sample_count: 1170
avg_envstep_per_episode: 195.0
avg_sample_per_episode: 195.0
avg_envstep_per_sec: 501.852238520155
avg_train_sample_per_sec: 501.852238520155
avg_episode_per_sec: 2.5736012231802823
collect_time: 2.3313635173772593
reward_mean: 1038.3333740234375
reward_std: 223.5767364501953
reward_max: 1310.0
reward_min: 745.0
total_envstep_count: 464006
total_train_sample_count: 463987
total_episode_count: 2827
total_duration: 921.7926698575353
[2022-12-21 15:45:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1183
train_sample_count: 1183
avg_envstep_per_episode: 169.0
avg_sample_per_episode: 169.0
avg_envstep_per_sec: 481.1260054924946
avg_train_sample_per_sec: 481.1260054924946
avg_episode_per_sec: 2.8468994407839916
collect_time: 2.458815334226315
reward_mean: 848.4285888671875
reward_std: 346.6714782714844
reward_max: 1295.0
reward_min: 231.0
total_envstep_count: 465000
total_train_sample_count: 464966
total_episode_count: 2834
total_duration: 924.2514851917616
[2022-12-21 15:45:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 799
train_sample_count: 799
avg_envstep_per_episode: 159.8
avg_sample_per_episode: 159.8
avg_envstep_per_sec: 485.082881424032
avg_train_sample_per_sec: 485.082881424032
avg_episode_per_sec: 3.035562461977672
collect_time: 1.6471412012199198
reward_mean: 715.2000122070312
reward_std: 427.8609313964844
reward_max: 1302.0
reward_min: 231.0
total_envstep_count: 466011
total_train_sample_count: 465969
total_episode_count: 2839
total_duration: 925.8986263929816
[2022-12-21 15:45:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 671
train_sample_count: 671
avg_envstep_per_episode: 167.75
avg_sample_per_episode: 167.75
avg_envstep_per_sec: 494.49933740243836
avg_train_sample_per_sec: 494.49933740243836
avg_episode_per_sec: 2.9478350962887534
collect_time: 1.3569280062632725
reward_mean: 874.75
reward_std: 214.61404418945312
reward_max: 1123.0
reward_min: 605.0
total_envstep_count: 466984
total_train_sample_count: 466940
total_episode_count: 2843
total_duration: 927.2555543992448
[2022-12-21 15:45:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1032
train_sample_count: 1032
avg_envstep_per_episode: 206.4
avg_sample_per_episode: 206.4
avg_envstep_per_sec: 497.6075463470237
avg_train_sample_per_sec: 497.6075463470237
avg_episode_per_sec: 2.4108892749371305
collect_time: 2.073923531859582
reward_mean: 1099.199951171875
reward_std: 308.6223449707031
reward_max: 1665.0
reward_min: 719.0
total_envstep_count: 467987
total_train_sample_count: 467936
total_episode_count: 2848
total_duration: 929.3294779311044
[2022-12-21 15:45:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 654
train_sample_count: 654
avg_envstep_per_episode: 163.5
avg_sample_per_episode: 163.5
avg_envstep_per_sec: 506.6288737353074
avg_train_sample_per_sec: 506.6288737353074
avg_episode_per_sec: 3.098647545781697
collect_time: 1.2908857625467431
reward_mean: 832.75
reward_std: 397.9927062988281
reward_max: 1304.0
reward_min: 231.0
total_envstep_count: 468967
total_train_sample_count: 468938
total_episode_count: 2852
total_duration: 930.6203636936511
[2022-12-21 15:45:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 995
train_sample_count: 995
avg_envstep_per_episode: 199.0
avg_sample_per_episode: 199.0
avg_envstep_per_sec: 503.60784781928004
avg_train_sample_per_sec: 503.60784781928004
avg_episode_per_sec: 2.5306927026094472
collect_time: 1.9757436352680833
reward_mean: 1119.0
reward_std: 424.0999755859375
reward_max: 1890.0
reward_min: 584.0
total_envstep_count: 469996
total_train_sample_count: 469981
total_episode_count: 2857
total_duration: 932.5961073289192
[2022-12-21 15:45:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1812
train_sample_count: 1812
avg_envstep_per_episode: 258.85714285714283
avg_sample_per_episode: 258.85714285714283
avg_envstep_per_sec: 507.1838314709371
avg_train_sample_per_sec: 507.1838314709371
avg_episode_per_sec: 1.959319437249757
collect_time: 3.5726690946452857
reward_mean: 961.0
reward_std: 190.612548828125
reward_max: 1216.0
reward_min: 606.0
total_envstep_count: 471085
total_train_sample_count: 471049
total_episode_count: 2864
total_duration: 936.1687764235645
[2022-12-21 15:45:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 584
train_sample_count: 584
avg_envstep_per_episode: 194.66666666666666
avg_sample_per_episode: 194.66666666666666
avg_envstep_per_sec: 510.34036640033264
avg_train_sample_per_sec: 510.34036640033264
avg_episode_per_sec: 2.6216114712345857
collect_time: 1.1443343275375666
reward_mean: 1039.6666259765625
reward_std: 4.496912479400635
reward_max: 1046.0
reward_min: 1036.0
total_envstep_count: 472042
total_train_sample_count: 472017
total_episode_count: 2867
total_duration: 937.313110751102
[2022-12-21 15:45:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1276
train_sample_count: 1276
avg_envstep_per_episode: 182.28571428571428
avg_sample_per_episode: 182.28571428571428
avg_envstep_per_sec: 508.3812125805515
avg_train_sample_per_sec: 508.3812125805515
avg_episode_per_sec: 2.788925147385471
collect_time: 2.509927527657843
reward_mean: 899.2857055664062
reward_std: 331.9955749511719
reward_max: 1318.0
reward_min: 231.0
total_envstep_count: 473028
total_train_sample_count: 473005
total_episode_count: 2874
total_duration: 939.8230382787599
[2022-12-21 15:45:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1104
train_sample_count: 1104
avg_envstep_per_episode: 220.8
avg_sample_per_episode: 220.8
avg_envstep_per_sec: 507.1292190135307
avg_train_sample_per_sec: 507.1292190135307
avg_episode_per_sec: 2.2967808832134544
collect_time: 2.176959951444928
reward_mean: 1215.800048828125
reward_std: 423.7633361816406
reward_max: 1825.0
reward_min: 618.0
total_envstep_count: 474016
total_train_sample_count: 473977
total_episode_count: 2879
total_duration: 941.9999982302048
[2022-12-21 15:45:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 700
train_sample_count: 700
avg_envstep_per_episode: 233.33333333333334
avg_sample_per_episode: 233.33333333333334
avg_envstep_per_sec: 512.3030811061303
avg_train_sample_per_sec: 512.3030811061303
avg_episode_per_sec: 2.195584633311987
collect_time: 1.3663786649274237
reward_mean: 1324.3333740234375
reward_std: 403.5892028808594
reward_max: 1895.0
reward_min: 1030.0
total_envstep_count: 474998
total_train_sample_count: 474953
total_episode_count: 2882
total_duration: 943.3663768951322
[2022-12-21 15:45:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1015
train_sample_count: 1015
avg_envstep_per_episode: 169.16666666666666
avg_sample_per_episode: 169.16666666666666
avg_envstep_per_sec: 510.3501934783774
avg_train_sample_per_sec: 510.3501934783774
avg_episode_per_sec: 3.01684843435494
collect_time: 1.9888304402945303
reward_mean: 873.0
reward_std: 311.08465576171875
reward_max: 1130.0
reward_min: 223.0
total_envstep_count: 475976
total_train_sample_count: 475944
total_episode_count: 2888
total_duration: 945.3552073354268
[2022-12-21 15:45:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 983
train_sample_count: 983
avg_envstep_per_episode: 196.6
avg_sample_per_episode: 196.6
avg_envstep_per_sec: 505.1893270282242
avg_train_sample_per_sec: 505.1893270282242
avg_episode_per_sec: 2.569630351109991
collect_time: 1.9458051613689002
reward_mean: 1149.0
reward_std: 136.00881958007812
reward_max: 1321.0
reward_min: 1034.0
total_envstep_count: 477003
total_train_sample_count: 476951
total_episode_count: 2893
total_duration: 947.3010124967957
[2022-12-21 15:45:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 590
train_sample_count: 590
avg_envstep_per_episode: 147.5
avg_sample_per_episode: 147.5
avg_envstep_per_sec: 498.4675713919428
avg_train_sample_per_sec: 498.4675713919428
avg_episode_per_sec: 3.379441161979273
collect_time: 1.183627649743509
reward_mean: 740.0
reward_std: 177.2018585205078
reward_max: 1035.0
reward_min: 594.0
total_envstep_count: 477976
total_train_sample_count: 477949
total_episode_count: 2897
total_duration: 948.4846401465392
[2022-12-21 15:45:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1644
train_sample_count: 1644
avg_envstep_per_episode: 234.85714285714286
avg_sample_per_episode: 234.85714285714286
avg_envstep_per_sec: 492.528091733897
avg_train_sample_per_sec: 492.528091733897
avg_episode_per_sec: 2.097139076725839
collect_time: 3.337880676435041
reward_mean: 1231.7142333984375
reward_std: 827.556396484375
reward_max: 2994.0
reward_min: 231.0
total_envstep_count: 478964
total_train_sample_count: 478933
total_episode_count: 2904
total_duration: 951.8225208229742
[2022-12-21 15:45:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1061
train_sample_count: 1061
avg_envstep_per_episode: 176.83333333333334
avg_sample_per_episode: 176.83333333333334
avg_envstep_per_sec: 489.8058891159314
avg_train_sample_per_sec: 489.8058891159314
avg_episode_per_sec: 2.7698730769986697
collect_time: 2.1661642368470453
reward_mean: 912.3333129882812
reward_std: 282.4214782714844
reward_max: 1410.0
reward_min: 609.0
total_envstep_count: 479943
total_train_sample_count: 479922
total_episode_count: 2910
total_duration: 953.9886850598213
[2022-12-21 15:45:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 921
train_sample_count: 921
avg_envstep_per_episode: 153.5
avg_sample_per_episode: 153.5
avg_envstep_per_sec: 479.902993933459
avg_train_sample_per_sec: 479.902993933459
avg_episode_per_sec: 3.1264038692733487
collect_time: 1.9191378500291276
reward_mean: 816.5
reward_std: 354.5789794921875
reward_max: 1311.0
reward_min: 222.0
total_envstep_count: 480947
total_train_sample_count: 480903
total_episode_count: 2916
total_duration: 955.9078229098503
[2022-12-21 15:46:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1024
train_sample_count: 1024
avg_envstep_per_episode: 204.8
avg_sample_per_episode: 204.8
avg_envstep_per_sec: 489.5032807912349
avg_train_sample_per_sec: 489.5032807912349
avg_episode_per_sec: 2.3901527382384518
collect_time: 2.0919165206508987
reward_mean: 1021.0
reward_std: 257.5857238769531
reward_max: 1310.0
reward_min: 719.0
total_envstep_count: 481975
total_train_sample_count: 481927
total_episode_count: 2921
total_duration: 957.9997394305012
[2022-12-21 15:46:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1099
train_sample_count: 1099
avg_envstep_per_episode: 157.0
avg_sample_per_episode: 157.0
avg_envstep_per_sec: 501.8788895723887
avg_train_sample_per_sec: 501.8788895723887
avg_episode_per_sec: 3.196680825301839
collect_time: 2.189771322990634
reward_mean: 815.5714111328125
reward_std: 290.06298828125
reward_max: 1045.0
reward_min: 231.0
total_envstep_count: 482947
total_train_sample_count: 482918
total_episode_count: 2928
total_duration: 960.1895107534918
[2022-12-21 15:46:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 756
train_sample_count: 756
avg_envstep_per_episode: 151.2
avg_sample_per_episode: 151.2
avg_envstep_per_sec: 506.1625442461646
avg_train_sample_per_sec: 506.1625442461646
avg_episode_per_sec: 3.3476358746439456
collect_time: 1.493591354385817
reward_mean: 870.0
reward_std: 206.20669555664062
reward_max: 1039.0
reward_min: 611.0
total_envstep_count: 483919
total_train_sample_count: 483890
total_episode_count: 2933
total_duration: 961.6831021078776
[2022-12-21 15:46:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1093
train_sample_count: 1093
avg_envstep_per_episode: 182.16666666666666
avg_sample_per_episode: 182.16666666666666
avg_envstep_per_sec: 502.94244549748623
avg_train_sample_per_sec: 502.94244549748623
avg_episode_per_sec: 2.760891741065798
collect_time: 2.1732108907985634
reward_mean: 1038.5
reward_std: 274.2691955566406
reward_max: 1411.0
reward_min: 609.0
total_envstep_count: 484954
total_train_sample_count: 484911
total_episode_count: 2939
total_duration: 963.8563129986762
[2022-12-21 15:46:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1045
train_sample_count: 1045
avg_envstep_per_episode: 209.0
avg_sample_per_episode: 209.0
avg_envstep_per_sec: 499.6524951083603
avg_train_sample_per_sec: 499.6524951083603
avg_episode_per_sec: 2.3906817947768437
collect_time: 2.091453580699861
reward_mean: 1052.199951171875
reward_std: 420.6924743652344
reward_max: 1828.0
reward_min: 623.0
total_envstep_count: 485911
total_train_sample_count: 485884
total_episode_count: 2944
total_duration: 965.9477665793761
[2022-12-21 15:46:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1040
train_sample_count: 1040
avg_envstep_per_episode: 173.33333333333334
avg_sample_per_episode: 173.33333333333334
avg_envstep_per_sec: 502.55765009343156
avg_train_sample_per_sec: 502.55765009343156
avg_episode_per_sec: 2.8993710582313357
collect_time: 2.0694143245190904
reward_mean: 1003.3333129882812
reward_std: 620.971435546875
reward_max: 1831.0
reward_min: 231.0
total_envstep_count: 486906
total_train_sample_count: 486864
total_episode_count: 2950
total_duration: 968.0171809038952
[2022-12-21 15:46:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 885
train_sample_count: 885
avg_envstep_per_episode: 177.0
avg_sample_per_episode: 177.0
avg_envstep_per_sec: 510.8255982781138
avg_train_sample_per_sec: 510.8255982781138
avg_episode_per_sec: 2.88602032925488
collect_time: 1.732489528682881
reward_mean: 949.5999755859375
reward_std: 183.32223510742188
reward_max: 1046.0
reward_min: 583.0
total_envstep_count: 487902
total_train_sample_count: 487869
total_episode_count: 2955
total_duration: 969.7496704325781
[2022-12-21 15:46:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 949
train_sample_count: 949
avg_envstep_per_episode: 158.16666666666666
avg_sample_per_episode: 158.16666666666666
avg_envstep_per_sec: 503.3762674296391
avg_train_sample_per_sec: 503.3762674296391
avg_episode_per_sec: 3.182568603348614
collect_time: 1.885269650962735
reward_mean: 948.3333129882812
reward_std: 570.59814453125
reward_max: 1831.0
reward_min: 231.0
total_envstep_count: 488897
total_train_sample_count: 488866
total_episode_count: 2961
total_duration: 971.6349400835409
[2022-12-21 15:46:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 951
train_sample_count: 951
avg_envstep_per_episode: 190.2
avg_sample_per_episode: 190.2
avg_envstep_per_sec: 501.8617375469917
avg_train_sample_per_sec: 501.8617375469917
avg_episode_per_sec: 2.638600092255477
collect_time: 1.8949442223834674
reward_mean: 976.2000122070312
reward_std: 121.70357513427734
reward_max: 1045.0
reward_min: 733.0
total_envstep_count: 489892
total_train_sample_count: 489853
total_episode_count: 2966
total_duration: 973.5298843059244
[2022-12-21 15:46:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1056
train_sample_count: 1056
avg_envstep_per_episode: 211.2
avg_sample_per_episode: 211.2
avg_envstep_per_sec: 506.14077192238307
avg_train_sample_per_sec: 506.14077192238307
avg_episode_per_sec: 2.396499867056738
collect_time: 2.0863760806883547
reward_mean: 1066.4000244140625
reward_std: 213.51026916503906
reward_max: 1401.0
reward_min: 734.0
total_envstep_count: 490865
total_train_sample_count: 490825
total_episode_count: 2971
total_duration: 975.6162603866128
[2022-12-21 15:46:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1002
train_sample_count: 1002
avg_envstep_per_episode: 167.0
avg_sample_per_episode: 167.0
avg_envstep_per_sec: 518.2336198621933
avg_train_sample_per_sec: 518.2336198621933
avg_episode_per_sec: 3.1031953285161276
collect_time: 1.9334909230058213
reward_mean: 935.6666870117188
reward_std: 302.6299743652344
reward_max: 1310.0
reward_min: 600.0
total_envstep_count: 491870
total_train_sample_count: 491827
total_episode_count: 2977
total_duration: 977.5497513096186
[2022-12-21 15:46:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1115
train_sample_count: 1115
avg_envstep_per_episode: 159.28571428571428
avg_sample_per_episode: 159.28571428571428
avg_envstep_per_sec: 514.0872931975653
avg_train_sample_per_sec: 514.0872931975653
avg_episode_per_sec: 3.227453858639423
collect_time: 2.168892354963347
reward_mean: 849.5714111328125
reward_std: 257.7262268066406
reward_max: 1301.0
reward_min: 606.0
total_envstep_count: 492864
total_train_sample_count: 492822
total_episode_count: 2984
total_duration: 979.7186436645819
[2022-12-21 15:46:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 496
train_sample_count: 496
avg_envstep_per_episode: 165.33333333333334
avg_sample_per_episode: 165.33333333333334
avg_envstep_per_sec: 493.3772772220886
avg_train_sample_per_sec: 493.3772772220886
avg_episode_per_sec: 2.984136757391665
collect_time: 1.00531585644292
reward_mean: 923.0
reward_std: 233.336669921875
reward_max: 1135.0
reward_min: 598.0
total_envstep_count: 493837
total_train_sample_count: 493798
total_episode_count: 2987
total_duration: 980.7239595210249
[2022-12-21 15:46:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1303
train_sample_count: 1303
avg_envstep_per_episode: 217.16666666666666
avg_sample_per_episode: 217.16666666666666
avg_envstep_per_sec: 501.1049873047501
avg_train_sample_per_sec: 501.1049873047501
avg_episode_per_sec: 2.307467324503838
collect_time: 2.6002535057739755
reward_mean: 1250.3333740234375
reward_std: 123.84622955322266
reward_max: 1409.0
reward_min: 1046.0
total_envstep_count: 494873
total_train_sample_count: 494837
total_episode_count: 2993
total_duration: 983.3242130267988
[2022-12-21 15:46:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1119
train_sample_count: 1119
avg_envstep_per_episode: 186.5
avg_sample_per_episode: 186.5
avg_envstep_per_sec: 511.85199774849895
avg_train_sample_per_sec: 511.85199774849895
avg_episode_per_sec: 2.744514733235919
collect_time: 2.1861788269308002
reward_mean: 1080.0
reward_std: 418.5888977050781
reward_max: 1551.0
reward_min: 231.0
total_envstep_count: 495868
total_train_sample_count: 495836
total_episode_count: 2999
total_duration: 985.5103918537296
[2022-12-21 15:46:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 652
train_sample_count: 652
avg_envstep_per_episode: 217.33333333333334
avg_sample_per_episode: 217.33333333333334
avg_envstep_per_sec: 508.3521216717859
avg_train_sample_per_sec: 508.3521216717859
avg_episode_per_sec: 2.3390435046247817
collect_time: 1.2825755459735435
reward_mean: 1122.3333740234375
reward_std: 127.76106262207031
reward_max: 1303.0
reward_min: 1030.0
total_envstep_count: 496850
total_train_sample_count: 496812
total_episode_count: 3002
total_duration: 986.7929673997032
[2022-12-21 15:47:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1410
train_sample_count: 1410
avg_envstep_per_episode: 176.25
avg_sample_per_episode: 176.25
avg_envstep_per_sec: 519.9574940610198
avg_train_sample_per_sec: 519.9574940610198
avg_episode_per_sec: 2.9501134414809638
collect_time: 2.7117601267509164
reward_mean: 1006.5
reward_std: 314.8686218261719
reward_max: 1318.0
reward_min: 231.0
total_envstep_count: 497866
total_train_sample_count: 497802
total_episode_count: 3010
total_duration: 989.5047275264542
[2022-12-21 15:47:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 892
train_sample_count: 892
avg_envstep_per_episode: 178.4
avg_sample_per_episode: 178.4
avg_envstep_per_sec: 498.7735554319245
avg_train_sample_per_sec: 498.7735554319245
avg_episode_per_sec: 2.7958158936767066
collect_time: 1.7883867143428485
reward_mean: 995.0
reward_std: 320.861328125
reward_max: 1318.0
reward_min: 597.0
total_envstep_count: 498855
total_train_sample_count: 498838
total_episode_count: 3015
total_duration: 991.2931142407971
[2022-12-21 15:47:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 789
train_sample_count: 789
avg_envstep_per_episode: 157.8
avg_sample_per_episode: 157.8
avg_envstep_per_sec: 497.19011925804887
avg_train_sample_per_sec: 497.19011925804887
avg_episode_per_sec: 3.150761212028193
collect_time: 1.5869181012233624
reward_mean: 811.7999877929688
reward_std: 316.5807189941406
reward_max: 1045.0
reward_min: 231.0
total_envstep_count: 499884
total_train_sample_count: 499831
total_episode_count: 3020
total_duration: 992.8800323420204
[2022-12-21 15:47:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1245
train_sample_count: 1245
avg_envstep_per_episode: 207.5
avg_sample_per_episode: 207.5
avg_envstep_per_sec: 501.8769499691185
avg_train_sample_per_sec: 501.8769499691185
avg_episode_per_sec: 2.4186840962367158
collect_time: 2.4806877464219212
reward_mean: 1025.0
reward_std: 486.3777770996094
reward_max: 1818.0
reward_min: 223.0
total_envstep_count: 500839
total_train_sample_count: 500812
total_episode_count: 3026
total_duration: 995.3607200884423
[2022-12-21 15:47:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 903
train_sample_count: 903
avg_envstep_per_episode: 180.6
avg_sample_per_episode: 180.6
avg_envstep_per_sec: 506.6525020984348
avg_train_sample_per_sec: 506.6525020984348
avg_episode_per_sec: 2.805384839969185
collect_time: 1.7822866683969538
reward_mean: 932.0
reward_std: 365.24896240234375
reward_max: 1306.0
reward_min: 231.0
total_envstep_count: 501867
total_train_sample_count: 501823
total_episode_count: 3031
total_duration: 997.1430067568393
[2022-12-21 15:47:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 987
train_sample_count: 987
avg_envstep_per_episode: 164.5
avg_sample_per_episode: 164.5
avg_envstep_per_sec: 491.9438905377084
avg_train_sample_per_sec: 491.9438905377084
avg_episode_per_sec: 2.9905403680103855
collect_time: 2.006326369702816
reward_mean: 912.8333129882812
reward_std: 429.14385986328125
reward_max: 1322.0
reward_min: 215.0
total_envstep_count: 502879
total_train_sample_count: 502846
total_episode_count: 3037
total_duration: 999.1493331265422
[2022-12-21 15:47:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 688
train_sample_count: 688
avg_envstep_per_episode: 229.33333333333334
avg_sample_per_episode: 229.33333333333334
avg_envstep_per_sec: 489.80460564007035
avg_train_sample_per_sec: 489.80460564007035
avg_episode_per_sec: 2.1357758966863534
collect_time: 1.4046417532169393
reward_mean: 1236.3333740234375
reward_std: 219.9307861328125
reward_max: 1544.0
reward_min: 1043.0
total_envstep_count: 503838
total_train_sample_count: 503810
total_episode_count: 3040
total_duration: 1000.5539748797592
[2022-12-21 15:47:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1545
train_sample_count: 1545
avg_envstep_per_episode: 171.66666666666666
avg_sample_per_episode: 171.66666666666666
avg_envstep_per_sec: 499.39732597899405
avg_train_sample_per_sec: 499.39732597899405
avg_episode_per_sec: 2.9091106367708393
collect_time: 3.093729020217034
reward_mean: 858.2222290039062
reward_std: 488.82757568359375
reward_max: 1550.0
reward_min: 218.0
total_envstep_count: 504879
total_train_sample_count: 504851
total_episode_count: 3049
total_duration: 1003.6477038999761
[2022-12-21 15:47:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1143
train_sample_count: 1143
avg_envstep_per_episode: 190.5
avg_sample_per_episode: 190.5
avg_envstep_per_sec: 426.4004362485161
avg_train_sample_per_sec: 426.4004362485161
avg_episode_per_sec: 2.2383224999922104
collect_time: 2.6805788710165226
reward_mean: 1057.0
reward_std: 241.94558715820312
reward_max: 1313.0
reward_min: 585.0
total_envstep_count: 505883
total_train_sample_count: 505838
total_episode_count: 3055
total_duration: 1006.3282827709927
[2022-12-21 15:47:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 542
train_sample_count: 542
avg_envstep_per_episode: 180.66666666666666
avg_sample_per_episode: 180.66666666666666
avg_envstep_per_sec: 498.32752011823226
avg_train_sample_per_sec: 498.32752011823226
avg_episode_per_sec: 2.758270406558481
collect_time: 1.0876381057008573
reward_mean: 884.3333129882812
reward_std: 206.7306365966797
reward_max: 1034.0
reward_min: 592.0
total_envstep_count: 506857
total_train_sample_count: 506824
total_episode_count: 3058
total_duration: 1007.4159208766936
[2022-12-21 15:47:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1237
train_sample_count: 1237
avg_envstep_per_episode: 206.16666666666666
avg_sample_per_episode: 206.16666666666666
avg_envstep_per_sec: 499.8678736395309
avg_train_sample_per_sec: 499.8678736395309
avg_episode_per_sec: 2.424581440450433
collect_time: 2.4746539340354494
reward_mean: 1136.3333740234375
reward_std: 397.38299560546875
reward_max: 1892.0
reward_min: 713.0
total_envstep_count: 507861
total_train_sample_count: 507821
total_episode_count: 3064
total_duration: 1009.890574810729
[2022-12-21 15:47:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 720
train_sample_count: 720
avg_envstep_per_episode: 180.0
avg_sample_per_episode: 180.0
avg_envstep_per_sec: 507.4262966399341
avg_train_sample_per_sec: 507.4262966399341
avg_episode_per_sec: 2.819034981332967
collect_time: 1.4189252799227838
reward_mean: 1037.0
reward_std: 397.7876281738281
reward_max: 1674.0
reward_min: 618.0
total_envstep_count: 508834
total_train_sample_count: 508805
total_episode_count: 3068
total_duration: 1011.3095000906518
[2022-12-21 15:48:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1210
train_sample_count: 1210
avg_envstep_per_episode: 151.25
avg_sample_per_episode: 151.25
avg_envstep_per_sec: 504.4966420935908
avg_train_sample_per_sec: 504.4966420935908
avg_episode_per_sec: 3.3355149890485345
collect_time: 2.3984302352909
reward_mean: 819.125
reward_std: 384.1218566894531
reward_max: 1315.0
reward_min: 231.0
total_envstep_count: 509836
total_train_sample_count: 509787
total_episode_count: 3076
total_duration: 1013.7079303259427
[2022-12-21 15:48:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 923
train_sample_count: 923
avg_envstep_per_episode: 184.6
avg_sample_per_episode: 184.6
avg_envstep_per_sec: 498.8223142473264
avg_train_sample_per_sec: 498.8223142473264
avg_episode_per_sec: 2.7021793837883337
collect_time: 1.8503582811701513
reward_mean: 927.5999755859375
reward_std: 264.3532409667969
reward_max: 1302.0
reward_min: 615.0
total_envstep_count: 510847
total_train_sample_count: 510794
total_episode_count: 3081
total_duration: 1015.5582886071129
[2022-12-21 15:48:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 726
train_sample_count: 726
avg_envstep_per_episode: 145.2
avg_sample_per_episode: 145.2
avg_envstep_per_sec: 510.2688262418651
avg_train_sample_per_sec: 510.2688262418651
avg_episode_per_sec: 3.514248114613396
collect_time: 1.4227794500929973
reward_mean: 729.4000244140625
reward_std: 307.25921630859375
reward_max: 1047.0
reward_min: 217.0
total_envstep_count: 511860
total_train_sample_count: 511820
total_episode_count: 3086
total_duration: 1016.9810680572059
[2022-12-21 15:48:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1356
train_sample_count: 1356
avg_envstep_per_episode: 226.0
avg_sample_per_episode: 226.0
avg_envstep_per_sec: 508.7494524222457
avg_train_sample_per_sec: 508.7494524222457
avg_episode_per_sec: 2.2511037717798486
collect_time: 2.665359134135369
reward_mean: 986.3333129882812
reward_std: 194.623291015625
reward_max: 1306.0
reward_min: 712.0
total_envstep_count: 512910
total_train_sample_count: 512864
total_episode_count: 3092
total_duration: 1019.6464271913412
[2022-12-21 15:48:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 148.33333333333334
avg_sample_per_episode: 148.33333333333334
avg_envstep_per_sec: 494.5721972004754
avg_train_sample_per_sec: 494.5721972004754
avg_episode_per_sec: 3.3341945878683736
collect_time: 1.7995350426850572
reward_mean: 857.1666870117188
reward_std: 397.6470031738281
reward_max: 1311.0
reward_min: 231.0
total_envstep_count: 513921
total_train_sample_count: 513886
total_episode_count: 3098
total_duration: 1021.4459622340263
[2022-12-21 15:48:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1048
train_sample_count: 1048
avg_envstep_per_episode: 149.71428571428572
avg_sample_per_episode: 149.71428571428572
avg_envstep_per_sec: 488.82261244979003
avg_train_sample_per_sec: 488.82261244979003
avg_episode_per_sec: 3.265036533538674
collect_time: 2.1439270060520093
reward_mean: 751.1428833007812
reward_std: 383.254638671875
reward_max: 1301.0
reward_min: 231.0
total_envstep_count: 514906
total_train_sample_count: 514862
total_episode_count: 3105
total_duration: 1023.5898892400783
[2022-12-21 15:48:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1389
train_sample_count: 1389
avg_envstep_per_episode: 173.625
avg_sample_per_episode: 173.625
avg_envstep_per_sec: 490.56689522780357
avg_train_sample_per_sec: 490.56689522780357
avg_episode_per_sec: 2.825439281369639
collect_time: 2.8314181277050765
reward_mean: 768.75
reward_std: 390.3251037597656
reward_max: 1368.0
reward_min: 231.0
total_envstep_count: 515915
total_train_sample_count: 515891
total_episode_count: 3113
total_duration: 1026.4213073677834
[2022-12-21 15:48:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 832
train_sample_count: 832
avg_envstep_per_episode: 118.85714285714286
avg_sample_per_episode: 118.85714285714286
avg_envstep_per_sec: 496.4087953892859
avg_train_sample_per_sec: 496.4087953892859
avg_episode_per_sec: 4.176516307361781
collect_time: 1.6760379907200114
reward_mean: 647.1428833007812
reward_std: 309.0018310546875
reward_max: 1045.0
reward_min: 231.0
total_envstep_count: 516917
total_train_sample_count: 516879
total_episode_count: 3120
total_duration: 1028.0973453585034
[2022-12-21 15:48:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1040
train_sample_count: 1040
avg_envstep_per_episode: 173.33333333333334
avg_sample_per_episode: 173.33333333333334
avg_envstep_per_sec: 490.4804695714355
avg_train_sample_per_sec: 490.4804695714355
avg_episode_per_sec: 2.829695016758282
collect_time: 2.120369850625684
reward_mean: 894.6666870117188
reward_std: 204.963134765625
reward_max: 1043.0
reward_min: 594.0
total_envstep_count: 517912
total_train_sample_count: 517883
total_episode_count: 3126
total_duration: 1030.217715209129
[2022-12-21 15:48:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1024
train_sample_count: 1024
avg_envstep_per_episode: 146.28571428571428
avg_sample_per_episode: 146.28571428571428
avg_envstep_per_sec: 489.20036638067535
avg_train_sample_per_sec: 489.20036638067535
avg_episode_per_sec: 3.344143129555398
collect_time: 2.093211841961635
reward_mean: 731.4285888671875
reward_std: 261.2059020996094
reward_max: 1045.0
reward_min: 231.0
total_envstep_count: 518938
total_train_sample_count: 518907
total_episode_count: 3133
total_duration: 1032.3109270510906
[2022-12-21 15:48:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 595
train_sample_count: 595
avg_envstep_per_episode: 198.33333333333334
avg_sample_per_episode: 198.33333333333334
avg_envstep_per_sec: 501.00464298312664
avg_train_sample_per_sec: 501.00464298312664
avg_episode_per_sec: 2.526073830167025
collect_time: 1.1876137443701076
reward_mean: 1016.0
reward_std: 246.68333435058594
reward_max: 1313.0
reward_min: 709.0
total_envstep_count: 519920
total_train_sample_count: 519886
total_episode_count: 3136
total_duration: 1033.4985407954607
[2022-12-21 15:48:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1162
train_sample_count: 1162
avg_envstep_per_episode: 193.66666666666666
avg_sample_per_episode: 193.66666666666666
avg_envstep_per_sec: 506.2128039890206
avg_train_sample_per_sec: 506.2128039890206
avg_episode_per_sec: 2.613835476707507
collect_time: 2.2954772989606225
reward_mean: 1026.0
reward_std: 206.97181701660156
reward_max: 1295.0
reward_min: 609.0
total_envstep_count: 520890
total_train_sample_count: 520856
total_episode_count: 3142
total_duration: 1035.7940180944213
[2022-12-21 15:48:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 837
train_sample_count: 837
avg_envstep_per_episode: 209.25
avg_sample_per_episode: 209.25
avg_envstep_per_sec: 502.6774762262868
avg_train_sample_per_sec: 502.6774762262868
avg_episode_per_sec: 2.4022818457648114
collect_time: 1.66508355672418
reward_mean: 1137.5
reward_std: 303.5205993652344
reward_max: 1326.0
reward_min: 612.0
total_envstep_count: 521879
total_train_sample_count: 521837
total_episode_count: 3146
total_duration: 1037.4591016511454
[2022-12-21 15:48:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1247
train_sample_count: 1247
avg_envstep_per_episode: 178.14285714285714
avg_sample_per_episode: 178.14285714285714
avg_envstep_per_sec: 503.63240807789634
avg_train_sample_per_sec: 503.63240807789634
avg_episode_per_sec: 2.8271265890499393
collect_time: 2.476012226375884
reward_mean: 939.7142944335938
reward_std: 362.0389404296875
reward_max: 1314.0
reward_min: 231.0
total_envstep_count: 522872
total_train_sample_count: 522832
total_episode_count: 3153
total_duration: 1039.9351138775212
[2022-12-21 15:48:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 956
train_sample_count: 956
avg_envstep_per_episode: 239.0
avg_sample_per_episode: 239.0
avg_envstep_per_sec: 513.1886115368827
avg_train_sample_per_sec: 513.1886115368827
avg_episode_per_sec: 2.14723268425474
collect_time: 1.8628628510227423
reward_mean: 949.5
reward_std: 138.63711547851562
reward_max: 1038.0
reward_min: 710.0
total_envstep_count: 523885
total_train_sample_count: 523848
total_episode_count: 3157
total_duration: 1041.797976728544
[2022-12-21 15:48:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 832
train_sample_count: 832
avg_envstep_per_episode: 166.4
avg_sample_per_episode: 166.4
avg_envstep_per_sec: 510.06263922338263
avg_train_sample_per_sec: 510.06263922338263
avg_episode_per_sec: 3.0652802837943667
collect_time: 1.6311722051762048
reward_mean: 872.0
reward_std: 324.5932922363281
reward_max: 1048.0
reward_min: 223.0
total_envstep_count: 524883
total_train_sample_count: 524836
total_episode_count: 3162
total_duration: 1043.4291489337202
[2022-12-21 15:48:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1157
train_sample_count: 1157
avg_envstep_per_episode: 165.28571428571428
avg_sample_per_episode: 165.28571428571428
avg_envstep_per_sec: 506.70621337538745
avg_train_sample_per_sec: 506.70621337538745
avg_episode_per_sec: 3.0656382831700193
collect_time: 2.2833744080079987
reward_mean: 928.1428833007812
reward_std: 284.6177673339844
reward_max: 1049.0
reward_min: 231.0
total_envstep_count: 525893
total_train_sample_count: 525861
total_episode_count: 3169
total_duration: 1045.7125233417282
[2022-12-21 15:48:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1161
train_sample_count: 1161
avg_envstep_per_episode: 145.125
avg_sample_per_episode: 145.125
avg_envstep_per_sec: 500.9881703205307
avg_train_sample_per_sec: 500.9881703205307
avg_episode_per_sec: 3.452114868703054
collect_time: 2.317419988693936
reward_mean: 768.125
reward_std: 399.88946533203125
reward_max: 1311.0
reward_min: 223.0
total_envstep_count: 526886
total_train_sample_count: 526842
total_episode_count: 3177
total_duration: 1048.0299433304222
[2022-12-21 15:49:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 552
train_sample_count: 552
avg_envstep_per_episode: 138.0
avg_sample_per_episode: 138.0
avg_envstep_per_sec: 503.0345682802816
avg_train_sample_per_sec: 503.0345682802816
avg_episode_per_sec: 3.6451780310165334
collect_time: 1.0973400931214647
reward_mean: 650.25
reward_std: 426.8866271972656
reward_max: 1120.0
reward_min: 223.0
total_envstep_count: 527874
total_train_sample_count: 527850
total_episode_count: 3181
total_duration: 1049.1272834235435
[2022-12-21 15:49:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1041
train_sample_count: 1041
avg_envstep_per_episode: 173.5
avg_sample_per_episode: 173.5
avg_envstep_per_sec: 495.9152635160656
avg_train_sample_per_sec: 495.9152635160656
avg_episode_per_sec: 2.8583012306401474
collect_time: 2.0991489405251507
reward_mean: 910.1666870117188
reward_std: 366.033447265625
reward_max: 1406.0
reward_min: 226.0
total_envstep_count: 528869
total_train_sample_count: 528831
total_episode_count: 3187
total_duration: 1051.2264323640686
[2022-12-21 15:49:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1116
train_sample_count: 1116
avg_envstep_per_episode: 223.2
avg_sample_per_episode: 223.2
avg_envstep_per_sec: 499.8007921382246
avg_train_sample_per_sec: 499.8007921382246
avg_episode_per_sec: 2.2392508608343396
collect_time: 2.232889618332897
reward_mean: 1097.800048828125
reward_std: 239.90614318847656
reward_max: 1401.0
reward_min: 712.0
total_envstep_count: 529858
total_train_sample_count: 529827
total_episode_count: 3192
total_duration: 1053.4593219824014
[2022-12-21 15:49:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1016
train_sample_count: 1016
avg_envstep_per_episode: 145.14285714285714
avg_sample_per_episode: 145.14285714285714
avg_envstep_per_sec: 513.1113158199068
avg_train_sample_per_sec: 513.1113158199068
avg_episode_per_sec: 3.5352157586017205
collect_time: 1.980077165861215
reward_mean: 859.1428833007812
reward_std: 443.934814453125
reward_max: 1411.0
reward_min: 231.0
total_envstep_count: 530876
total_train_sample_count: 530831
total_episode_count: 3199
total_duration: 1055.4393991482627
[2022-12-21 15:49:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1336
train_sample_count: 1336
avg_envstep_per_episode: 190.85714285714286
avg_sample_per_episode: 190.85714285714286
avg_envstep_per_sec: 502.7195191810221
avg_train_sample_per_sec: 502.7195191810221
avg_episode_per_sec: 2.634009456786792
collect_time: 2.6575455080329307
reward_mean: 976.7142944335938
reward_std: 378.797607421875
reward_max: 1648.0
reward_min: 582.0
total_envstep_count: 531888
total_train_sample_count: 531855
total_episode_count: 3206
total_duration: 1058.0969446562956
[2022-12-21 15:49:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 380
train_sample_count: 380
avg_envstep_per_episode: 190.0
avg_sample_per_episode: 190.0
avg_envstep_per_sec: 511.2483494551364
avg_train_sample_per_sec: 511.2483494551364
avg_episode_per_sec: 2.690780786605981
collect_time: 0.7432786832563577
reward_mean: 1033.0
reward_std: 1.0
reward_max: 1034.0
reward_min: 1032.0
total_envstep_count: 532863
total_train_sample_count: 532823
total_episode_count: 3208
total_duration: 1058.840223339552
[2022-12-21 15:49:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1501
train_sample_count: 1501
avg_envstep_per_episode: 187.625
avg_sample_per_episode: 187.625
avg_envstep_per_sec: 511.36633303215774
avg_train_sample_per_sec: 511.36633303215774
avg_episode_per_sec: 2.725470129418562
collect_time: 2.935273409768273
reward_mean: 1046.375
reward_std: 389.6164245605469
reward_max: 1553.0
reward_min: 231.0
total_envstep_count: 533873
total_train_sample_count: 533844
total_episode_count: 3216
total_duration: 1061.7754967493204
[2022-12-21 15:49:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 164
train_sample_count: 164
avg_envstep_per_episode: 82.0
avg_sample_per_episode: 82.0
avg_envstep_per_sec: 509.62215605424683
avg_train_sample_per_sec: 509.62215605424683
avg_episode_per_sec: 6.214904342124961
collect_time: 0.32180704479132377
reward_mean: 420.5
reward_std: 189.5
reward_max: 610.0
reward_min: 231.0
total_envstep_count: 534856
total_train_sample_count: 534812
total_episode_count: 3218
total_duration: 1062.0973037941117
[2022-12-21 15:49:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1806
train_sample_count: 1806
avg_envstep_per_episode: 258.0
avg_sample_per_episode: 258.0
avg_envstep_per_sec: 507.05232172564774
avg_train_sample_per_sec: 507.05232172564774
avg_episode_per_sec: 1.9653190764559991
collect_time: 3.561762608351052
reward_mean: 1426.0
reward_std: 443.0001525878906
reward_max: 2322.0
reward_min: 1041.0
total_envstep_count: 535851
total_train_sample_count: 535814
total_episode_count: 3225
total_duration: 1065.6590664024627
[2022-12-21 15:49:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1066
train_sample_count: 1066
avg_envstep_per_episode: 152.28571428571428
avg_sample_per_episode: 152.28571428571428
avg_envstep_per_sec: 506.83456606690703
avg_train_sample_per_sec: 506.83456606690703
avg_episode_per_sec: 3.328181953535037
collect_time: 2.103250392474766
reward_mean: 828.5714111328125
reward_std: 269.8528137207031
reward_max: 1300.0
reward_min: 584.0
total_envstep_count: 536837
total_train_sample_count: 536808
total_episode_count: 3232
total_duration: 1067.7623167949375
[2022-12-21 15:49:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1024
train_sample_count: 1024
avg_envstep_per_episode: 146.28571428571428
avg_sample_per_episode: 146.28571428571428
avg_envstep_per_sec: 525.3246066189973
avg_train_sample_per_sec: 525.3246066189973
avg_episode_per_sec: 3.591086178059552
collect_time: 1.9492709595129958
reward_mean: 793.7142944335938
reward_std: 368.52978515625
reward_max: 1315.0
reward_min: 215.0
total_envstep_count: 537854
total_train_sample_count: 537820
total_episode_count: 3239
total_duration: 1069.7115877544504
[2022-12-21 15:49:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1019
train_sample_count: 1019
avg_envstep_per_episode: 113.22222222222223
avg_sample_per_episode: 113.22222222222223
avg_envstep_per_sec: 514.5385755707658
avg_train_sample_per_sec: 514.5385755707658
avg_episode_per_sec: 4.544501648809512
collect_time: 1.98041516881343
reward_mean: 653.7777709960938
reward_std: 378.5257263183594
reward_max: 1308.0
reward_min: 218.0
total_envstep_count: 538861
total_train_sample_count: 538827
total_episode_count: 3248
total_duration: 1071.6920029232638
[2022-12-21 15:49:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 567
train_sample_count: 567
avg_envstep_per_episode: 189.0
avg_sample_per_episode: 189.0
avg_envstep_per_sec: 502.1427893590831
avg_train_sample_per_sec: 502.1427893590831
avg_episode_per_sec: 2.656840155339064
collect_time: 1.1291608921113818
reward_mean: 1021.0
reward_std: 244.0095672607422
reward_max: 1306.0
reward_min: 710.0
total_envstep_count: 539851
total_train_sample_count: 539814
total_episode_count: 3251
total_duration: 1072.8211638153753
[2022-12-21 15:49:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1092
train_sample_count: 1092
avg_envstep_per_episode: 218.4
avg_sample_per_episode: 218.4
avg_envstep_per_sec: 492.89302788968274
avg_train_sample_per_sec: 492.89302788968274
avg_episode_per_sec: 2.256836208286093
collect_time: 2.215490863555909
reward_mean: 1174.199951171875
reward_std: 219.24635314941406
reward_max: 1408.0
reward_min: 810.0
total_envstep_count: 540831
total_train_sample_count: 540786
total_episode_count: 3256
total_duration: 1075.0366546789312
[2022-12-21 15:49:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1237
train_sample_count: 1237
avg_envstep_per_episode: 137.44444444444446
avg_sample_per_episode: 137.44444444444446
avg_envstep_per_sec: 501.2556350894072
avg_train_sample_per_sec: 501.2556350894072
avg_episode_per_sec: 3.646969050771758
collect_time: 2.467802680720708
reward_mean: 725.111083984375
reward_std: 370.3375244140625
reward_max: 1044.0
reward_min: 231.0
total_envstep_count: 541825
total_train_sample_count: 541783
total_episode_count: 3265
total_duration: 1077.504457359652
[2022-12-21 15:49:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 757
train_sample_count: 757
avg_envstep_per_episode: 151.4
avg_sample_per_episode: 151.4
avg_envstep_per_sec: 497.38022618148267
avg_train_sample_per_sec: 497.38022618148267
avg_episode_per_sec: 3.285206249547442
collect_time: 1.5219744576733294
reward_mean: 902.4000244140625
reward_std: 418.489501953125
reward_max: 1310.0
reward_min: 231.0
total_envstep_count: 542812
total_train_sample_count: 542768
total_episode_count: 3270
total_duration: 1079.0264318173254
[2022-12-21 15:49:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1199
train_sample_count: 1199
avg_envstep_per_episode: 149.875
avg_sample_per_episode: 149.875
avg_envstep_per_sec: 422.0040179038925
avg_train_sample_per_sec: 422.0040179038925
avg_episode_per_sec: 2.815706541477181
collect_time: 2.84120517609162
reward_mean: 866.375
reward_std: 476.15777587890625
reward_max: 1550.0
reward_min: 231.0
total_envstep_count: 543822
total_train_sample_count: 543787
total_episode_count: 3278
total_duration: 1081.867636993417
[2022-12-21 15:49:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1010
train_sample_count: 1010
avg_envstep_per_episode: 168.33333333333334
avg_sample_per_episode: 168.33333333333334
avg_envstep_per_sec: 496.34794899998553
avg_train_sample_per_sec: 496.34794899998553
avg_episode_per_sec: 2.9486016772276367
collect_time: 2.0348628457816584
reward_mean: 893.3333129882812
reward_std: 376.0127258300781
reward_max: 1394.0
reward_min: 215.0
total_envstep_count: 544810
total_train_sample_count: 544785
total_episode_count: 3284
total_duration: 1083.9024998391985
[2022-12-21 15:49:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 614
train_sample_count: 614
avg_envstep_per_episode: 122.8
avg_sample_per_episode: 122.8
avg_envstep_per_sec: 498.78078298779434
avg_train_sample_per_sec: 498.78078298779434
avg_episode_per_sec: 4.061732760486924
collect_time: 1.2310017164695481
reward_mean: 687.7999877929688
reward_std: 431.98028564453125
reward_max: 1310.0
reward_min: 231.0
total_envstep_count: 545801
total_train_sample_count: 545759
total_episode_count: 3289
total_duration: 1085.133501555668
[2022-12-21 15:50:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1150
train_sample_count: 1150
avg_envstep_per_episode: 191.66666666666666
avg_sample_per_episode: 191.66666666666666
avg_envstep_per_sec: 508.33732149733646
avg_train_sample_per_sec: 508.33732149733646
avg_episode_per_sec: 2.652194720855668
collect_time: 2.2622773331153607
reward_mean: 1118.5
reward_std: 366.4654541015625
reward_max: 1548.0
reward_min: 602.0
total_envstep_count: 546788
total_train_sample_count: 546753
total_episode_count: 3295
total_duration: 1087.3957788887835
[2022-12-21 15:50:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1257
train_sample_count: 1257
avg_envstep_per_episode: 157.125
avg_sample_per_episode: 157.125
avg_envstep_per_sec: 509.0413680357537
avg_train_sample_per_sec: 509.0413680357537
avg_episode_per_sec: 3.2397223104900794
collect_time: 2.469347441938573
reward_mean: 875.625
reward_std: 393.31695556640625
reward_max: 1312.0
reward_min: 215.0
total_envstep_count: 547791
total_train_sample_count: 547758
total_episode_count: 3303
total_duration: 1089.8651263307222
[2022-12-21 15:50:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 736
train_sample_count: 736
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 501.212550728459
avg_train_sample_per_sec: 501.212550728459
avg_episode_per_sec: 2.7239812539590162
collect_time: 1.4684388867164289
reward_mean: 1149.0
reward_std: 300.2773742675781
reward_max: 1328.0
reward_min: 629.0
total_envstep_count: 548755
total_train_sample_count: 548734
total_episode_count: 3307
total_duration: 1091.3335652174387
[2022-12-21 15:50:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1229
train_sample_count: 1229
avg_envstep_per_episode: 175.57142857142858
avg_sample_per_episode: 175.57142857142858
avg_envstep_per_sec: 504.7074966321465
avg_train_sample_per_sec: 504.7074966321465
avg_episode_per_sec: 2.874656205390582
collect_time: 2.43507379660689
reward_mean: 1047.7142333984375
reward_std: 519.7880859375
reward_max: 1827.0
reward_min: 231.0
total_envstep_count: 549808
total_train_sample_count: 549771
total_episode_count: 3314
total_duration: 1093.7686390140457
[2022-12-21 15:50:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 936
train_sample_count: 936
avg_envstep_per_episode: 156.0
avg_sample_per_episode: 156.0
avg_envstep_per_sec: 516.425938737206
avg_train_sample_per_sec: 516.425938737206
avg_episode_per_sec: 3.3104226842128592
collect_time: 1.8124573724719564
reward_mean: 809.6666870117188
reward_std: 177.0665283203125
reward_max: 1043.0
reward_min: 601.0
total_envstep_count: 550834
total_train_sample_count: 550803
total_episode_count: 3320
total_duration: 1095.5810963865176
[2022-12-21 15:50:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1194
train_sample_count: 1194
avg_envstep_per_episode: 170.57142857142858
avg_sample_per_episode: 170.57142857142858
avg_envstep_per_sec: 508.4329789564732
avg_train_sample_per_sec: 508.4329789564732
avg_episode_per_sec: 2.9807628582037795
collect_time: 2.348392117385088
reward_mean: 1000.7142944335938
reward_std: 261.2167663574219
reward_max: 1317.0
reward_min: 626.0
total_envstep_count: 551853
total_train_sample_count: 551841
total_episode_count: 3327
total_duration: 1097.9294885039028
[2022-12-21 15:50:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 595
train_sample_count: 595
avg_envstep_per_episode: 148.75
avg_sample_per_episode: 148.75
avg_envstep_per_sec: 514.216992750018
avg_train_sample_per_sec: 514.216992750018
avg_episode_per_sec: 3.4569209596639863
collect_time: 1.1570990620476325
reward_mean: 830.5
reward_std: 215.0912628173828
reward_max: 1048.0
reward_min: 607.0
total_envstep_count: 552858
total_train_sample_count: 552820
total_episode_count: 3331
total_duration: 1099.0865875659504
[2022-12-21 15:50:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1169
train_sample_count: 1169
avg_envstep_per_episode: 194.83333333333334
avg_sample_per_episode: 194.83333333333334
avg_envstep_per_sec: 517.4547307372766
avg_train_sample_per_sec: 517.4547307372766
avg_episode_per_sec: 2.655883990097228
collect_time: 2.2591348200341947
reward_mean: 919.1666870117188
reward_std: 381.78985595703125
reward_max: 1302.0
reward_min: 231.0
total_envstep_count: 553830
total_train_sample_count: 553809
total_episode_count: 3337
total_duration: 1101.3457223859846
[2022-12-21 15:50:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 965
train_sample_count: 965
avg_envstep_per_episode: 160.83333333333334
avg_sample_per_episode: 160.83333333333334
avg_envstep_per_sec: 514.0976585389543
avg_train_sample_per_sec: 514.0976585389543
avg_episode_per_sec: 3.196462125630804
collect_time: 1.8770752676495215
reward_mean: 876.0
reward_std: 266.40069580078125
reward_max: 1310.0
reward_min: 626.0
total_envstep_count: 554841
total_train_sample_count: 554798
total_episode_count: 3343
total_duration: 1103.2227976536342
[2022-12-21 15:50:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 938
train_sample_count: 938
avg_envstep_per_episode: 156.33333333333334
avg_sample_per_episode: 156.33333333333334
avg_envstep_per_sec: 505.2363234992204
avg_train_sample_per_sec: 505.2363234992204
avg_episode_per_sec: 3.231788849675184
collect_time: 1.8565569345915156
reward_mean: 759.3333129882812
reward_std: 305.3127746582031
reward_max: 1049.0
reward_min: 226.0
total_envstep_count: 555820
total_train_sample_count: 555784
total_episode_count: 3349
total_duration: 1105.0793545882257
[2022-12-21 15:50:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1286
train_sample_count: 1286
avg_envstep_per_episode: 183.71428571428572
avg_sample_per_episode: 183.71428571428572
avg_envstep_per_sec: 499.52901436566304
avg_train_sample_per_sec: 499.52901436566304
avg_episode_per_sec: 2.719053732939068
collect_time: 2.5744250344157744
reward_mean: 982.0
reward_std: 366.3951721191406
reward_max: 1554.0
reward_min: 591.0
total_envstep_count: 556814
total_train_sample_count: 556782
total_episode_count: 3356
total_duration: 1107.6537796226414
[2022-12-21 15:51:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 995
train_sample_count: 995
avg_envstep_per_episode: 165.83333333333334
avg_sample_per_episode: 165.83333333333334
avg_envstep_per_sec: 497.73190925952053
avg_train_sample_per_sec: 497.73190925952053
avg_episode_per_sec: 3.0013984477961038
collect_time: 1.99906813585705
reward_mean: 921.5
reward_std: 313.95794677734375
reward_max: 1313.0
reward_min: 610.0
total_envstep_count: 557777
total_train_sample_count: 557753
total_episode_count: 3362
total_duration: 1109.6528477584984
[2022-12-21 15:51:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 829
train_sample_count: 829
avg_envstep_per_episode: 165.8
avg_sample_per_episode: 165.8
avg_envstep_per_sec: 493.4924313385445
avg_train_sample_per_sec: 493.4924313385445
avg_episode_per_sec: 2.9764320346112454
collect_time: 1.6798636561688043
reward_mean: 912.7999877929688
reward_std: 411.46539306640625
reward_max: 1668.0
reward_min: 601.0
total_envstep_count: 558798
total_train_sample_count: 558750
total_episode_count: 3367
total_duration: 1111.3327114146673
[2022-12-21 15:51:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 776
train_sample_count: 776
avg_envstep_per_episode: 155.2
avg_sample_per_episode: 155.2
avg_envstep_per_sec: 487.40845252182953
avg_train_sample_per_sec: 487.40845252182953
avg_episode_per_sec: 3.1405183796509637
collect_time: 1.5920938506195588
reward_mean: 866.2000122070312
reward_std: 267.35400390625
reward_max: 1305.0
reward_min: 616.0
total_envstep_count: 559764
total_train_sample_count: 559730
total_episode_count: 3372
total_duration: 1112.9248052652868
[2022-12-21 15:51:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1250
train_sample_count: 1250
avg_envstep_per_episode: 178.57142857142858
avg_sample_per_episode: 178.57142857142858
avg_envstep_per_sec: 496.9763228070764
avg_train_sample_per_sec: 496.9763228070764
avg_episode_per_sec: 2.783067407719628
collect_time: 2.5152103684529927
reward_mean: 948.0
reward_std: 297.8734130859375
reward_max: 1310.0
reward_min: 603.0
total_envstep_count: 560766
total_train_sample_count: 560728
total_episode_count: 3379
total_duration: 1115.4400156337397
[2022-12-21 15:51:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 892
train_sample_count: 892
avg_envstep_per_episode: 178.4
avg_sample_per_episode: 178.4
avg_envstep_per_sec: 505.2414000308734
avg_train_sample_per_sec: 505.2414000308734
avg_episode_per_sec: 2.8320706279757477
collect_time: 1.7654926930878847
reward_mean: 980.2000122070312
reward_std: 400.5363464355469
reward_max: 1304.0
reward_min: 215.0
total_envstep_count: 561763
total_train_sample_count: 561716
total_episode_count: 3384
total_duration: 1117.2055083268276
[2022-12-21 15:51:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 948
train_sample_count: 948
avg_envstep_per_episode: 158.0
avg_sample_per_episode: 158.0
avg_envstep_per_sec: 500.6790672101469
avg_train_sample_per_sec: 500.6790672101469
avg_episode_per_sec: 3.1688548557604235
collect_time: 1.8934284696230408
reward_mean: 755.3333129882812
reward_std: 398.5296630859375
reward_max: 1546.0
reward_min: 231.0
total_envstep_count: 562726
total_train_sample_count: 562700
total_episode_count: 3390
total_duration: 1119.0989367964507
[2022-12-21 15:51:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1124
train_sample_count: 1124
avg_envstep_per_episode: 187.33333333333334
avg_sample_per_episode: 187.33333333333334
avg_envstep_per_sec: 503.96932351751553
avg_train_sample_per_sec: 503.96932351751553
avg_episode_per_sec: 2.6902277056095136
collect_time: 2.230294479344307
reward_mean: 1000.0
reward_std: 345.6973571777344
reward_max: 1409.0
reward_min: 601.0
total_envstep_count: 563713
total_train_sample_count: 563692
total_episode_count: 3396
total_duration: 1121.329231275795
[2022-12-21 15:51:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 865
train_sample_count: 865
avg_envstep_per_episode: 144.16666666666666
avg_sample_per_episode: 144.16666666666666
avg_envstep_per_sec: 510.35401800641995
avg_train_sample_per_sec: 510.35401800641995
avg_episode_per_sec: 3.5400278705647628
collect_time: 1.6949019102052387
reward_mean: 827.6666870117188
reward_std: 258.64434814453125
reward_max: 1309.0
reward_min: 626.0
total_envstep_count: 564716
total_train_sample_count: 564677
total_episode_count: 3402
total_duration: 1123.0241331860004
[2022-12-21 15:51:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 949
train_sample_count: 949
avg_envstep_per_episode: 189.8
avg_sample_per_episode: 189.8
avg_envstep_per_sec: 507.10875150535765
avg_train_sample_per_sec: 507.10875150535765
avg_episode_per_sec: 2.6718058561926115
collect_time: 1.8713934578783813
reward_mean: 1027.199951171875
reward_std: 187.6671600341797
reward_max: 1302.0
reward_min: 711.0
total_envstep_count: 565697
total_train_sample_count: 565662
total_episode_count: 3407
total_duration: 1124.8955266438788
[2022-12-21 15:51:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1038
train_sample_count: 1038
avg_envstep_per_episode: 173.0
avg_sample_per_episode: 173.0
avg_envstep_per_sec: 492.5888481850755
avg_train_sample_per_sec: 492.5888481850755
avg_episode_per_sec: 2.847334382572691
collect_time: 2.107234063102465
reward_mean: 992.0
reward_std: 280.9549255371094
reward_max: 1314.0
reward_min: 625.0
total_envstep_count: 566669
total_train_sample_count: 566652
total_episode_count: 3413
total_duration: 1127.0027607069812
[2022-12-21 15:51:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1065
train_sample_count: 1065
avg_envstep_per_episode: 177.5
avg_sample_per_episode: 177.5
avg_envstep_per_sec: 499.32766838914534
avg_train_sample_per_sec: 499.32766838914534
avg_episode_per_sec: 2.8131136247275794
collect_time: 2.13286798914176
reward_mean: 1062.1666259765625
reward_std: 228.30126953125
reward_max: 1311.0
reward_min: 626.0
total_envstep_count: 567671
total_train_sample_count: 567633
total_episode_count: 3419
total_duration: 1129.135628696123
[2022-12-21 15:51:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 559
train_sample_count: 559
avg_envstep_per_episode: 139.75
avg_sample_per_episode: 139.75
avg_envstep_per_sec: 497.01326466073834
avg_train_sample_per_sec: 497.01326466073834
avg_episode_per_sec: 3.556445543189541
collect_time: 1.1247184728189776
reward_mean: 799.0
reward_std: 408.099853515625
reward_max: 1300.0
reward_min: 231.0
total_envstep_count: 568652
total_train_sample_count: 568612
total_episode_count: 3423
total_duration: 1130.260347168942
[2022-12-21 15:51:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1364
train_sample_count: 1364
avg_envstep_per_episode: 227.33333333333334
avg_sample_per_episode: 227.33333333333334
avg_envstep_per_sec: 496.86157758520346
avg_train_sample_per_sec: 496.86157758520346
avg_episode_per_sec: 2.1856081125448834
collect_time: 2.7452313914655573
reward_mean: 1214.5
reward_std: 377.7224426269531
reward_max: 1889.0
reward_min: 626.0
total_envstep_count: 569639
total_train_sample_count: 569604
total_episode_count: 3429
total_duration: 1133.0055785604075
[2022-12-21 15:51:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 994
train_sample_count: 994
avg_envstep_per_episode: 198.8
avg_sample_per_episode: 198.8
avg_envstep_per_sec: 478.96683590158534
avg_train_sample_per_sec: 478.96683590158534
avg_episode_per_sec: 2.409289919022059
collect_time: 2.0753002619251073
reward_mean: 1115.199951171875
reward_std: 393.758544921875
reward_max: 1835.0
reward_min: 626.0
total_envstep_count: 570642
total_train_sample_count: 570610
total_episode_count: 3434
total_duration: 1135.0808788223326
[2022-12-21 15:51:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 711
train_sample_count: 711
avg_envstep_per_episode: 177.75
avg_sample_per_episode: 177.75
avg_envstep_per_sec: 479.5318668335598
avg_train_sample_per_sec: 479.5318668335598
avg_episode_per_sec: 2.6977882803575794
collect_time: 1.4826960399834705
reward_mean: 1029.75
reward_std: 203.1284942626953
reward_max: 1308.0
reward_min: 734.0
total_envstep_count: 571630
total_train_sample_count: 571597
total_episode_count: 3438
total_duration: 1136.563574862316
[2022-12-21 15:51:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 924
train_sample_count: 924
avg_envstep_per_episode: 231.0
avg_sample_per_episode: 231.0
avg_envstep_per_sec: 505.4318586719146
avg_train_sample_per_sec: 505.4318586719146
avg_episode_per_sec: 2.1880167042074223
collect_time: 1.828139608033268
reward_mean: 1271.5
reward_std: 360.80499267578125
reward_max: 1893.0
reward_min: 1033.0
total_envstep_count: 572603
total_train_sample_count: 572569
total_episode_count: 3442
total_duration: 1138.3917144703494
[2022-12-21 15:51:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 749
train_sample_count: 749
avg_envstep_per_episode: 149.8
avg_sample_per_episode: 149.8
avg_envstep_per_sec: 495.530192484927
avg_train_sample_per_sec: 495.530192484927
avg_episode_per_sec: 3.307945210179753
collect_time: 1.5115123384187796
reward_mean: 804.2000122070312
reward_std: 341.42840576171875
reward_max: 1135.0
reward_min: 231.0
total_envstep_count: 573615
total_train_sample_count: 573594
total_episode_count: 3447
total_duration: 1139.903226808768
[2022-12-21 15:52:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 965
train_sample_count: 965
avg_envstep_per_episode: 160.83333333333334
avg_sample_per_episode: 160.83333333333334
avg_envstep_per_sec: 503.68532122330083
avg_train_sample_per_sec: 503.68532122330083
avg_episode_per_sec: 3.1317222044972075
collect_time: 1.915878742815661
reward_mean: 845.6666870117188
reward_std: 339.2986145019531
reward_max: 1302.0
reward_min: 231.0
total_envstep_count: 574610
total_train_sample_count: 574571
total_episode_count: 3453
total_duration: 1141.8191055515838
[2022-12-21 15:52:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1008
train_sample_count: 1008
avg_envstep_per_episode: 201.6
avg_sample_per_episode: 201.6
avg_envstep_per_sec: 515.7181992857535
avg_train_sample_per_sec: 515.7181992857535
avg_episode_per_sec: 2.5581259885206022
collect_time: 1.9545558046934057
reward_mean: 1101.0
reward_std: 450.9682922363281
reward_max: 1827.0
reward_min: 626.0
total_envstep_count: 575598
total_train_sample_count: 575555
total_episode_count: 3458
total_duration: 1143.7736613562772
[2022-12-21 15:52:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 633
train_sample_count: 633
avg_envstep_per_episode: 126.6
avg_sample_per_episode: 126.6
avg_envstep_per_sec: 513.1048015114162
avg_train_sample_per_sec: 513.1048015114162
avg_episode_per_sec: 4.052960517467743
collect_time: 1.2336661012241885
reward_mean: 742.7999877929688
reward_std: 343.31060791015625
reward_max: 1129.0
reward_min: 231.0
total_envstep_count: 576585
total_train_sample_count: 576536
total_episode_count: 3463
total_duration: 1145.0073274575013
[2022-12-21 15:52:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1767
train_sample_count: 1767
avg_envstep_per_episode: 252.42857142857142
avg_sample_per_episode: 252.42857142857142
avg_envstep_per_sec: 510.2582067846142
avg_train_sample_per_sec: 510.2582067846142
avg_episode_per_sec: 2.021396404919241
collect_time: 3.462952631638654
reward_mean: 969.1428833007812
reward_std: 951.0471801757812
reward_max: 2912.0
reward_min: 226.0
total_envstep_count: 577580
total_train_sample_count: 577547
total_episode_count: 3470
total_duration: 1148.47028008914
[2022-12-21 15:52:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1318
train_sample_count: 1318
avg_envstep_per_episode: 188.28571428571428
avg_sample_per_episode: 188.28571428571428
avg_envstep_per_sec: 510.45798509019096
avg_train_sample_per_sec: 510.45798509019096
avg_episode_per_sec: 2.711081863149724
collect_time: 2.5819950681487085
reward_mean: 977.0
reward_std: 508.93896484375
reward_max: 1833.0
reward_min: 231.0
total_envstep_count: 578574
total_train_sample_count: 578529
total_episode_count: 3477
total_duration: 1151.0522751572887
[2022-12-21 15:52:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 793
train_sample_count: 793
avg_envstep_per_episode: 99.125
avg_sample_per_episode: 99.125
avg_envstep_per_sec: 512.8767932535479
avg_train_sample_per_sec: 512.8767932535479
avg_episode_per_sec: 5.174040789443107
collect_time: 1.5461803115899009
reward_mean: 576.25
reward_std: 241.1331329345703
reward_max: 1034.0
reward_min: 223.0
total_envstep_count: 579592
total_train_sample_count: 579550
total_episode_count: 3485
total_duration: 1152.5984554688787
[2022-12-21 15:52:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1142
train_sample_count: 1142
avg_envstep_per_episode: 163.14285714285714
avg_sample_per_episode: 163.14285714285714
avg_envstep_per_sec: 489.44676212144145
avg_train_sample_per_sec: 489.44676212144145
avg_episode_per_sec: 3.0001115016200437
collect_time: 2.333246613074227
reward_mean: 922.4285888671875
reward_std: 433.7302551269531
reward_max: 1674.0
reward_min: 231.0
total_envstep_count: 580601
total_train_sample_count: 580560
total_episode_count: 3492
total_duration: 1154.9317020819528
[2022-12-21 15:52:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 831
train_sample_count: 831
avg_envstep_per_episode: 166.2
avg_sample_per_episode: 166.2
avg_envstep_per_sec: 487.05402320836833
avg_train_sample_per_sec: 487.05402320836833
avg_episode_per_sec: 2.9305296221923487
collect_time: 1.706176235904917
reward_mean: 942.0
reward_std: 279.5675354003906
reward_max: 1313.0
reward_min: 610.0
total_envstep_count: 581558
total_train_sample_count: 581535
total_episode_count: 3497
total_duration: 1156.6378783178577
[2022-12-21 15:52:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 966
train_sample_count: 966
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 514.816745798469
avg_train_sample_per_sec: 514.816745798469
avg_episode_per_sec: 3.1976195391209252
collect_time: 1.8763958396531102
reward_mean: 813.3333129882812
reward_std: 353.9527587890625
reward_max: 1306.0
reward_min: 231.0
total_envstep_count: 582577
total_train_sample_count: 582549
total_episode_count: 3503
total_duration: 1158.5142741575107
[2022-12-21 15:52:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 958
train_sample_count: 958
avg_envstep_per_episode: 239.5
avg_sample_per_episode: 239.5
avg_envstep_per_sec: 504.98133175365325
avg_train_sample_per_sec: 504.98133175365325
avg_episode_per_sec: 2.1084815522073206
collect_time: 1.8970998327267756
reward_mean: 1156.75
reward_std: 308.1195983886719
reward_max: 1394.0
reward_min: 627.0
total_envstep_count: 583565
total_train_sample_count: 583531
total_episode_count: 3507
total_duration: 1160.4113739902375
[2022-12-21 15:52:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1125
train_sample_count: 1125
avg_envstep_per_episode: 187.5
avg_sample_per_episode: 187.5
avg_envstep_per_sec: 491.08055963200826
avg_train_sample_per_sec: 491.08055963200826
avg_episode_per_sec: 2.6190963180373776
collect_time: 2.2908664941715875
reward_mean: 1002.5
reward_std: 134.79954528808594
reward_max: 1132.0
reward_min: 710.0
total_envstep_count: 584575
total_train_sample_count: 584524
total_episode_count: 3513
total_duration: 1162.702240484409
[2022-12-21 15:52:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1138
train_sample_count: 1138
avg_envstep_per_episode: 189.66666666666666
avg_sample_per_episode: 189.66666666666666
avg_envstep_per_sec: 505.50696771203667
avg_train_sample_per_sec: 505.50696771203667
avg_episode_per_sec: 2.6652388455819156
collect_time: 2.251205369434719
reward_mean: 1061.6666259765625
reward_std: 158.13250732421875
reward_max: 1320.0
reward_min: 782.0
total_envstep_count: 585555
total_train_sample_count: 585506
total_episode_count: 3519
total_duration: 1164.9534458538437
[2022-12-21 15:52:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 814
train_sample_count: 814
avg_envstep_per_episode: 203.5
avg_sample_per_episode: 203.5
avg_envstep_per_sec: 507.2430162946354
avg_train_sample_per_sec: 507.2430162946354
avg_episode_per_sec: 2.4925946746665133
collect_time: 1.6047534886654462
reward_mean: 1165.25
reward_std: 252.84518432617188
reward_max: 1410.0
reward_min: 806.0
total_envstep_count: 586503
total_train_sample_count: 586476
total_episode_count: 3523
total_duration: 1166.5581993425092
[2022-12-21 15:52:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 658
train_sample_count: 658
avg_envstep_per_episode: 219.33333333333334
avg_sample_per_episode: 219.33333333333334
avg_envstep_per_sec: 503.8182853971475
avg_train_sample_per_sec: 503.8182853971475
avg_episode_per_sec: 2.2970438543942895
collect_time: 1.306026436657246
reward_mean: 1118.6666259765625
reward_std: 264.2225341796875
reward_max: 1306.0
reward_min: 745.0
total_envstep_count: 587492
total_train_sample_count: 587446
total_episode_count: 3526
total_duration: 1167.8642257791664
[2022-12-21 15:52:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1260
train_sample_count: 1260
avg_envstep_per_episode: 252.0
avg_sample_per_episode: 252.0
avg_envstep_per_sec: 500.90867614161755
avg_train_sample_per_sec: 500.90867614161755
avg_episode_per_sec: 1.9877328418318156
collect_time: 2.515428580126592
reward_mean: 1386.199951171875
reward_std: 322.7311096191406
reward_max: 1892.0
reward_min: 1035.0
total_envstep_count: 588487
total_train_sample_count: 588442
total_episode_count: 3531
total_duration: 1170.379654359293
[2022-12-21 15:52:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1110
train_sample_count: 1110
avg_envstep_per_episode: 185.0
avg_sample_per_episode: 185.0
avg_envstep_per_sec: 503.36753834626296
avg_train_sample_per_sec: 503.36753834626296
avg_episode_per_sec: 2.7209056126825026
collect_time: 2.205148158037237
reward_mean: 1059.1666259765625
reward_std: 225.8498077392578
reward_max: 1308.0
reward_min: 628.0
total_envstep_count: 589481
total_train_sample_count: 589444
total_episode_count: 3537
total_duration: 1172.5848025173302
[2022-12-21 15:52:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 753
train_sample_count: 753
avg_envstep_per_episode: 188.25
avg_sample_per_episode: 188.25
avg_envstep_per_sec: 484.51577068689875
avg_train_sample_per_sec: 484.51577068689875
avg_episode_per_sec: 2.5737889545120782
collect_time: 1.5541289789854946
reward_mean: 1133.25
reward_std: 106.1752700805664
reward_max: 1308.0
reward_min: 1047.0
total_envstep_count: 590487
total_train_sample_count: 590437
total_episode_count: 3541
total_duration: 1174.1389314963158
[2022-12-21 15:52:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1305
train_sample_count: 1305
avg_envstep_per_episode: 217.5
avg_sample_per_episode: 217.5
avg_envstep_per_sec: 501.4351364675409
avg_train_sample_per_sec: 501.4351364675409
avg_episode_per_sec: 2.3054489032990384
collect_time: 2.602530028496469
reward_mean: 984.3333129882812
reward_std: 340.2267150878906
reward_max: 1527.0
reward_min: 614.0
total_envstep_count: 591490
total_train_sample_count: 591454
total_episode_count: 3547
total_duration: 1176.7414615248122
[2022-12-21 15:52:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 976
train_sample_count: 976
avg_envstep_per_episode: 162.66666666666666
avg_sample_per_episode: 162.66666666666666
avg_envstep_per_sec: 497.3306375391833
avg_train_sample_per_sec: 497.3306375391833
avg_episode_per_sec: 3.057360476675307
collect_time: 1.9624771255382467
reward_mean: 961.8333129882812
reward_std: 253.81320190429688
reward_max: 1312.0
reward_min: 626.0
total_envstep_count: 592486
total_train_sample_count: 592430
total_episode_count: 3553
total_duration: 1178.7039386503504
[2022-12-21 15:53:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 702
train_sample_count: 702
avg_envstep_per_episode: 175.5
avg_sample_per_episode: 175.5
avg_envstep_per_sec: 501.87968696345706
avg_train_sample_per_sec: 501.87968696345706
avg_episode_per_sec: 2.8597133160310944
collect_time: 1.398741607271135
reward_mean: 969.25
reward_std: 126.1276626586914
reward_max: 1047.0
reward_min: 751.0
total_envstep_count: 593474
total_train_sample_count: 593444
total_episode_count: 3557
total_duration: 1180.1026802576216
[2022-12-21 15:53:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 947
train_sample_count: 947
avg_envstep_per_episode: 135.28571428571428
avg_sample_per_episode: 135.28571428571428
avg_envstep_per_sec: 509.3876799324723
avg_train_sample_per_sec: 509.3876799324723
avg_episode_per_sec: 3.765273241317113
collect_time: 1.8590948256258188
reward_mean: 803.1428833007812
reward_std: 299.24114990234375
reward_max: 1049.0
reward_min: 231.0
total_envstep_count: 594436
total_train_sample_count: 594415
total_episode_count: 3564
total_duration: 1181.9617750832474
[2022-12-21 15:53:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1111
train_sample_count: 1111
avg_envstep_per_episode: 185.16666666666666
avg_sample_per_episode: 185.16666666666666
avg_envstep_per_sec: 513.0505666798634
avg_train_sample_per_sec: 513.0505666798634
avg_episode_per_sec: 2.7707501350847714
collect_time: 2.1654785554369123
reward_mean: 925.5
reward_std: 298.6205749511719
reward_max: 1301.0
reward_min: 601.0
total_envstep_count: 595423
total_train_sample_count: 595394
total_episode_count: 3570
total_duration: 1184.1272536386844
[2022-12-21 15:53:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 770
train_sample_count: 770
avg_envstep_per_episode: 385.0
avg_sample_per_episode: 385.0
avg_envstep_per_sec: 516.5450251336104
avg_train_sample_per_sec: 516.5450251336104
avg_episode_per_sec: 1.3416753899574294
collect_time: 1.4906735377053155
reward_mean: 1807.5
reward_std: 502.5
reward_max: 2310.0
reward_min: 1305.0
total_envstep_count: 596381
total_train_sample_count: 596368
total_episode_count: 3572
total_duration: 1185.6179271763897
[2022-12-21 15:53:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1529
train_sample_count: 1529
avg_envstep_per_episode: 191.125
avg_sample_per_episode: 191.125
avg_envstep_per_sec: 518.2359271427746
avg_train_sample_per_sec: 518.2359271427746
avg_episode_per_sec: 2.711502561898101
collect_time: 2.9503936719129835
reward_mean: 1030.125
reward_std: 416.678955078125
reward_max: 1676.0
reward_min: 223.0
total_envstep_count: 597406
total_train_sample_count: 597357
total_episode_count: 3580
total_duration: 1188.5683208483026
[2022-12-21 15:53:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 523
train_sample_count: 523
avg_envstep_per_episode: 174.33333333333334
avg_sample_per_episode: 174.33333333333334
avg_envstep_per_sec: 502.4323050975664
avg_train_sample_per_sec: 502.4323050975664
avg_episode_per_sec: 2.882020870540534
collect_time: 1.0409362509013818
reward_mean: 1039.3333740234375
reward_std: 7.7602972984313965
reward_max: 1049.0
reward_min: 1030.0
total_envstep_count: 598379
total_train_sample_count: 598336
total_episode_count: 3583
total_duration: 1189.6092570992041
[2022-12-21 15:53:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1444
train_sample_count: 1444
avg_envstep_per_episode: 180.5
avg_sample_per_episode: 180.5
avg_envstep_per_sec: 506.1512308303329
avg_train_sample_per_sec: 506.1512308303329
avg_episode_per_sec: 2.8041619436583543
collect_time: 2.8529022790898706
reward_mean: 1055.625
reward_std: 198.73471069335938
reward_max: 1315.0
reward_min: 626.0
total_envstep_count: 599404
total_train_sample_count: 599360
total_episode_count: 3591
total_duration: 1192.462159378294
[2022-12-21 15:53:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1083
train_sample_count: 1083
avg_envstep_per_episode: 180.5
avg_sample_per_episode: 180.5
avg_envstep_per_sec: 511.3418252877804
avg_train_sample_per_sec: 511.3418252877804
avg_episode_per_sec: 2.832918699655293
collect_time: 2.1179570034007944
reward_mean: 1059.6666259765625
reward_std: 228.50650024414062
reward_max: 1310.0
reward_min: 626.0
total_envstep_count: 600374
total_train_sample_count: 600335
total_episode_count: 3597
total_duration: 1194.5801163816948
[2022-12-21 15:53:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 216
train_sample_count: 216
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 492.49451363082875
avg_train_sample_per_sec: 492.49451363082875
avg_episode_per_sec: 2.280067192735318
collect_time: 0.4385835659519904
reward_mean: 1311.0
reward_std: 0.0
reward_max: 1311.0
reward_min: 1311.0
total_envstep_count: 601333
total_train_sample_count: 601295
total_episode_count: 3598
total_duration: 1195.0186999476468
[2022-12-21 15:53:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1213
train_sample_count: 1213
avg_envstep_per_episode: 173.28571428571428
avg_sample_per_episode: 173.28571428571428
avg_envstep_per_sec: 494.85378630983286
avg_train_sample_per_sec: 494.85378630983286
avg_episode_per_sec: 2.8557102260254164
collect_time: 2.4512290974783584
reward_mean: 961.8571166992188
reward_std: 471.3580322265625
reward_max: 1314.0
reward_min: 231.0
total_envstep_count: 602336
total_train_sample_count: 602304
total_episode_count: 3605
total_duration: 1197.4699290451251
[2022-12-21 15:53:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 954
train_sample_count: 954
avg_envstep_per_episode: 159.0
avg_sample_per_episode: 159.0
avg_envstep_per_sec: 482.6529413313239
avg_train_sample_per_sec: 482.6529413313239
avg_episode_per_sec: 3.0355530901341123
collect_time: 1.976575543844274
reward_mean: 816.5
reward_std: 405.0328063964844
reward_max: 1550.0
reward_min: 231.0
total_envstep_count: 603308
total_train_sample_count: 603282
total_episode_count: 3611
total_duration: 1199.4465045889694
[2022-12-21 15:53:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 724
train_sample_count: 724
avg_envstep_per_episode: 181.0
avg_sample_per_episode: 181.0
avg_envstep_per_sec: 482.0482529459154
avg_train_sample_per_sec: 482.0482529459154
avg_episode_per_sec: 2.6632500162757755
collect_time: 1.5019243313827153
reward_mean: 937.5
reward_std: 256.98297119140625
reward_max: 1305.0
reward_min: 626.0
total_envstep_count: 604328
total_train_sample_count: 604294
total_episode_count: 3615
total_duration: 1200.9484289203522
[2022-12-21 15:53:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 747
train_sample_count: 747
avg_envstep_per_episode: 249.0
avg_sample_per_episode: 249.0
avg_envstep_per_sec: 499.52142635453066
avg_train_sample_per_sec: 499.52142635453066
avg_episode_per_sec: 2.006110146002131
collect_time: 1.495431348063584
reward_mean: 1011.6666870117188
reward_std: 239.08900451660156
reward_max: 1291.0
reward_min: 707.0
total_envstep_count: 605302
total_train_sample_count: 605269
total_episode_count: 3618
total_duration: 1202.4438602684158
[2022-12-21 15:53:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 983
train_sample_count: 983
avg_envstep_per_episode: 196.6
avg_sample_per_episode: 196.6
avg_envstep_per_sec: 498.8458993928394
avg_train_sample_per_sec: 498.8458993928394
avg_episode_per_sec: 2.5373646968099663
collect_time: 1.970548422261142
reward_mean: 1133.4000244140625
reward_std: 494.12005615234375
reward_max: 1674.0
reward_min: 231.0
total_envstep_count: 606290
total_train_sample_count: 606240
total_episode_count: 3623
total_duration: 1204.414408690677
[2022-12-21 15:53:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 775
train_sample_count: 775
avg_envstep_per_episode: 155.0
avg_sample_per_episode: 155.0
avg_envstep_per_sec: 486.2915011388003
avg_train_sample_per_sec: 486.2915011388003
avg_episode_per_sec: 3.137364523476131
collect_time: 1.5936943133595805
reward_mean: 870.5999755859375
reward_std: 204.31993103027344
reward_max: 1048.0
reward_min: 615.0
total_envstep_count: 607246
total_train_sample_count: 607219
total_episode_count: 3628
total_duration: 1206.0081030040365
[2022-12-21 15:53:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1117
train_sample_count: 1117
avg_envstep_per_episode: 279.25
avg_sample_per_episode: 279.25
avg_envstep_per_sec: 501.44875238323505
avg_train_sample_per_sec: 501.44875238323505
avg_episode_per_sec: 1.795698307549633
collect_time: 2.2275456757868777
reward_mean: 1409.25
reward_std: 602.1815795898438
reward_max: 2322.0
reward_min: 733.0
total_envstep_count: 608243
total_train_sample_count: 608192
total_episode_count: 3632
total_duration: 1208.2356486798233
[2022-12-21 15:53:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 744
train_sample_count: 744
avg_envstep_per_episode: 148.8
avg_sample_per_episode: 148.8
avg_envstep_per_sec: 520.241491453499
avg_train_sample_per_sec: 520.241491453499
avg_episode_per_sec: 3.4962465823487836
collect_time: 1.4301050804720394
reward_mean: 802.7999877929688
reward_std: 366.2291259765625
reward_max: 1307.0
reward_min: 231.0
total_envstep_count: 609198
total_train_sample_count: 609164
total_episode_count: 3637
total_duration: 1209.6657537602953
[2022-12-21 15:53:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 969
train_sample_count: 969
avg_envstep_per_episode: 193.8
avg_sample_per_episode: 193.8
avg_envstep_per_sec: 505.07914155901386
avg_train_sample_per_sec: 505.07914155901386
avg_episode_per_sec: 2.606187520944344
collect_time: 1.9185112198635137
reward_mean: 1120.5999755859375
reward_std: 106.24989318847656
reward_max: 1311.0
reward_min: 1035.0
total_envstep_count: 610171
total_train_sample_count: 610133
total_episode_count: 3642
total_duration: 1211.5842649801589
[2022-12-21 15:53:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 492
train_sample_count: 492
avg_envstep_per_episode: 164.0
avg_sample_per_episode: 164.0
avg_envstep_per_sec: 491.2702747159845
avg_train_sample_per_sec: 491.2702747159845
avg_episode_per_sec: 2.9955504555852714
collect_time: 1.0014853845664433
reward_mean: 985.0
reward_std: 285.0298156738281
reward_max: 1307.0
reward_min: 614.0
total_envstep_count: 611144
total_train_sample_count: 611105
total_episode_count: 3645
total_duration: 1212.5857503647253
[2022-12-21 15:54:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1171
train_sample_count: 1171
avg_envstep_per_episode: 234.2
avg_sample_per_episode: 234.2
avg_envstep_per_sec: 501.2483629004893
avg_train_sample_per_sec: 501.2483629004893
avg_episode_per_sec: 2.1402577408219012
collect_time: 2.336167230998964
reward_mean: 1259.4000244140625
reward_std: 328.77020263671875
reward_max: 1885.0
reward_min: 1036.0
total_envstep_count: 612155
total_train_sample_count: 612120
total_episode_count: 3650
total_duration: 1214.9219175957242
[2022-12-21 15:54:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2521
train_sample_count: 2521
avg_envstep_per_episode: 360.14285714285717
avg_sample_per_episode: 360.14285714285717
avg_envstep_per_sec: 496.16658292924717
avg_train_sample_per_sec: 496.16658292924717
avg_episode_per_sec: 1.3776938042462237
collect_time: 5.080954838023608
reward_mean: 1159.5714111328125
reward_std: 769.6438598632812
reward_max: 2804.0
reward_min: 231.0
total_envstep_count: 613181
total_train_sample_count: 613129
total_episode_count: 3657
total_duration: 1220.0028724337478
[2022-12-21 15:54:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 206.66666666666666
avg_sample_per_episode: 206.66666666666666
avg_envstep_per_sec: 502.5901689952543
avg_train_sample_per_sec: 502.5901689952543
avg_episode_per_sec: 2.431887914493166
collect_time: 1.2336094859146645
reward_mean: 1037.3333740234375
reward_std: 4.71404504776001
reward_max: 1044.0
reward_min: 1034.0
total_envstep_count: 614138
total_train_sample_count: 614097
total_episode_count: 3660
total_duration: 1221.2364819196625
[2022-12-21 15:54:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1328
train_sample_count: 1328
avg_envstep_per_episode: 189.71428571428572
avg_sample_per_episode: 189.71428571428572
avg_envstep_per_sec: 504.7721855593611
avg_train_sample_per_sec: 504.7721855593611
avg_episode_per_sec: 2.660696761231572
collect_time: 2.6308898112687857
reward_mean: 1113.2857666015625
reward_std: 397.3863525390625
reward_max: 1554.0
reward_min: 231.0
total_envstep_count: 615116
total_train_sample_count: 615077
total_episode_count: 3667
total_duration: 1223.8673717309314
[2022-12-21 15:54:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 755
train_sample_count: 755
avg_envstep_per_episode: 188.75
avg_sample_per_episode: 188.75
avg_envstep_per_sec: 509.53862945419314
avg_train_sample_per_sec: 509.53862945419314
avg_episode_per_sec: 2.6995424077043344
collect_time: 1.4817326034902198
reward_mean: 1067.25
reward_std: 298.2879333496094
reward_max: 1409.0
reward_min: 734.0
total_envstep_count: 616096
total_train_sample_count: 616048
total_episode_count: 3671
total_duration: 1225.3491043344216
[2022-12-21 15:54:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1260
train_sample_count: 1260
avg_envstep_per_episode: 180.0
avg_sample_per_episode: 180.0
avg_envstep_per_sec: 501.90806012237476
avg_train_sample_per_sec: 501.90806012237476
avg_episode_per_sec: 2.788378111790971
collect_time: 2.5104199356607024
reward_mean: 998.7142944335938
reward_std: 296.0263977050781
reward_max: 1306.0
reward_min: 604.0
total_envstep_count: 617075
total_train_sample_count: 617044
total_episode_count: 3678
total_duration: 1227.8595242700821
[2022-12-21 15:54:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 847
train_sample_count: 847
avg_envstep_per_episode: 169.4
avg_sample_per_episode: 169.4
avg_envstep_per_sec: 501.732797343514
avg_train_sample_per_sec: 501.732797343514
avg_episode_per_sec: 2.961822888686623
collect_time: 1.688149557861367
reward_mean: 954.0
reward_std: 327.2509765625
reward_max: 1551.0
reward_min: 626.0
total_envstep_count: 618071
total_train_sample_count: 618035
total_episode_count: 3683
total_duration: 1229.5476738279435
[2022-12-21 15:54:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 870
train_sample_count: 870
avg_envstep_per_episode: 217.5
avg_sample_per_episode: 217.5
avg_envstep_per_sec: 504.7363814683736
avg_train_sample_per_sec: 504.7363814683736
avg_episode_per_sec: 2.3206270412339016
collect_time: 1.7236720631649445
reward_mean: 1137.75
reward_std: 294.5796813964844
reward_max: 1326.0
reward_min: 628.0
total_envstep_count: 619051
total_train_sample_count: 619013
total_episode_count: 3687
total_duration: 1231.2713458911085
[2022-12-21 15:54:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1381
train_sample_count: 1381
avg_envstep_per_episode: 197.28571428571428
avg_sample_per_episode: 197.28571428571428
avg_envstep_per_sec: 444.084096391273
avg_train_sample_per_sec: 444.084096391273
avg_episode_per_sec: 2.2509693517298417
collect_time: 3.1097713501166013
reward_mean: 1048.142822265625
reward_std: 281.8831481933594
reward_max: 1426.0
reward_min: 585.0
total_envstep_count: 620054
total_train_sample_count: 620010
total_episode_count: 3694
total_duration: 1234.381117241225
[2022-12-21 15:55:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 733
train_sample_count: 733
avg_envstep_per_episode: 146.6
avg_sample_per_episode: 146.6
avg_envstep_per_sec: 470.22928753420024
avg_train_sample_per_sec: 470.22928753420024
avg_episode_per_sec: 3.20756676353479
collect_time: 1.5588140071915197
reward_mean: 762.4000244140625
reward_std: 273.60235595703125
reward_max: 1302.0
reward_min: 581.0
total_envstep_count: 621057
total_train_sample_count: 621019
total_episode_count: 3699
total_duration: 1235.9399312484165
[2022-12-21 15:55:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1273
train_sample_count: 1273
avg_envstep_per_episode: 212.16666666666666
avg_sample_per_episode: 212.16666666666666
avg_envstep_per_sec: 507.7764249293095
avg_train_sample_per_sec: 507.7764249293095
avg_episode_per_sec: 2.393290298174279
collect_time: 2.507008867489706
reward_mean: 1177.0
reward_std: 133.69493103027344
reward_max: 1315.0
reward_min: 1041.0
total_envstep_count: 622046
total_train_sample_count: 622016
total_episode_count: 3705
total_duration: 1238.4469401159063
[2022-12-21 15:55:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 329
train_sample_count: 329
avg_envstep_per_episode: 164.5
avg_sample_per_episode: 164.5
avg_envstep_per_sec: 509.22128498382364
avg_train_sample_per_sec: 509.22128498382364
avg_episode_per_sec: 3.095570121482211
collect_time: 0.6460845406539738
reward_mean: 962.0
reward_std: 336.0
reward_max: 1298.0
reward_min: 626.0
total_envstep_count: 623029
total_train_sample_count: 623017
total_episode_count: 3707
total_duration: 1239.0930246565601
[2022-12-21 15:55:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1446
train_sample_count: 1446
avg_envstep_per_episode: 206.57142857142858
avg_sample_per_episode: 206.57142857142858
avg_envstep_per_sec: 509.3141986417886
avg_train_sample_per_sec: 509.3141986417886
avg_episode_per_sec: 2.4655597444623236
collect_time: 2.839111895674839
reward_mean: 1253.7142333984375
reward_std: 486.8381042480469
reward_max: 1674.0
reward_min: 231.0
total_envstep_count: 624032
total_train_sample_count: 624007
total_episode_count: 3714
total_duration: 1241.932136552235
[2022-12-21 15:55:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 669
train_sample_count: 669
avg_envstep_per_episode: 133.8
avg_sample_per_episode: 133.8
avg_envstep_per_sec: 509.7172106350567
avg_train_sample_per_sec: 509.7172106350567
avg_episode_per_sec: 3.8095456699182115
collect_time: 1.3124924684542099
reward_mean: 715.5999755859375
reward_std: 398.95843505859375
reward_max: 1046.0
reward_min: 223.0
total_envstep_count: 625035
total_train_sample_count: 624988
total_episode_count: 3719
total_duration: 1243.2446290206892
[2022-12-21 15:55:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1434
train_sample_count: 1434
avg_envstep_per_episode: 204.85714285714286
avg_sample_per_episode: 204.85714285714286
avg_envstep_per_sec: 501.25314731584274
avg_train_sample_per_sec: 501.25314731584274
avg_episode_per_sec: 2.446842420649163
collect_time: 2.8608299173360154
reward_mean: 1257.857177734375
reward_std: 255.5662841796875
reward_max: 1674.0
reward_min: 1038.0
total_envstep_count: 626014
total_train_sample_count: 625978
total_episode_count: 3726
total_duration: 1246.1054589380253
[2022-12-21 15:55:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 899
train_sample_count: 899
avg_envstep_per_episode: 149.83333333333334
avg_sample_per_episode: 149.83333333333334
avg_envstep_per_sec: 499.81751838157084
avg_train_sample_per_sec: 499.81751838157084
avg_episode_per_sec: 3.335823259498804
collect_time: 1.7986564434776078
reward_mean: 880.8333129882812
reward_std: 354.57318115234375
reward_max: 1311.0
reward_min: 231.0
total_envstep_count: 627024
total_train_sample_count: 626985
total_episode_count: 3732
total_duration: 1247.9041153815028
[2022-12-21 15:55:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1032
train_sample_count: 1032
avg_envstep_per_episode: 206.4
avg_sample_per_episode: 206.4
avg_envstep_per_sec: 495.37160658002085
avg_train_sample_per_sec: 495.37160658002085
avg_episode_per_sec: 2.400056233430334
collect_time: 2.0832845207354325
reward_mean: 1091.4000244140625
reward_std: 203.0926971435547
reward_max: 1308.0
reward_min: 760.0
total_envstep_count: 627995
total_train_sample_count: 627957
total_episode_count: 3737
total_duration: 1249.9873999022382
[2022-12-21 15:55:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 179.25
avg_sample_per_episode: 179.25
avg_envstep_per_sec: 501.58029419858855
avg_train_sample_per_sec: 501.58029419858855
avg_episode_per_sec: 2.7982164250967285
collect_time: 1.4294819957901321
reward_mean: 998.75
reward_std: 318.04510498046875
reward_max: 1314.0
reward_min: 624.0
total_envstep_count: 628961
total_train_sample_count: 628926
total_episode_count: 3741
total_duration: 1251.4168818980284
[2022-12-21 15:55:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1245
train_sample_count: 1245
avg_envstep_per_episode: 177.85714285714286
avg_sample_per_episode: 177.85714285714286
avg_envstep_per_sec: 504.39002921365335
avg_train_sample_per_sec: 504.39002921365335
avg_episode_per_sec: 2.835927875096846
collect_time: 2.4683279364997786
reward_mean: 954.1428833007812
reward_std: 377.2393798828125
reward_max: 1407.0
reward_min: 223.0
total_envstep_count: 629964
total_train_sample_count: 629919
total_episode_count: 3748
total_duration: 1253.885209834528
[2022-12-21 15:55:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 429
train_sample_count: 429
avg_envstep_per_episode: 214.5
avg_sample_per_episode: 214.5
avg_envstep_per_sec: 500.1718383306947
avg_train_sample_per_sec: 500.1718383306947
avg_episode_per_sec: 2.331803442101141
collect_time: 0.8577052267312207
reward_mean: 1039.5
reward_std: 1.5
reward_max: 1041.0
reward_min: 1038.0
total_envstep_count: 630922
total_train_sample_count: 630888
total_episode_count: 3750
total_duration: 1254.7429150612593
[2022-12-21 15:55:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1066
train_sample_count: 1066
avg_envstep_per_episode: 213.2
avg_sample_per_episode: 213.2
avg_envstep_per_sec: 507.1262222211926
avg_train_sample_per_sec: 507.1262222211926
avg_episode_per_sec: 2.3786408171725735
collect_time: 2.1020407805594483
reward_mean: 1250.800048828125
reward_std: 190.44412231445312
reward_max: 1542.0
reward_min: 1035.0
total_envstep_count: 631902
total_train_sample_count: 631858
total_episode_count: 3755
total_duration: 1256.8449558418188
[2022-12-21 15:55:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 993
train_sample_count: 993
avg_envstep_per_episode: 198.6
avg_sample_per_episode: 198.6
avg_envstep_per_sec: 501.98115556317117
avg_train_sample_per_sec: 501.98115556317117
avg_episode_per_sec: 2.5275989706101267
collect_time: 1.9781619070659262
reward_mean: 1042.5999755859375
reward_std: 491.85919189453125
reward_max: 1546.0
reward_min: 231.0
total_envstep_count: 632898
total_train_sample_count: 632863
total_episode_count: 3760
total_duration: 1258.8231177488847
[2022-12-21 15:55:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1338
train_sample_count: 1338
avg_envstep_per_episode: 223.0
avg_sample_per_episode: 223.0
avg_envstep_per_sec: 500.50442934099306
avg_train_sample_per_sec: 500.50442934099306
avg_episode_per_sec: 2.2444144813497444
collect_time: 2.6733030150436936
reward_mean: 1209.8333740234375
reward_std: 321.1896667480469
reward_max: 1676.0
reward_min: 626.0
total_envstep_count: 633918
total_train_sample_count: 633865
total_episode_count: 3766
total_duration: 1261.4964207639284
[2022-12-21 15:55:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 648
train_sample_count: 648
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 507.35488159115965
avg_train_sample_per_sec: 507.35488159115965
avg_episode_per_sec: 2.3488651925516653
collect_time: 1.277212506495948
reward_mean: 1217.0
reward_std: 126.6043701171875
reward_max: 1310.0
reward_min: 1038.0
total_envstep_count: 634884
total_train_sample_count: 634861
total_episode_count: 3769
total_duration: 1262.7736332704244
[2022-12-21 15:55:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 929
train_sample_count: 929
avg_envstep_per_episode: 232.25
avg_sample_per_episode: 232.25
avg_envstep_per_sec: 495.01156617726355
avg_train_sample_per_sec: 495.01156617726355
avg_episode_per_sec: 2.1313738048536646
collect_time: 1.8767238252112382
reward_mean: 1305.75
reward_std: 3.699662208557129
reward_max: 1309.0
reward_min: 1300.0
total_envstep_count: 635889
total_train_sample_count: 635850
total_episode_count: 3773
total_duration: 1264.6503570956356
[2022-12-21 15:55:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1173
train_sample_count: 1173
avg_envstep_per_episode: 234.6
avg_sample_per_episode: 234.6
avg_envstep_per_sec: 496.7543421243865
avg_train_sample_per_sec: 496.7543421243865
avg_episode_per_sec: 2.117452438722875
collect_time: 2.3613281264611126
reward_mean: 1306.0
reward_std: 613.8836669921875
reward_max: 1888.0
reward_min: 231.0
total_envstep_count: 636877
total_train_sample_count: 636843
total_episode_count: 3778
total_duration: 1267.0116852220967
[2022-12-21 15:55:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 895
train_sample_count: 895
avg_envstep_per_episode: 179.0
avg_sample_per_episode: 179.0
avg_envstep_per_sec: 504.13946014859516
avg_train_sample_per_sec: 504.13946014859516
avg_episode_per_sec: 2.8164215650759505
collect_time: 1.7753024128208466
reward_mean: 871.4000244140625
reward_std: 261.3599853515625
reward_max: 1305.0
reward_min: 626.0
total_envstep_count: 637867
total_train_sample_count: 637822
total_episode_count: 3783
total_duration: 1268.7869876349175
[2022-12-21 15:56:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1541
train_sample_count: 1541
avg_envstep_per_episode: 192.625
avg_sample_per_episode: 192.625
avg_envstep_per_sec: 492.33510963761233
avg_train_sample_per_sec: 492.33510963761233
avg_episode_per_sec: 2.5559252933815046
collect_time: 3.1299819367630857
reward_mean: 1096.25
reward_std: 393.4316101074219
reward_max: 1673.0
reward_min: 231.0
total_envstep_count: 638876
total_train_sample_count: 638823
total_episode_count: 3791
total_duration: 1271.9169695716805
[2022-12-21 15:56:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 434
train_sample_count: 434
avg_envstep_per_episode: 144.66666666666666
avg_sample_per_episode: 144.66666666666666
avg_envstep_per_sec: 496.92927950123993
avg_train_sample_per_sec: 496.92927950123993
avg_episode_per_sec: 3.434995019593824
collect_time: 0.8733637117048103
reward_mean: 766.0
reward_std: 441.73370361328125
reward_max: 1305.0
reward_min: 223.0
total_envstep_count: 639833
total_train_sample_count: 639797
total_episode_count: 3794
total_duration: 1272.7903332833853
[2022-12-21 15:56:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1243
train_sample_count: 1243
avg_envstep_per_episode: 207.16666666666666
avg_sample_per_episode: 207.16666666666666
avg_envstep_per_sec: 502.83837369220345
avg_train_sample_per_sec: 502.83837369220345
avg_episode_per_sec: 2.4272166067202097
collect_time: 2.471967266286767
reward_mean: 1119.1666259765625
reward_std: 300.4759521484375
reward_max: 1405.0
reward_min: 626.0
total_envstep_count: 640811
total_train_sample_count: 640776
total_episode_count: 3800
total_duration: 1275.262300549672
[2022-12-21 15:56:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 983
train_sample_count: 983
avg_envstep_per_episode: 196.6
avg_sample_per_episode: 196.6
avg_envstep_per_sec: 501.28556204405317
avg_train_sample_per_sec: 501.28556204405317
avg_episode_per_sec: 2.549773967670667
collect_time: 1.9609581333076846
reward_mean: 1155.5999755859375
reward_std: 509.7029113769531
reward_max: 1832.0
reward_min: 614.0
total_envstep_count: 641816
total_train_sample_count: 641771
total_episode_count: 3805
total_duration: 1277.2232586829798
[2022-12-21 15:56:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1041
train_sample_count: 1041
avg_envstep_per_episode: 173.5
avg_sample_per_episode: 173.5
avg_envstep_per_sec: 497.5358885486886
avg_train_sample_per_sec: 497.5358885486886
avg_episode_per_sec: 2.867642008926159
collect_time: 2.0923113768467947
reward_mean: 906.0
reward_std: 190.98953247070312
reward_max: 1047.0
reward_min: 636.0
total_envstep_count: 642771
total_train_sample_count: 642740
total_episode_count: 3811
total_duration: 1279.3155700598265
[2022-12-21 15:56:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 767
train_sample_count: 767
avg_envstep_per_episode: 153.4
avg_sample_per_episode: 153.4
avg_envstep_per_sec: 494.7499454041075
avg_train_sample_per_sec: 494.7499454041075
avg_episode_per_sec: 3.2252278057634127
collect_time: 1.5502780892143828
reward_mean: 800.2000122070312
reward_std: 362.705078125
reward_max: 1316.0
reward_min: 231.0
total_envstep_count: 643776
total_train_sample_count: 643735
total_episode_count: 3816
total_duration: 1280.8658481490409
[2022-12-21 15:56:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 770
train_sample_count: 770
avg_envstep_per_episode: 192.5
avg_sample_per_episode: 192.5
avg_envstep_per_sec: 504.23302665320216
avg_train_sample_per_sec: 504.23302665320216
avg_episode_per_sec: 2.6193923462504007
collect_time: 1.5270717293367322
reward_mean: 1096.25
reward_std: 384.9346618652344
reward_max: 1693.0
reward_min: 617.0
total_envstep_count: 644757
total_train_sample_count: 644709
total_episode_count: 3820
total_duration: 1282.3929198783776
[2022-12-21 15:56:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 475
train_sample_count: 475
avg_envstep_per_episode: 237.5
avg_sample_per_episode: 237.5
avg_envstep_per_sec: 506.8941443556571
avg_train_sample_per_sec: 506.8941443556571
avg_episode_per_sec: 2.1342911341290822
collect_time: 0.9370792803373186
reward_mean: 1238.0
reward_std: 431.0
reward_max: 1669.0
reward_min: 807.0
total_envstep_count: 645716
total_train_sample_count: 645676
total_episode_count: 3822
total_duration: 1283.3299991587148
[2022-12-21 15:56:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1707
train_sample_count: 1707
avg_envstep_per_episode: 243.85714285714286
avg_sample_per_episode: 243.85714285714286
avg_envstep_per_sec: 503.9751902988304
avg_train_sample_per_sec: 503.9751902988304
avg_episode_per_sec: 2.0666820926138327
collect_time: 3.3870714925229555
reward_mean: 1315.5714111328125
reward_std: 603.5103759765625
reward_max: 2600.0
reward_min: 595.0
total_envstep_count: 646735
total_train_sample_count: 646699
total_episode_count: 3829
total_duration: 1286.7170706512377
[2022-12-21 15:56:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 194
train_sample_count: 194
avg_envstep_per_episode: 194.0
avg_sample_per_episode: 194.0
avg_envstep_per_sec: 488.08240321018394
avg_train_sample_per_sec: 488.08240321018394
avg_episode_per_sec: 2.515888676341154
collect_time: 0.39747386655211453
reward_mean: 1033.0
reward_std: 0.0
reward_max: 1033.0
reward_min: 1033.0
total_envstep_count: 647694
total_train_sample_count: 647661
total_episode_count: 3830
total_duration: 1287.11454451779
[2022-12-21 15:56:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1966
train_sample_count: 1966
avg_envstep_per_episode: 280.85714285714283
avg_sample_per_episode: 280.85714285714283
avg_envstep_per_sec: 497.1991619058619
avg_train_sample_per_sec: 497.1991619058619
avg_episode_per_sec: 1.7702920312009325
collect_time: 3.9541498671557216
reward_mean: 1499.2857666015625
reward_std: 421.9927673339844
reward_max: 2307.0
reward_min: 1031.0
total_envstep_count: 648697
total_train_sample_count: 648667
total_episode_count: 3837
total_duration: 1291.0686943849457
[2022-12-21 15:56:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 692
train_sample_count: 692
avg_envstep_per_episode: 173.0
avg_sample_per_episode: 173.0
avg_envstep_per_sec: 517.0984518691754
avg_train_sample_per_sec: 517.0984518691754
avg_episode_per_sec: 2.9890083923073725
collect_time: 1.3382364567107121
reward_mean: 1065.75
reward_std: 531.16162109375
reward_max: 1675.0
reward_min: 231.0
total_envstep_count: 649694
total_train_sample_count: 649647
total_episode_count: 3841
total_duration: 1292.4069308416565
[2022-12-21 15:56:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1244
train_sample_count: 1244
avg_envstep_per_episode: 207.33333333333334
avg_sample_per_episode: 207.33333333333334
avg_envstep_per_sec: 518.6557934504071
avg_train_sample_per_sec: 518.6557934504071
avg_episode_per_sec: 2.5015552738765616
collect_time: 2.3985078653497176
reward_mean: 1236.1666259765625
reward_std: 285.9588623046875
reward_max: 1551.0
reward_min: 628.0
total_envstep_count: 650704
total_train_sample_count: 650663
total_episode_count: 3847
total_duration: 1294.8054387070063
[2022-12-21 15:56:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1341
train_sample_count: 1341
avg_envstep_per_episode: 191.57142857142858
avg_sample_per_episode: 191.57142857142858
avg_envstep_per_sec: 499.5494513552237
avg_train_sample_per_sec: 499.5494513552237
avg_episode_per_sec: 2.6076406856723087
collect_time: 2.684418922615192
reward_mean: 1137.0
reward_std: 445.2126159667969
reward_max: 1549.0
reward_min: 231.0
total_envstep_count: 651698
total_train_sample_count: 651656
total_episode_count: 3854
total_duration: 1297.4898576296214
[2022-12-21 15:56:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 711
train_sample_count: 711
avg_envstep_per_episode: 177.75
avg_sample_per_episode: 177.75
avg_envstep_per_sec: 498.802733575994
avg_train_sample_per_sec: 498.802733575994
avg_episode_per_sec: 2.806203845715859
collect_time: 1.42541319872634
reward_mean: 899.5
reward_std: 283.0569763183594
reward_max: 1293.0
reward_min: 626.0
total_envstep_count: 652670
total_train_sample_count: 652631
total_episode_count: 3858
total_duration: 1298.9152708283477
[2022-12-21 15:56:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1296
train_sample_count: 1296
avg_envstep_per_episode: 185.14285714285714
avg_sample_per_episode: 185.14285714285714
avg_envstep_per_sec: 504.4780939239126
avg_train_sample_per_sec: 504.4780939239126
avg_episode_per_sec: 2.724804519650762
collect_time: 2.56899162839659
reward_mean: 966.1428833007812
reward_std: 365.4458923339844
reward_max: 1407.0
reward_min: 231.0
total_envstep_count: 653663
total_train_sample_count: 653639
total_episode_count: 3865
total_duration: 1301.4842624567443
[2022-12-21 15:56:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 552
train_sample_count: 552
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 497.28190288046983
avg_train_sample_per_sec: 497.28190288046983
avg_episode_per_sec: 2.7026190373938577
collect_time: 1.110034362406071
reward_mean: 1037.0
reward_std: 222.903564453125
reward_max: 1310.0
reward_min: 764.0
total_envstep_count: 654669
total_train_sample_count: 654611
total_episode_count: 3868
total_duration: 1302.5942968191505
[2022-12-21 15:56:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1129
train_sample_count: 1129
avg_envstep_per_episode: 225.8
avg_sample_per_episode: 225.8
avg_envstep_per_sec: 493.17374707035873
avg_train_sample_per_sec: 493.17374707035873
avg_episode_per_sec: 2.184117568956416
collect_time: 2.289254054390959
reward_mean: 1112.5999755859375
reward_std: 304.0977478027344
reward_max: 1549.0
reward_min: 635.0
total_envstep_count: 655628
total_train_sample_count: 655596
total_episode_count: 3873
total_duration: 1304.8835508735415
[2022-12-21 15:57:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 854
train_sample_count: 854
avg_envstep_per_episode: 213.5
avg_sample_per_episode: 213.5
avg_envstep_per_sec: 479.36631633447837
avg_train_sample_per_sec: 479.36631633447837
avg_episode_per_sec: 2.245275486344161
collect_time: 1.781518581718872
reward_mean: 1178.5
reward_std: 136.63546752929688
reward_max: 1322.0
reward_min: 1037.0
total_envstep_count: 656617
total_train_sample_count: 656582
total_episode_count: 3877
total_duration: 1306.6650694552604
[2022-12-21 15:57:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 887
train_sample_count: 887
avg_envstep_per_episode: 221.75
avg_sample_per_episode: 221.75
avg_envstep_per_sec: 481.65376972346644
avg_train_sample_per_sec: 481.65376972346644
avg_episode_per_sec: 2.172057586126117
collect_time: 1.8415718006510287
reward_mean: 1336.5
reward_std: 223.7884063720703
reward_max: 1676.0
reward_min: 1047.0
total_envstep_count: 657589
total_train_sample_count: 657553
total_episode_count: 3881
total_duration: 1308.5066412559115
[2022-12-21 15:57:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1136
train_sample_count: 1136
avg_envstep_per_episode: 189.33333333333334
avg_sample_per_episode: 189.33333333333334
avg_envstep_per_sec: 499.72247214853394
avg_train_sample_per_sec: 499.72247214853394
avg_episode_per_sec: 2.6393792543056374
collect_time: 2.273261786919087
reward_mean: 1075.1666259765625
reward_std: 248.3716278076172
reward_max: 1404.0
reward_min: 626.0
total_envstep_count: 658591
total_train_sample_count: 658557
total_episode_count: 3887
total_duration: 1310.7799030428307
[2022-12-21 15:57:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 430
train_sample_count: 430
avg_envstep_per_episode: 107.5
avg_sample_per_episode: 107.5
avg_envstep_per_sec: 497.13558805961503
avg_train_sample_per_sec: 497.13558805961503
avg_episode_per_sec: 4.624517098228977
collect_time: 0.8649551758673042
reward_mean: 561.75
reward_std: 198.58421325683594
reward_max: 761.0
reward_min: 231.0
total_envstep_count: 659571
total_train_sample_count: 659539
total_episode_count: 3891
total_duration: 1311.6448582186981
[2022-12-21 15:57:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1157
train_sample_count: 1157
avg_envstep_per_episode: 289.25
avg_sample_per_episode: 289.25
avg_envstep_per_sec: 499.2376814997703
avg_train_sample_per_sec: 499.2376814997703
avg_episode_per_sec: 1.7259729697485575
collect_time: 2.3175333971671215
reward_mean: 1545.0
reward_std: 554.4312133789062
reward_max: 2321.0
reward_min: 753.0
total_envstep_count: 660561
total_train_sample_count: 660516
total_episode_count: 3895
total_duration: 1313.9623916158653
[2022-12-21 15:57:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1094
train_sample_count: 1094
avg_envstep_per_episode: 218.8
avg_sample_per_episode: 218.8
avg_envstep_per_sec: 500.28376716640105
avg_train_sample_per_sec: 500.28376716640105
avg_episode_per_sec: 2.2864888810164583
collect_time: 2.186758939224428
reward_mean: 1278.5999755859375
reward_std: 249.830810546875
reward_max: 1550.0
reward_min: 811.0
total_envstep_count: 661540
total_train_sample_count: 661490
total_episode_count: 3900
total_duration: 1316.1491505550896
[2022-12-21 15:57:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 882
train_sample_count: 882
avg_envstep_per_episode: 294.0
avg_sample_per_episode: 294.0
avg_envstep_per_sec: 493.00818379791156
avg_train_sample_per_sec: 493.00818379791156
avg_episode_per_sec: 1.676898584346638
collect_time: 1.789016955470134
reward_mean: 1557.6666259765625
reward_std: 551.9603271484375
reward_max: 2323.0
reward_min: 1042.0
total_envstep_count: 662506
total_train_sample_count: 662468
total_episode_count: 3903
total_duration: 1317.9381675105597
[2022-12-21 15:57:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1266
train_sample_count: 1266
avg_envstep_per_episode: 180.85714285714286
avg_sample_per_episode: 180.85714285714286
avg_envstep_per_sec: 498.8643328338596
avg_train_sample_per_sec: 498.8643328338596
avg_episode_per_sec: 2.758333593868102
collect_time: 2.537764110751981
reward_mean: 937.5714111328125
reward_std: 500.4075012207031
reward_max: 1893.0
reward_min: 231.0
total_envstep_count: 663523
total_train_sample_count: 663470
total_episode_count: 3910
total_duration: 1320.4759316213117
[2022-12-21 15:57:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 727
train_sample_count: 727
avg_envstep_per_episode: 181.75
avg_sample_per_episode: 181.75
avg_envstep_per_sec: 493.85599918921895
avg_train_sample_per_sec: 493.85599918921895
avg_episode_per_sec: 2.7172269556490725
collect_time: 1.4720890324174292
reward_mean: 991.75
reward_std: 355.2332763671875
reward_max: 1551.0
reward_min: 627.0
total_envstep_count: 664504
total_train_sample_count: 664461
total_episode_count: 3914
total_duration: 1321.9480206537291
[2022-12-21 15:57:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1170
train_sample_count: 1170
avg_envstep_per_episode: 234.0
avg_sample_per_episode: 234.0
avg_envstep_per_sec: 503.7149895120756
avg_train_sample_per_sec: 503.7149895120756
avg_episode_per_sec: 2.1526281603080153
collect_time: 2.3227420751034678
reward_mean: 1311.4000244140625
reward_std: 369.9376220703125
reward_max: 1896.0
reward_min: 809.0
total_envstep_count: 665483
total_train_sample_count: 665451
total_episode_count: 3919
total_duration: 1324.2707627288326
[2022-12-21 15:57:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1124
train_sample_count: 1124
avg_envstep_per_episode: 187.33333333333334
avg_sample_per_episode: 187.33333333333334
avg_envstep_per_sec: 500.58909494889207
avg_train_sample_per_sec: 500.58909494889207
avg_episode_per_sec: 2.672183780865972
collect_time: 2.2453545459570097
reward_mean: 1024.0
reward_std: 403.7218322753906
reward_max: 1547.0
reward_min: 618.0
total_envstep_count: 666485
total_train_sample_count: 666431
total_episode_count: 3925
total_duration: 1326.5161172747896
[2022-12-21 15:57:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 828
train_sample_count: 828
avg_envstep_per_episode: 276.0
avg_sample_per_episode: 276.0
avg_envstep_per_sec: 496.67270438303143
avg_train_sample_per_sec: 496.67270438303143
avg_episode_per_sec: 1.7995387839964907
collect_time: 1.667093827973785
reward_mean: 1557.6666259765625
reward_std: 206.66452026367188
reward_max: 1815.0
reward_min: 1309.0
total_envstep_count: 667458
total_train_sample_count: 667427
total_episode_count: 3928
total_duration: 1328.1832111027634
[2022-12-21 15:57:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1067
train_sample_count: 1067
avg_envstep_per_episode: 213.4
avg_sample_per_episode: 213.4
avg_envstep_per_sec: 497.8595604053195
avg_train_sample_per_sec: 497.8595604053195
avg_episode_per_sec: 2.332987630765321
collect_time: 2.1431746718518965
reward_mean: 1242.199951171875
reward_std: 376.3521728515625
reward_max: 1673.0
reward_min: 626.0
total_envstep_count: 668439
total_train_sample_count: 668398
total_episode_count: 3933
total_duration: 1330.3263857746153
[2022-12-21 15:57:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 920
train_sample_count: 920
avg_envstep_per_episode: 230.0
avg_sample_per_episode: 230.0
avg_envstep_per_sec: 493.3525638019834
avg_train_sample_per_sec: 493.3525638019834
avg_episode_per_sec: 2.145011146965145
collect_time: 1.8647921739984303
reward_mean: 1330.75
reward_std: 184.86532592773438
reward_max: 1547.0
reward_min: 1041.0
total_envstep_count: 669419
total_train_sample_count: 669378
total_episode_count: 3937
total_duration: 1332.1911779486138
[2022-12-21 15:57:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1437
train_sample_count: 1437
avg_envstep_per_episode: 159.66666666666666
avg_sample_per_episode: 159.66666666666666
avg_envstep_per_sec: 497.57909179143724
avg_train_sample_per_sec: 497.57909179143724
avg_episode_per_sec: 3.116361743996475
collect_time: 2.887983083908047
reward_mean: 949.7777709960938
reward_std: 497.7124938964844
reward_max: 1677.0
reward_min: 223.0
total_envstep_count: 670423
total_train_sample_count: 670395
total_episode_count: 3946
total_duration: 1335.0791610325218
[2022-12-21 15:57:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 324
train_sample_count: 324
avg_envstep_per_episode: 162.0
avg_sample_per_episode: 162.0
avg_envstep_per_sec: 499.051137585287
avg_train_sample_per_sec: 499.051137585287
avg_episode_per_sec: 3.080562577686957
collect_time: 0.649232063807547
reward_mean: 842.0
reward_std: 207.0
reward_max: 1049.0
reward_min: 635.0
total_envstep_count: 671446
total_train_sample_count: 671427
total_episode_count: 3948
total_duration: 1335.7283930963295
[2022-12-21 15:57:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1403
train_sample_count: 1403
avg_envstep_per_episode: 200.42857142857142
avg_sample_per_episode: 200.42857142857142
avg_envstep_per_sec: 496.63334395414665
avg_train_sample_per_sec: 496.63334395414665
avg_episode_per_sec: 2.4778570261432833
collect_time: 2.8250217531296826
reward_mean: 1190.142822265625
reward_std: 252.3758087158203
reward_max: 1404.0
reward_min: 627.0
total_envstep_count: 672441
total_train_sample_count: 672398
total_episode_count: 3955
total_duration: 1338.5534148494592
[2022-12-21 15:57:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1027
train_sample_count: 1027
avg_envstep_per_episode: 205.4
avg_sample_per_episode: 205.4
avg_envstep_per_sec: 495.8711431869177
avg_train_sample_per_sec: 495.8711431869177
avg_episode_per_sec: 2.414173043753251
collect_time: 2.071102571929406
reward_mean: 1099.5999755859375
reward_std: 535.4028930664062
reward_max: 1883.0
reward_min: 223.0
total_envstep_count: 673429
total_train_sample_count: 673401
total_episode_count: 3960
total_duration: 1340.6245174213886
[2022-12-21 15:57:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 920
train_sample_count: 920
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 485.244798164858
avg_train_sample_per_sec: 485.244798164858
avg_episode_per_sec: 2.637199990026402
collect_time: 1.8959502574357066
reward_mean: 1016.7999877929688
reward_std: 349.6829528808594
reward_max: 1407.0
reward_min: 614.0
total_envstep_count: 674424
total_train_sample_count: 674381
total_episode_count: 3965
total_duration: 1342.5204676788244
[2022-12-21 15:58:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1119
train_sample_count: 1119
avg_envstep_per_episode: 186.5
avg_sample_per_episode: 186.5
avg_envstep_per_sec: 493.12976253140613
avg_train_sample_per_sec: 493.12976253140613
avg_episode_per_sec: 2.64412741303703
collect_time: 2.2691796054973135
reward_mean: 1012.5
reward_std: 261.6541748046875
reward_max: 1323.0
reward_min: 626.0
total_envstep_count: 675410
total_train_sample_count: 675368
total_episode_count: 3971
total_duration: 1344.7896472843217
[2022-12-21 15:58:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 478
train_sample_count: 478
avg_envstep_per_episode: 239.0
avg_sample_per_episode: 239.0
avg_envstep_per_sec: 512.3981132993754
avg_train_sample_per_sec: 512.3981132993754
avg_episode_per_sec: 2.1439251602484326
collect_time: 0.9328683841595689
reward_mean: 1220.0
reward_std: 179.0
reward_max: 1399.0
reward_min: 1041.0
total_envstep_count: 676369
total_train_sample_count: 676338
total_episode_count: 3973
total_duration: 1345.7225156684813
[2022-12-21 15:58:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1188
train_sample_count: 1188
avg_envstep_per_episode: 237.6
avg_sample_per_episode: 237.6
avg_envstep_per_sec: 507.16831311479046
avg_train_sample_per_sec: 507.16831311479046
avg_episode_per_sec: 2.1345467723686466
collect_time: 2.3424176339090663
reward_mean: 1227.0
reward_std: 361.855224609375
reward_max: 1664.0
reward_min: 626.0
total_envstep_count: 677365
total_train_sample_count: 677322
total_episode_count: 3978
total_duration: 1348.0649333023903
[2022-12-21 15:58:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 335
train_sample_count: 335
avg_envstep_per_episode: 335.0
avg_sample_per_episode: 335.0
avg_envstep_per_sec: 506.6975726772358
avg_train_sample_per_sec: 506.6975726772358
avg_episode_per_sec: 1.5125300676932414
collect_time: 0.6611438816056724
reward_mean: 1887.0
reward_std: 0.0
reward_max: 1887.0
reward_min: 1887.0
total_envstep_count: 678348
total_train_sample_count: 678293
total_episode_count: 3979
total_duration: 1348.726077183996
[2022-12-21 15:58:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1337
train_sample_count: 1337
avg_envstep_per_episode: 222.83333333333334
avg_sample_per_episode: 222.83333333333334
avg_envstep_per_sec: 503.4182431967949
avg_train_sample_per_sec: 503.4182431967949
avg_episode_per_sec: 2.2591693785944424
collect_time: 2.6558433629854443
reward_mean: 1343.3333740234375
reward_std: 449.552978515625
reward_max: 1892.0
reward_min: 626.0
total_envstep_count: 679319
total_train_sample_count: 679294
total_episode_count: 3985
total_duration: 1351.3819205469815
[2022-12-21 15:58:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 833
train_sample_count: 833
avg_envstep_per_episode: 208.25
avg_sample_per_episode: 208.25
avg_envstep_per_sec: 507.3431628565821
avg_train_sample_per_sec: 507.3431628565821
avg_episode_per_sec: 2.436221670379746
collect_time: 1.6418867168916118
reward_mean: 1309.5
reward_std: 452.79437255859375
reward_max: 1896.0
reward_min: 626.0
total_envstep_count: 680302
total_train_sample_count: 680259
total_episode_count: 3989
total_duration: 1353.023807263873
[2022-12-21 15:58:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2038
train_sample_count: 2038
avg_envstep_per_episode: 254.75
avg_sample_per_episode: 254.75
avg_envstep_per_sec: 506.14105937742727
avg_train_sample_per_sec: 506.14105937742727
avg_episode_per_sec: 1.9868147571243466
collect_time: 4.02654549011854
reward_mean: 1260.125
reward_std: 729.3741455078125
reward_max: 2979.0
reward_min: 626.0
total_envstep_count: 681328
total_train_sample_count: 681277
total_episode_count: 3997
total_duration: 1357.0503527539915
[2022-12-21 15:58:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 321
train_sample_count: 321
avg_envstep_per_episode: 107.0
avg_sample_per_episode: 107.0
avg_envstep_per_sec: 499.3882823336666
avg_train_sample_per_sec: 499.3882823336666
avg_episode_per_sec: 4.667180208725856
collect_time: 0.6427864076024188
reward_mean: 626.6666870117188
reward_std: 0.471404492855072
reward_max: 627.0
reward_min: 626.0
total_envstep_count: 682333
total_train_sample_count: 682306
total_episode_count: 4000
total_duration: 1357.693139161594
[2022-12-21 15:58:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1406
train_sample_count: 1406
avg_envstep_per_episode: 200.85714285714286
avg_sample_per_episode: 200.85714285714286
avg_envstep_per_sec: 496.7650385765131
avg_train_sample_per_sec: 496.7650385765131
avg_episode_per_sec: 2.4732256543638633
collect_time: 2.8303118996234353
reward_mean: 1096.857177734375
reward_std: 352.3262939453125
reward_max: 1553.0
reward_min: 614.0
total_envstep_count: 683328
total_train_sample_count: 683304
total_episode_count: 4007
total_duration: 1360.5234510612174
[2022-12-21 15:58:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 747
train_sample_count: 747
avg_envstep_per_episode: 149.4
avg_sample_per_episode: 149.4
avg_envstep_per_sec: 496.09407629118834
avg_train_sample_per_sec: 496.09407629118834
avg_episode_per_sec: 3.3205761465273653
collect_time: 1.5057627891560217
reward_mean: 951.7999877929688
reward_std: 469.08990478515625
reward_max: 1831.0
reward_min: 626.0
total_envstep_count: 684307
total_train_sample_count: 684279
total_episode_count: 4012
total_duration: 1362.0292138503735
[2022-12-21 15:58:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1090
train_sample_count: 1090
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 492.49192185517717
avg_train_sample_per_sec: 492.49192185517717
avg_episode_per_sec: 2.259137256216409
collect_time: 2.2132342717298963
reward_mean: 1315.199951171875
reward_std: 366.02862548828125
reward_max: 1673.0
reward_min: 626.0
total_envstep_count: 685295
total_train_sample_count: 685249
total_episode_count: 4017
total_duration: 1364.2424481221033
[2022-12-21 15:58:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1317
train_sample_count: 1317
avg_envstep_per_episode: 188.14285714285714
avg_sample_per_episode: 188.14285714285714
avg_envstep_per_sec: 495.76175972323534
avg_train_sample_per_sec: 495.76175972323534
avg_episode_per_sec: 2.6350283356588062
collect_time: 2.65651792251026
reward_mean: 1117.4285888671875
reward_std: 472.4301452636719
reward_max: 1834.0
reward_min: 626.0
total_envstep_count: 686273
total_train_sample_count: 686230
total_episode_count: 4024
total_duration: 1366.8989660446134
[2022-12-21 15:58:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 411
train_sample_count: 411
avg_envstep_per_episode: 205.5
avg_sample_per_episode: 205.5
avg_envstep_per_sec: 499.46857410226806
avg_train_sample_per_sec: 499.46857410226806
avg_episode_per_sec: 2.430504010230015
collect_time: 0.8228745937393975
reward_mean: 1257.0
reward_std: 631.0
reward_max: 1888.0
reward_min: 626.0
total_envstep_count: 687248
total_train_sample_count: 687217
total_episode_count: 4026
total_duration: 1367.721840638353
[2022-12-21 15:58:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1554
train_sample_count: 1554
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 499.20495799282264
avg_train_sample_per_sec: 499.20495799282264
avg_episode_per_sec: 2.2486709819496515
collect_time: 3.11294985179683
reward_mean: 1234.2857666015625
reward_std: 327.8591613769531
reward_max: 1891.0
reward_min: 747.0
total_envstep_count: 688249
total_train_sample_count: 688207
total_episode_count: 4033
total_duration: 1370.8347904901498
[2022-12-21 15:58:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 883
train_sample_count: 883
avg_envstep_per_episode: 176.6
avg_sample_per_episode: 176.6
avg_envstep_per_sec: 495.1571583670412
avg_train_sample_per_sec: 495.1571583670412
avg_episode_per_sec: 2.8038344188394175
collect_time: 1.783272209801046
reward_mean: 896.2000122070312
reward_std: 245.12640380859375
reward_max: 1299.0
reward_min: 620.0
total_envstep_count: 689244
total_train_sample_count: 689198
total_episode_count: 4038
total_duration: 1372.6180626999508
[2022-12-21 15:58:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 749
train_sample_count: 749
avg_envstep_per_episode: 187.25
avg_sample_per_episode: 187.25
avg_envstep_per_sec: 500.159514770667
avg_train_sample_per_sec: 500.159514770667
avg_episode_per_sec: 2.671078850577661
collect_time: 1.4975222461646687
reward_mean: 1064.5
reward_std: 36.342124938964844
reward_max: 1127.0
reward_min: 1037.0
total_envstep_count: 690240
total_train_sample_count: 690211
total_episode_count: 4042
total_duration: 1374.1155849461154
[2022-12-21 15:58:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 805
train_sample_count: 805
avg_envstep_per_episode: 201.25
avg_sample_per_episode: 201.25
avg_envstep_per_sec: 508.94504477089663
avg_train_sample_per_sec: 508.94504477089663
avg_episode_per_sec: 2.528919477122468
collect_time: 1.581703188332197
reward_mean: 992.0
reward_std: 263.92327880859375
reward_max: 1412.0
reward_min: 761.0
total_envstep_count: 691220
total_train_sample_count: 691184
total_episode_count: 4046
total_duration: 1375.6972881344475
[2022-12-21 15:58:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1120
train_sample_count: 1120
avg_envstep_per_episode: 224.0
avg_sample_per_episode: 224.0
avg_envstep_per_sec: 496.16493559714934
avg_train_sample_per_sec: 496.16493559714934
avg_episode_per_sec: 2.2150220339158455
collect_time: 2.2573138882779906
reward_mean: 1313.199951171875
reward_std: 356.8133239746094
reward_max: 1830.0
reward_min: 713.0
total_envstep_count: 692215
total_train_sample_count: 692172
total_episode_count: 4051
total_duration: 1377.9546020227256
[2022-12-21 15:58:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1190
train_sample_count: 1190
avg_envstep_per_episode: 198.33333333333334
avg_sample_per_episode: 198.33333333333334
avg_envstep_per_sec: 501.58444680128423
avg_train_sample_per_sec: 501.58444680128423
avg_episode_per_sec: 2.528997210762778
collect_time: 2.3724818574198125
reward_mean: 1192.5
reward_std: 397.14300537109375
reward_max: 1847.0
reward_min: 626.0
total_envstep_count: 693185
total_train_sample_count: 693146
total_episode_count: 4057
total_duration: 1380.3270838801454
[2022-12-21 15:59:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 913
train_sample_count: 913
avg_envstep_per_episode: 182.6
avg_sample_per_episode: 182.6
avg_envstep_per_sec: 513.2652119643196
avg_train_sample_per_sec: 513.2652119643196
avg_episode_per_sec: 2.8108719165625393
collect_time: 1.7788074833785315
reward_mean: 995.4000244140625
reward_std: 336.3983459472656
reward_max: 1407.0
reward_min: 606.0
total_envstep_count: 694165
total_train_sample_count: 694131
total_episode_count: 4062
total_duration: 1382.105891363524
[2022-12-21 15:59:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 829
train_sample_count: 829
avg_envstep_per_episode: 207.25
avg_sample_per_episode: 207.25
avg_envstep_per_sec: 506.0261764447419
avg_train_sample_per_sec: 506.0261764447419
avg_episode_per_sec: 2.441622081759913
collect_time: 1.6382551705613728
reward_mean: 1114.75
reward_std: 208.816162109375
reward_max: 1314.0
reward_min: 811.0
total_envstep_count: 695147
total_train_sample_count: 695116
total_episode_count: 4066
total_duration: 1383.7441465340855
[2022-12-21 15:59:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1008
train_sample_count: 1008
avg_envstep_per_episode: 201.6
avg_sample_per_episode: 201.6
avg_envstep_per_sec: 495.63504864281214
avg_train_sample_per_sec: 495.63504864281214
avg_episode_per_sec: 2.458507185728235
collect_time: 2.033754478744364
reward_mean: 1158.4000244140625
reward_std: 250.773681640625
reward_max: 1402.0
reward_min: 717.0
total_envstep_count: 696152
total_train_sample_count: 696112
total_episode_count: 4071
total_duration: 1385.77790101283
[2022-12-21 15:59:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 860
train_sample_count: 860
avg_envstep_per_episode: 215.0
avg_sample_per_episode: 215.0
avg_envstep_per_sec: 505.3436397898889
avg_train_sample_per_sec: 505.3436397898889
avg_episode_per_sec: 2.35043553390646
collect_time: 1.7018122566211966
reward_mean: 1196.0
reward_std: 157.8892059326172
reward_max: 1399.0
reward_min: 1037.0
total_envstep_count: 697149
total_train_sample_count: 697128
total_episode_count: 4075
total_duration: 1387.4797132694512
[2022-12-21 15:59:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 815
train_sample_count: 815
avg_envstep_per_episode: 271.6666666666667
avg_sample_per_episode: 271.6666666666667
avg_envstep_per_sec: 498.8618477955475
avg_train_sample_per_sec: 498.8618477955475
avg_episode_per_sec: 1.836301280229009
collect_time: 1.6337188414015937
reward_mean: 1605.3333740234375
reward_std: 213.719970703125
reward_max: 1828.0
reward_min: 1317.0
total_envstep_count: 698146
total_train_sample_count: 698099
total_episode_count: 4078
total_duration: 1389.1134321108527
[2022-12-21 15:59:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 474
train_sample_count: 474
avg_envstep_per_episode: 237.0
avg_sample_per_episode: 237.0
avg_envstep_per_sec: 500.86843071491626
avg_train_sample_per_sec: 500.86843071491626
avg_episode_per_sec: 2.113368905970111
collect_time: 0.9463563102258901
reward_mean: 1210.0
reward_std: 183.0
reward_max: 1393.0
reward_min: 1027.0
total_envstep_count: 699104
total_train_sample_count: 699065
total_episode_count: 4080
total_duration: 1390.0597884210786
[2022-12-21 15:59:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1548
train_sample_count: 1548
avg_envstep_per_episode: 258.0
avg_sample_per_episode: 258.0
avg_envstep_per_sec: 496.62439614566523
avg_train_sample_per_sec: 496.62439614566523
avg_episode_per_sec: 1.9249007602545163
collect_time: 3.117043810199681
reward_mean: 1391.8333740234375
reward_std: 740.3023071289062
reward_max: 2321.0
reward_min: 231.0
total_envstep_count: 700115
total_train_sample_count: 700073
total_episode_count: 4086
total_duration: 1393.1768322312782
[2022-12-21 15:59:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1439
train_sample_count: 1439
avg_envstep_per_episode: 239.83333333333334
avg_sample_per_episode: 239.83333333333334
avg_envstep_per_sec: 489.73075291287626
avg_train_sample_per_sec: 489.73075291287626
avg_episode_per_sec: 2.0419628335491713
collect_time: 2.938349269350459
reward_mean: 1322.8333740234375
reward_std: 425.5460510253906
reward_max: 1892.0
reward_min: 732.0
total_envstep_count: 701134
total_train_sample_count: 701092
total_episode_count: 4092
total_duration: 1396.1151815006288
[2022-12-21 15:59:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 526
train_sample_count: 526
avg_envstep_per_episode: 263.0
avg_sample_per_episode: 263.0
avg_envstep_per_sec: 497.0532119067683
avg_train_sample_per_sec: 497.0532119067683
avg_episode_per_sec: 1.8899361669458872
collect_time: 1.0582367991994008
reward_mean: 1484.0
reward_std: 176.0
reward_max: 1660.0
reward_min: 1308.0
total_envstep_count: 702101
total_train_sample_count: 702074
total_episode_count: 4094
total_duration: 1397.1734182998282
[2022-12-21 15:59:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1017
train_sample_count: 1017
avg_envstep_per_episode: 254.25
avg_sample_per_episode: 254.25
avg_envstep_per_sec: 501.43369693988865
avg_train_sample_per_sec: 501.43369693988865
avg_episode_per_sec: 1.9722072642670154
collect_time: 2.0281843964744892
reward_mean: 1465.0
reward_std: 395.2935485839844
reward_max: 1832.0
reward_min: 802.0
total_envstep_count: 703098
total_train_sample_count: 703067
total_episode_count: 4098
total_duration: 1399.2016026963026
[2022-12-21 15:59:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 565
train_sample_count: 565
avg_envstep_per_episode: 282.5
avg_sample_per_episode: 282.5
avg_envstep_per_sec: 507.17894615563586
avg_train_sample_per_sec: 507.17894615563586
avg_episode_per_sec: 1.7953237032057905
collect_time: 1.1140052328327936
reward_mean: 1749.5
reward_std: 79.5
reward_max: 1829.0
reward_min: 1670.0
total_envstep_count: 704073
total_train_sample_count: 704040
total_episode_count: 4100
total_duration: 1400.3156079291355
[2022-12-21 15:59:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1968
train_sample_count: 1968
avg_envstep_per_episode: 281.14285714285717
avg_sample_per_episode: 281.14285714285717
avg_envstep_per_sec: 510.83318567301677
avg_train_sample_per_sec: 510.83318567301677
avg_episode_per_sec: 1.8169879571702832
collect_time: 3.852529661727405
reward_mean: 1608.4285888671875
reward_std: 524.4523315429688
reward_max: 2595.0
reward_min: 722.0
total_envstep_count: 705093
total_train_sample_count: 705060
total_episode_count: 4107
total_duration: 1404.168137590863
[2022-12-21 15:59:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 379
train_sample_count: 379
avg_envstep_per_episode: 189.5
avg_sample_per_episode: 189.5
avg_envstep_per_sec: 511.85796038042184
avg_train_sample_per_sec: 511.85796038042184
avg_episode_per_sec: 2.701097416255524
collect_time: 0.7404397886443351
reward_mean: 972.5
reward_std: 339.5
reward_max: 1312.0
reward_min: 633.0
total_envstep_count: 706075
total_train_sample_count: 706027
total_episode_count: 4109
total_duration: 1404.9085773795073
[2022-12-21 15:59:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1362
train_sample_count: 1362
avg_envstep_per_episode: 272.4
avg_sample_per_episode: 272.4
avg_envstep_per_sec: 506.56748293830293
avg_train_sample_per_sec: 506.56748293830293
avg_episode_per_sec: 1.859645678921817
collect_time: 2.6886842244587656
reward_mean: 1554.800048828125
reward_std: 179.85260009765625
reward_max: 1825.0
reward_min: 1322.0
total_envstep_count: 707030
total_train_sample_count: 706993
total_episode_count: 4114
total_duration: 1407.597261603966
[2022-12-21 15:59:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 763
train_sample_count: 763
avg_envstep_per_episode: 190.75
avg_sample_per_episode: 190.75
avg_envstep_per_sec: 496.66120779148275
avg_train_sample_per_sec: 496.66120779148275
avg_episode_per_sec: 2.60372848121354
collect_time: 1.5362584957920378
reward_mean: 1045.25
reward_std: 361.2148742675781
reward_max: 1407.0
reward_min: 627.0
total_envstep_count: 708011
total_train_sample_count: 707972
total_episode_count: 4118
total_duration: 1409.133520099758
[2022-12-21 15:59:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1444
train_sample_count: 1444
avg_envstep_per_episode: 206.28571428571428
avg_sample_per_episode: 206.28571428571428
avg_envstep_per_sec: 502.78098997279756
avg_train_sample_per_sec: 502.78098997279756
avg_episode_per_sec: 2.437303968012176
collect_time: 2.87202584982007
reward_mean: 1102.4285888671875
reward_std: 321.348876953125
reward_max: 1404.0
reward_min: 627.0
total_envstep_count: 709013
total_train_sample_count: 708972
total_episode_count: 4125
total_duration: 1412.0055459495782
[2022-12-21 15:59:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 500
train_sample_count: 500
avg_envstep_per_episode: 250.0
avg_sample_per_episode: 250.0
avg_envstep_per_sec: 506.4356119878495
avg_train_sample_per_sec: 506.4356119878495
avg_episode_per_sec: 2.025742447951398
collect_time: 0.9872923391730124
reward_mean: 1603.0
reward_std: 288.0
reward_max: 1891.0
reward_min: 1315.0
total_envstep_count: 709987
total_train_sample_count: 709952
total_episode_count: 4127
total_duration: 1412.9928382887513
[2022-12-21 15:59:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1119
train_sample_count: 1119
avg_envstep_per_episode: 223.8
avg_sample_per_episode: 223.8
avg_envstep_per_sec: 507.880251927216
avg_train_sample_per_sec: 507.880251927216
avg_episode_per_sec: 2.269348757494263
collect_time: 2.2032752715897352
reward_mean: 1206.199951171875
reward_std: 345.2821350097656
reward_max: 1820.0
reward_min: 809.0
total_envstep_count: 710983
total_train_sample_count: 710951
total_episode_count: 4132
total_duration: 1415.196113560341
[2022-12-21 16:00:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 860
train_sample_count: 860
avg_envstep_per_episode: 143.33333333333334
avg_sample_per_episode: 143.33333333333334
avg_envstep_per_sec: 501.1936761489761
avg_train_sample_per_sec: 501.1936761489761
avg_episode_per_sec: 3.4967000661556473
collect_time: 1.715903533755624
reward_mean: 781.0
reward_std: 337.7745666503906
reward_max: 1310.0
reward_min: 231.0
total_envstep_count: 711977
total_train_sample_count: 711943
total_episode_count: 4138
total_duration: 1416.9120170940967
[2022-12-21 16:00:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 403
train_sample_count: 403
avg_envstep_per_episode: 403.0
avg_sample_per_episode: 403.0
avg_envstep_per_sec: 501.4975712052596
avg_train_sample_per_sec: 501.4975712052596
avg_episode_per_sec: 1.2444108466631751
collect_time: 0.8035931241530476
reward_mean: 1653.0
reward_std: 0.0
reward_max: 1653.0
reward_min: 1653.0
total_envstep_count: 713048
total_train_sample_count: 713006
total_episode_count: 4139
total_duration: 1417.7156102182496
[2022-12-21 16:00:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1358
train_sample_count: 1358
avg_envstep_per_episode: 226.33333333333334
avg_sample_per_episode: 226.33333333333334
avg_envstep_per_sec: 494.46339692014897
avg_train_sample_per_sec: 494.46339692014897
avg_episode_per_sec: 2.184668911281954
collect_time: 2.7464115816429255
reward_mean: 1309.3333740234375
reward_std: 337.3300476074219
reward_max: 1671.0
reward_min: 613.0
total_envstep_count: 714042
total_train_sample_count: 714004
total_episode_count: 4145
total_duration: 1420.4620217998925
[2022-12-21 16:00:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1452
train_sample_count: 1452
avg_envstep_per_episode: 363.0
avg_sample_per_episode: 363.0
avg_envstep_per_sec: 498.4373618802893
avg_train_sample_per_sec: 498.4373618802893
avg_episode_per_sec: 1.3731056801109898
collect_time: 2.913104255512711
reward_mean: 1806.5
reward_std: 741.4979858398438
reward_max: 2979.0
reward_min: 1045.0
total_envstep_count: 715014
total_train_sample_count: 714976
total_episode_count: 4149
total_duration: 1423.3751260554052
[2022-12-21 16:00:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1036
train_sample_count: 1036
avg_envstep_per_episode: 259.0
avg_sample_per_episode: 259.0
avg_envstep_per_sec: 508.68387691189105
avg_train_sample_per_sec: 508.68387691189105
avg_episode_per_sec: 1.9640304127872241
collect_time: 2.0366283403541905
reward_mean: 1446.25
reward_std: 136.82904052734375
reward_max: 1672.0
reward_min: 1303.0
total_envstep_count: 716003
total_train_sample_count: 715964
total_episode_count: 4153
total_duration: 1425.4117543957593
[2022-12-21 16:00:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 709
train_sample_count: 709
avg_envstep_per_episode: 236.33333333333334
avg_sample_per_episode: 236.33333333333334
avg_envstep_per_sec: 505.0476824832866
avg_train_sample_per_sec: 505.0476824832866
avg_episode_per_sec: 2.1370141712974045
collect_time: 1.4038278455489452
reward_mean: 1466.3333740234375
reward_std: 293.6895446777344
reward_max: 1676.0
reward_min: 1051.0
total_envstep_count: 717001
total_train_sample_count: 716961
total_episode_count: 4156
total_duration: 1426.8155822413082
[2022-12-21 16:00:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1172
train_sample_count: 1172
avg_envstep_per_episode: 234.4
avg_sample_per_episode: 234.4
avg_envstep_per_sec: 502.3809163154072
avg_train_sample_per_sec: 502.3809163154072
avg_episode_per_sec: 2.1432632948609522
collect_time: 2.33289116273714
reward_mean: 1416.800048828125
reward_std: 78.01127624511719
reward_max: 1554.0
reward_min: 1311.0
total_envstep_count: 717983
total_train_sample_count: 717941
total_episode_count: 4161
total_duration: 1429.1484734040453
[2022-12-21 16:00:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 391
train_sample_count: 391
avg_envstep_per_episode: 130.33333333333334
avg_sample_per_episode: 130.33333333333334
avg_envstep_per_sec: 501.16974401059935
avg_train_sample_per_sec: 501.16974401059935
avg_episode_per_sec: 3.84529215353401
collect_time: 0.7801747904233634
reward_mean: 661.6666870117188
reward_std: 50.440284729003906
reward_max: 733.0
reward_min: 626.0
total_envstep_count: 718941
total_train_sample_count: 718908
total_episode_count: 4164
total_duration: 1429.9286481944687
[2022-12-21 16:00:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 481
train_sample_count: 481
avg_envstep_per_episode: 240.5
avg_sample_per_episode: 240.5
avg_envstep_per_sec: 507.4217985281965
avg_train_sample_per_sec: 507.4217985281965
avg_episode_per_sec: 2.109861948142189
collect_time: 0.9479293191486169
reward_mean: 1441.0
reward_std: 408.0
reward_max: 1849.0
reward_min: 1033.0
total_envstep_count: 719939
total_train_sample_count: 719881
total_episode_count: 4166
total_duration: 1430.8765775136173
[2022-12-21 16:00:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2482
train_sample_count: 2482
avg_envstep_per_episode: 310.25
avg_sample_per_episode: 310.25
avg_envstep_per_sec: 502.8040000138472
avg_train_sample_per_sec: 502.8040000138472
avg_episode_per_sec: 1.6206414182557525
collect_time: 4.9363171333793
reward_mean: 1559.375
reward_std: 658.3714599609375
reward_max: 2978.0
reward_min: 714.0
total_envstep_count: 720981
total_train_sample_count: 720935
total_episode_count: 4174
total_duration: 1435.8128946469967
[2022-12-21 16:00:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 623
train_sample_count: 623
avg_envstep_per_episode: 155.75
avg_sample_per_episode: 155.75
avg_envstep_per_sec: 519.2379586727745
avg_train_sample_per_sec: 519.2379586727745
avg_episode_per_sec: 3.3337910669199005
collect_time: 1.1998352385338928
reward_mean: 872.25
reward_std: 178.83843994140625
reward_max: 1046.0
reward_min: 623.0
total_envstep_count: 721963
total_train_sample_count: 721906
total_episode_count: 4178
total_duration: 1437.0127298855307
[2022-12-21 16:00:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1055
train_sample_count: 1055
avg_envstep_per_episode: 263.75
avg_sample_per_episode: 263.75
avg_envstep_per_sec: 516.9210534940247
avg_train_sample_per_sec: 516.9210534940247
avg_episode_per_sec: 1.9598902502143116
collect_time: 2.0409306080085887
reward_mean: 1430.25
reward_std: 118.26532745361328
reward_max: 1551.0
reward_min: 1311.0
total_envstep_count: 722936
total_train_sample_count: 722901
total_episode_count: 4182
total_duration: 1439.0536604935394
[2022-12-21 16:00:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 932
train_sample_count: 932
avg_envstep_per_episode: 186.4
avg_sample_per_episode: 186.4
avg_envstep_per_sec: 513.043092621272
avg_train_sample_per_sec: 513.043092621272
avg_episode_per_sec: 2.7523771063372955
collect_time: 1.8166115349846486
reward_mean: 1095.199951171875
reward_std: 383.1007385253906
reward_max: 1409.0
reward_min: 626.0
total_envstep_count: 723915
total_train_sample_count: 723881
total_episode_count: 4187
total_duration: 1440.8702720285241
[2022-12-21 16:00:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 588
train_sample_count: 588
avg_envstep_per_episode: 294.0
avg_sample_per_episode: 294.0
avg_envstep_per_sec: 513.5945249775892
avg_train_sample_per_sec: 513.5945249775892
avg_episode_per_sec: 1.7469201529849974
collect_time: 1.1448720175232738
reward_mean: 1859.0
reward_std: 37.0
reward_max: 1896.0
reward_min: 1822.0
total_envstep_count: 724873
total_train_sample_count: 724841
total_episode_count: 4189
total_duration: 1442.0151440460475
[2022-12-21 16:00:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1598
train_sample_count: 1598
avg_envstep_per_episode: 228.28571428571428
avg_sample_per_episode: 228.28571428571428
avg_envstep_per_sec: 504.2457900825331
avg_train_sample_per_sec: 504.2457900825331
avg_episode_per_sec: 2.2088363770824353
collect_time: 3.1690894231133693
reward_mean: 1387.5714111328125
reward_std: 346.36102294921875
reward_max: 1894.0
reward_min: 1038.0
total_envstep_count: 725867
total_train_sample_count: 725827
total_episode_count: 4196
total_duration: 1445.1842334691607
[2022-12-21 16:00:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 249
train_sample_count: 249
avg_envstep_per_episode: 249.0
avg_sample_per_episode: 249.0
avg_envstep_per_sec: 503.3201210806167
avg_train_sample_per_sec: 503.3201210806167
avg_episode_per_sec: 2.0213659481149264
collect_time: 0.49471497277995313
reward_mean: 1408.0
reward_std: 0.0
reward_max: 1408.0
reward_min: 1408.0
total_envstep_count: 726834
total_train_sample_count: 726796
total_episode_count: 4197
total_duration: 1445.6789484419407
[2022-12-21 16:00:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1274
train_sample_count: 1274
avg_envstep_per_episode: 254.8
avg_sample_per_episode: 254.8
avg_envstep_per_sec: 512.6485530776765
avg_train_sample_per_sec: 512.6485530776765
avg_episode_per_sec: 2.0119644940254178
collect_time: 2.4851333186284514
reward_mean: 1422.4000244140625
reward_std: 221.18101501464844
reward_max: 1670.0
reward_min: 1048.0
total_envstep_count: 727814
total_train_sample_count: 727782
total_episode_count: 4202
total_duration: 1448.1640817605692
[2022-12-21 16:00:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1308
train_sample_count: 1308
avg_envstep_per_episode: 261.6
avg_sample_per_episode: 261.6
avg_envstep_per_sec: 507.28233427812665
avg_train_sample_per_sec: 507.28233427812665
avg_episode_per_sec: 1.939152653968374
collect_time: 2.578445791654289
reward_mean: 1494.199951171875
reward_std: 569.6544189453125
reward_max: 2333.0
reward_min: 717.0
total_envstep_count: 728841
total_train_sample_count: 728802
total_episode_count: 4207
total_duration: 1450.7425275522235
[2022-12-21 16:01:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1106
train_sample_count: 1106
avg_envstep_per_episode: 184.33333333333334
avg_sample_per_episode: 184.33333333333334
avg_envstep_per_sec: 508.7859619765083
avg_train_sample_per_sec: 508.7859619765083
avg_episode_per_sec: 2.7601408425488696
collect_time: 2.1738021145541477
reward_mean: 1100.3333740234375
reward_std: 332.1945495605469
reward_max: 1555.0
reward_min: 626.0
total_envstep_count: 729828
total_train_sample_count: 729788
total_episode_count: 4213
total_duration: 1452.9163296667775
[2022-12-21 16:01:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 855
train_sample_count: 855
avg_envstep_per_episode: 213.75
avg_sample_per_episode: 213.75
avg_envstep_per_sec: 519.9823187451996
avg_train_sample_per_sec: 519.9823187451996
avg_episode_per_sec: 2.432665818690992
collect_time: 1.6442866789456452
reward_mean: 1139.75
reward_std: 504.4617919921875
reward_max: 1883.0
reward_min: 626.0
total_envstep_count: 730816
total_train_sample_count: 730763
total_episode_count: 4217
total_duration: 1454.5606163457232
[2022-12-21 16:01:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1104
train_sample_count: 1104
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 516.6912278206762
avg_train_sample_per_sec: 516.6912278206762
avg_episode_per_sec: 2.808104499025414
collect_time: 2.1366726210090725
reward_mean: 1024.1666259765625
reward_std: 462.1253356933594
reward_max: 1550.0
reward_min: 231.0
total_envstep_count: 731797
total_train_sample_count: 731747
total_episode_count: 4223
total_duration: 1456.6972889667322
[2022-12-21 16:01:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 883
train_sample_count: 883
avg_envstep_per_episode: 220.75
avg_sample_per_episode: 220.75
avg_envstep_per_sec: 511.10080846774713
avg_train_sample_per_sec: 511.10080846774713
avg_episode_per_sec: 2.3152924505900208
collect_time: 1.7276435203598812
reward_mean: 1241.25
reward_std: 401.6648864746094
reward_max: 1674.0
reward_min: 586.0
total_envstep_count: 732801
total_train_sample_count: 732762
total_episode_count: 4227
total_duration: 1458.424932487092
[2022-12-21 16:01:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 971
train_sample_count: 971
avg_envstep_per_episode: 242.75
avg_sample_per_episode: 242.75
avg_envstep_per_sec: 502.76202502519607
avg_train_sample_per_sec: 502.76202502519607
avg_episode_per_sec: 2.0711102987649683
collect_time: 1.9313312296236735
reward_mean: 1429.5
reward_std: 120.52074432373047
reward_max: 1551.0
reward_min: 1306.0
total_envstep_count: 733782
total_train_sample_count: 733757
total_episode_count: 4231
total_duration: 1460.3562637167158
[2022-12-21 16:01:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 697
train_sample_count: 697
avg_envstep_per_episode: 232.33333333333334
avg_sample_per_episode: 232.33333333333334
avg_envstep_per_sec: 501.6340275007823
avg_train_sample_per_sec: 501.6340275007823
avg_episode_per_sec: 2.159113461265921
collect_time: 1.3894591710067217
reward_mean: 1329.3333740234375
reward_std: 216.60459899902344
reward_max: 1550.0
reward_min: 1035.0
total_envstep_count: 734779
total_train_sample_count: 734730
total_episode_count: 4234
total_duration: 1461.7457228877226
[2022-12-21 16:01:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1193
train_sample_count: 1193
avg_envstep_per_episode: 238.6
avg_sample_per_episode: 238.6
avg_envstep_per_sec: 496.18177381731925
avg_train_sample_per_sec: 496.18177381731925
avg_episode_per_sec: 2.079554793869737
collect_time: 2.404360786616137
reward_mean: 1447.4000244140625
reward_std: 217.20645141601562
reward_max: 1679.0
reward_min: 1048.0
total_envstep_count: 735750
total_train_sample_count: 735719
total_episode_count: 4239
total_duration: 1464.1500836743387
[2022-12-21 16:01:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 782
train_sample_count: 782
avg_envstep_per_episode: 195.5
avg_sample_per_episode: 195.5
avg_envstep_per_sec: 493.8500834086883
avg_train_sample_per_sec: 493.8500834086883
avg_episode_per_sec: 2.526087383164646
collect_time: 1.5834764967587374
reward_mean: 1151.5
reward_std: 281.5328674316406
reward_max: 1412.0
reward_min: 740.0
total_envstep_count: 736730
total_train_sample_count: 736693
total_episode_count: 4243
total_duration: 1465.7335601710975
[2022-12-21 16:01:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1118
train_sample_count: 1118
avg_envstep_per_episode: 223.6
avg_sample_per_episode: 223.6
avg_envstep_per_sec: 502.4067321496593
avg_train_sample_per_sec: 502.4067321496593
avg_episode_per_sec: 2.2468995176639504
collect_time: 2.225288652515438
reward_mean: 1342.0
reward_std: 237.941162109375
reward_max: 1668.0
reward_min: 1047.0
total_envstep_count: 737726
total_train_sample_count: 737679
total_episode_count: 4248
total_duration: 1467.958848823613
[2022-12-21 16:02:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 689
train_sample_count: 689
avg_envstep_per_episode: 137.8
avg_sample_per_episode: 137.8
avg_envstep_per_sec: 507.26929739614377
avg_train_sample_per_sec: 507.26929739614377
avg_episode_per_sec: 3.6811995456904483
collect_time: 1.358252911297205
reward_mean: 807.2000122070312
reward_std: 488.7029113769531
reward_max: 1407.0
reward_min: 223.0
total_envstep_count: 738755
total_train_sample_count: 738704
total_episode_count: 4253
total_duration: 1469.3171017349102
[2022-12-21 16:02:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 483
train_sample_count: 483
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 511.5472931530428
avg_train_sample_per_sec: 511.5472931530428
avg_episode_per_sec: 3.177312379832564
collect_time: 0.9441942249814581
reward_mean: 892.3333129882812
reward_std: 216.6199951171875
reward_max: 1048.0
reward_min: 586.0
total_envstep_count: 739712
total_train_sample_count: 739679
total_episode_count: 4256
total_duration: 1470.2612959598916
[2022-12-21 16:02:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1004
train_sample_count: 1004
avg_envstep_per_episode: 251.0
avg_sample_per_episode: 251.0
avg_envstep_per_sec: 517.9000842233255
avg_train_sample_per_sec: 517.9000842233255
avg_episode_per_sec: 2.0633469490969145
collect_time: 1.9385978697139228
reward_mean: 1520.25
reward_std: 353.5225524902344
reward_max: 1892.0
reward_min: 1048.0
total_envstep_count: 740709
total_train_sample_count: 740671
total_episode_count: 4260
total_duration: 1472.1998938296056
[2022-12-21 16:02:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1147
train_sample_count: 1147
avg_envstep_per_episode: 229.4
avg_sample_per_episode: 229.4
avg_envstep_per_sec: 510.20226443662057
avg_train_sample_per_sec: 510.20226443662057
avg_episode_per_sec: 2.2240726435772475
collect_time: 2.2481280071670184
reward_mean: 1297.4000244140625
reward_std: 525.6761474609375
reward_max: 1883.0
reward_min: 628.0
total_envstep_count: 741689
total_train_sample_count: 741662
total_episode_count: 4265
total_duration: 1474.4480218367726
[2022-12-21 16:02:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 872
train_sample_count: 872
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 495.1145100926889
avg_train_sample_per_sec: 495.1145100926889
avg_episode_per_sec: 2.2711674774893984
collect_time: 1.7612087349990118
reward_mean: 1174.25
reward_std: 134.28956604003906
reward_max: 1312.0
reward_min: 1037.0
total_envstep_count: 742685
total_train_sample_count: 742654
total_episode_count: 4269
total_duration: 1476.2092305717715
[2022-12-21 16:02:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 654
train_sample_count: 654
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 497.3369263303871
avg_train_sample_per_sec: 497.3369263303871
avg_episode_per_sec: 2.2813620473870966
collect_time: 1.3150039045472761
reward_mean: 1335.3333740234375
reward_std: 213.4359130859375
reward_max: 1552.0
reward_min: 1045.0
total_envstep_count: 743659
total_train_sample_count: 743632
total_episode_count: 4272
total_duration: 1477.5242344763187
[2022-12-21 16:02:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 948
train_sample_count: 948
avg_envstep_per_episode: 189.6
avg_sample_per_episode: 189.6
avg_envstep_per_sec: 514.7133955993326
avg_train_sample_per_sec: 514.7133955993326
avg_episode_per_sec: 2.714733099152598
collect_time: 1.8418016863465312
reward_mean: 1151.800048828125
reward_std: 431.5772705078125
reward_max: 1555.0
reward_min: 627.0
total_envstep_count: 744686
total_train_sample_count: 744640
total_episode_count: 4277
total_duration: 1479.3660361626653
[2022-12-21 16:02:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 475
train_sample_count: 475
avg_envstep_per_episode: 237.5
avg_sample_per_episode: 237.5
avg_envstep_per_sec: 512.0669118384196
avg_train_sample_per_sec: 512.0669118384196
avg_episode_per_sec: 2.1560712077407143
collect_time: 0.9276131478494828
reward_mean: 1469.0
reward_std: 423.0
reward_max: 1892.0
reward_min: 1046.0
total_envstep_count: 745645
total_train_sample_count: 745607
total_episode_count: 4279
total_duration: 1480.2936493105149
[2022-12-21 16:02:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1376
train_sample_count: 1376
avg_envstep_per_episode: 229.33333333333334
avg_sample_per_episode: 229.33333333333334
avg_envstep_per_sec: 510.12002875113023
avg_train_sample_per_sec: 510.12002875113023
avg_episode_per_sec: 2.2243605904845793
collect_time: 2.697404380237151
reward_mean: 1380.3333740234375
reward_std: 254.89779663085938
reward_max: 1888.0
reward_min: 1036.0
total_envstep_count: 746633
total_train_sample_count: 746599
total_episode_count: 4285
total_duration: 1482.991053690752
[2022-12-21 16:02:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 376
train_sample_count: 376
avg_envstep_per_episode: 188.0
avg_sample_per_episode: 188.0
avg_envstep_per_sec: 499.0264957700884
avg_train_sample_per_sec: 499.0264957700884
avg_episode_per_sec: 2.654396254096215
collect_time: 0.7534670066361182
reward_mean: 1184.5
reward_std: 133.5
reward_max: 1318.0
reward_min: 1051.0
total_envstep_count: 747607
total_train_sample_count: 747575
total_episode_count: 4287
total_duration: 1483.7445206973882
[2022-12-21 16:02:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1483
train_sample_count: 1483
avg_envstep_per_episode: 247.16666666666666
avg_sample_per_episode: 247.16666666666666
avg_envstep_per_sec: 499.4503616810906
avg_train_sample_per_sec: 499.4503616810906
avg_episode_per_sec: 2.0207027444953094
collect_time: 2.9692640425935384
reward_mean: 1378.3333740234375
reward_std: 393.0252990722656
reward_max: 1829.0
reward_min: 750.0
total_envstep_count: 748609
total_train_sample_count: 748554
total_episode_count: 4293
total_duration: 1486.7137847399817
[2022-12-21 16:02:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2513
train_sample_count: 2513
avg_envstep_per_episode: 837.6666666666666
avg_sample_per_episode: 837.6666666666666
avg_envstep_per_sec: 503.568549318709
avg_train_sample_per_sec: 503.568549318709
avg_episode_per_sec: 0.6011562466996129
collect_time: 4.990383143267988
reward_mean: 1688.3333740234375
reward_std: 471.854736328125
reward_max: 2143.0
reward_min: 1038.0
total_envstep_count: 749575
total_train_sample_count: 749531
total_episode_count: 4296
total_duration: 1491.7041678832497
[2022-12-21 16:02:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1071
train_sample_count: 1071
avg_envstep_per_episode: 267.75
avg_sample_per_episode: 267.75
avg_envstep_per_sec: 497.8463639977129
avg_train_sample_per_sec: 497.8463639977129
avg_episode_per_sec: 1.8593701736609258
collect_time: 2.151266088196077
reward_mean: 1640.25
reward_std: 206.67532348632812
reward_max: 1893.0
reward_min: 1317.0
total_envstep_count: 750548
total_train_sample_count: 750506
total_episode_count: 4300
total_duration: 1493.8554339714458
[2022-12-21 16:02:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 235
train_sample_count: 235
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 491.2536933142883
avg_train_sample_per_sec: 491.2536933142883
avg_episode_per_sec: 2.0904412481459076
collect_time: 0.4783679048081061
reward_mean: 1302.0
reward_std: 0.0
reward_max: 1302.0
reward_min: 1302.0
total_envstep_count: 751515
total_train_sample_count: 751473
total_episode_count: 4301
total_duration: 1494.3338018762538
[2022-12-21 16:02:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2039
train_sample_count: 2039
avg_envstep_per_episode: 254.875
avg_sample_per_episode: 254.875
avg_envstep_per_sec: 490.33449360717725
avg_train_sample_per_sec: 490.33449360717725
avg_episode_per_sec: 1.9238234177819609
collect_time: 4.158385809246185
reward_mean: 1415.125
reward_std: 548.25390625
reward_max: 2324.0
reward_min: 223.0
total_envstep_count: 752541
total_train_sample_count: 752516
total_episode_count: 4309
total_duration: 1498.4921876855
[2022-12-21 16:02:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 426
train_sample_count: 426
avg_envstep_per_episode: 213.0
avg_sample_per_episode: 213.0
avg_envstep_per_sec: 506.8457129973076
avg_train_sample_per_sec: 506.8457129973076
avg_episode_per_sec: 2.3795573380155286
collect_time: 0.8404924596891341
reward_mean: 1169.5
reward_std: 131.5
reward_max: 1301.0
reward_min: 1038.0
total_envstep_count: 753499
total_train_sample_count: 753482
total_episode_count: 4311
total_duration: 1499.3326801451892
[2022-12-21 16:02:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 837
train_sample_count: 837
avg_envstep_per_episode: 209.25
avg_sample_per_episode: 209.25
avg_envstep_per_sec: 520.046029347519
avg_train_sample_per_sec: 520.046029347519
avg_episode_per_sec: 2.4852856838591113
collect_time: 1.6094729173303186
reward_mean: 1294.75
reward_std: 146.0862274169922
reward_max: 1409.0
reward_min: 1051.0
total_envstep_count: 754505
total_train_sample_count: 754451
total_episode_count: 4315
total_duration: 1500.9421530625195
[2022-12-21 16:03:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1204
train_sample_count: 1204
avg_envstep_per_episode: 301.0
avg_sample_per_episode: 301.0
avg_envstep_per_sec: 516.1533077718744
avg_train_sample_per_sec: 516.1533077718744
avg_episode_per_sec: 1.7147950424314766
collect_time: 2.3326402870445904
reward_mean: 1724.25
reward_std: 439.61083984375
reward_max: 2327.0
reward_min: 1134.0
total_envstep_count: 755461
total_train_sample_count: 755427
total_episode_count: 4319
total_duration: 1503.274793349564
[2022-12-21 16:03:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 809
train_sample_count: 809
avg_envstep_per_episode: 202.25
avg_sample_per_episode: 202.25
avg_envstep_per_sec: 511.2535715385804
avg_train_sample_per_sec: 511.2535715385804
avg_episode_per_sec: 2.5278297727494703
collect_time: 1.582385033644603
reward_mean: 1123.75
reward_std: 684.8442993164062
reward_max: 1890.0
reward_min: 223.0
total_envstep_count: 756451
total_train_sample_count: 756404
total_episode_count: 4323
total_duration: 1504.8571783832087
[2022-12-21 16:03:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 980
train_sample_count: 980
avg_envstep_per_episode: 245.0
avg_sample_per_episode: 245.0
avg_envstep_per_sec: 508.6226007614365
avg_train_sample_per_sec: 508.6226007614365
avg_episode_per_sec: 2.076010615352802
collect_time: 1.9267724213058663
reward_mean: 1417.25
reward_std: 306.85614013671875
reward_max: 1894.0
reward_min: 1041.0
total_envstep_count: 757431
total_train_sample_count: 757396
total_episode_count: 4327
total_duration: 1506.7839508045147
[2022-12-21 16:03:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 844
train_sample_count: 844
avg_envstep_per_episode: 281.3333333333333
avg_sample_per_episode: 281.3333333333333
avg_envstep_per_sec: 507.27722094598687
avg_train_sample_per_sec: 507.27722094598687
avg_episode_per_sec: 1.8031180839312329
collect_time: 1.6637845445259334
reward_mean: 1818.6666259765625
reward_std: 105.12321472167969
reward_max: 1893.0
reward_min: 1670.0
total_envstep_count: 758412
total_train_sample_count: 758372
total_episode_count: 4330
total_duration: 1508.4477353490406
[2022-12-21 16:03:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1297
train_sample_count: 1297
avg_envstep_per_episode: 259.4
avg_sample_per_episode: 259.4
avg_envstep_per_sec: 503.8642859824542
avg_train_sample_per_sec: 503.8642859824542
avg_episode_per_sec: 1.9424220739493223
collect_time: 2.5741058377873696
reward_mean: 1512.0
reward_std: 315.96075439453125
reward_max: 1893.0
reward_min: 1033.0
total_envstep_count: 759409
total_train_sample_count: 759381
total_episode_count: 4335
total_duration: 1511.021841186828
[2022-12-21 16:03:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 618
train_sample_count: 618
avg_envstep_per_episode: 206.0
avg_sample_per_episode: 206.0
avg_envstep_per_sec: 502.0698834979504
avg_train_sample_per_sec: 502.0698834979504
avg_episode_per_sec: 2.437232444164808
collect_time: 1.230904342826456
reward_mean: 1254.3333740234375
reward_std: 299.577880859375
reward_max: 1678.0
reward_min: 1042.0
total_envstep_count: 760367
total_train_sample_count: 760347
total_episode_count: 4338
total_duration: 1512.2527455296545
[2022-12-21 16:03:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1470
train_sample_count: 1470
avg_envstep_per_episode: 245.0
avg_sample_per_episode: 245.0
avg_envstep_per_sec: 510.2516623700116
avg_train_sample_per_sec: 510.2516623700116
avg_episode_per_sec: 2.0826598464082107
collect_time: 2.880931329399613
reward_mean: 1480.0
reward_std: 410.6872253417969
reward_max: 2335.0
reward_min: 1033.0
total_envstep_count: 761394
total_train_sample_count: 761337
total_episode_count: 4344
total_duration: 1515.133676859054
[2022-12-21 16:03:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1133
train_sample_count: 1133
avg_envstep_per_episode: 188.83333333333334
avg_sample_per_episode: 188.83333333333334
avg_envstep_per_sec: 492.90556554409113
avg_train_sample_per_sec: 492.90556554409113
avg_episode_per_sec: 2.6102677786977466
collect_time: 2.2986147432710444
reward_mean: 1091.0
reward_std: 529.1068115234375
reward_max: 1676.0
reward_min: 231.0
total_envstep_count: 762396
total_train_sample_count: 762350
total_episode_count: 4350
total_duration: 1517.432291602325
[2022-12-21 16:03:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 241
train_sample_count: 241
avg_envstep_per_episode: 241.0
avg_sample_per_episode: 241.0
avg_envstep_per_sec: 490.2440214162392
avg_train_sample_per_sec: 490.2440214162392
avg_episode_per_sec: 2.034207557743731
collect_time: 0.4915919204966299
reward_mean: 1406.0
reward_std: 0.0
reward_max: 1406.0
reward_min: 1406.0
total_envstep_count: 763355
total_train_sample_count: 763311
total_episode_count: 4351
total_duration: 1517.9238835228216
[2022-12-21 16:03:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1048
train_sample_count: 1048
avg_envstep_per_episode: 262.0
avg_sample_per_episode: 262.0
avg_envstep_per_sec: 485.31760690632626
avg_train_sample_per_sec: 485.31760690632626
avg_episode_per_sec: 1.852357278268421
collect_time: 2.159410631484219
reward_mean: 1500.5
reward_std: 211.29421997070312
reward_max: 1824.0
reward_min: 1311.0
total_envstep_count: 764368
total_train_sample_count: 764323
total_episode_count: 4355
total_duration: 1520.0832941543058
[2022-12-21 16:03:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 511
train_sample_count: 511
avg_envstep_per_episode: 511.0
avg_sample_per_episode: 511.0
avg_envstep_per_sec: 490.0889064453291
avg_train_sample_per_sec: 490.0889064453291
avg_episode_per_sec: 0.9590780948049493
collect_time: 1.0426679593838217
reward_mean: 2599.0
reward_std: 0.0
reward_max: 2599.0
reward_min: 2599.0
total_envstep_count: 765327
total_train_sample_count: 765290
total_episode_count: 4356
total_duration: 1521.1259621136896
[2022-12-21 16:03:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2147
train_sample_count: 2147
avg_envstep_per_episode: 306.7142857142857
avg_sample_per_episode: 306.7142857142857
avg_envstep_per_sec: 502.36656580004046
avg_train_sample_per_sec: 502.36656580004046
avg_episode_per_sec: 1.637897513088162
collect_time: 4.273771676227716
reward_mean: 1632.2857666015625
reward_std: 510.59844970703125
reward_max: 2326.0
reward_min: 1037.0
total_envstep_count: 766322
total_train_sample_count: 766285
total_episode_count: 4363
total_duration: 1525.3997337899173
[2022-12-21 16:04:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 737
train_sample_count: 737
avg_envstep_per_episode: 184.25
avg_sample_per_episode: 184.25
avg_envstep_per_sec: 513.8722163348938
avg_train_sample_per_sec: 513.8722163348938
avg_episode_per_sec: 2.788994389877307
collect_time: 1.4342086934696083
reward_mean: 1134.0
reward_std: 158.232421875
reward_max: 1408.0
reward_min: 1037.0
total_envstep_count: 767279
total_train_sample_count: 767250
total_episode_count: 4367
total_duration: 1526.8339424833869
[2022-12-21 16:04:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 789
train_sample_count: 789
avg_envstep_per_episode: 263.0
avg_sample_per_episode: 263.0
avg_envstep_per_sec: 516.5131936294131
avg_train_sample_per_sec: 516.5131936294131
avg_episode_per_sec: 1.963928492887502
collect_time: 1.5275505248101955
reward_mean: 1535.3333740234375
reward_std: 253.32501220703125
reward_max: 1889.0
reward_min: 1309.0
total_envstep_count: 768260
total_train_sample_count: 768219
total_episode_count: 4370
total_duration: 1528.3614930081972
[2022-12-21 16:04:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 766
train_sample_count: 766
avg_envstep_per_episode: 255.33333333333334
avg_sample_per_episode: 255.33333333333334
avg_envstep_per_sec: 508.0297189056871
avg_train_sample_per_sec: 508.0297189056871
avg_episode_per_sec: 1.989672528351255
collect_time: 1.5077858075901336
reward_mean: 1285.0
reward_std: 541.5428466796875
reward_max: 1887.0
reward_min: 574.0
total_envstep_count: 769241
total_train_sample_count: 769189
total_episode_count: 4373
total_duration: 1529.8692788157873
[2022-12-21 16:04:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1748
train_sample_count: 1748
avg_envstep_per_episode: 249.71428571428572
avg_sample_per_episode: 249.71428571428572
avg_envstep_per_sec: 498.6407773378249
avg_train_sample_per_sec: 498.6407773378249
avg_episode_per_sec: 1.9968452181720677
collect_time: 3.5055295905247332
reward_mean: 1323.4285888671875
reward_std: 349.0946960449219
reward_max: 1887.0
reward_min: 804.0
total_envstep_count: 770252
total_train_sample_count: 770205
total_episode_count: 4380
total_duration: 1533.374808406312
[2022-12-21 16:04:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 334
train_sample_count: 334
avg_envstep_per_episode: 167.0
avg_sample_per_episode: 167.0
avg_envstep_per_sec: 491.9117002067667
avg_train_sample_per_sec: 491.9117002067667
avg_episode_per_sec: 2.945579043154291
collect_time: 0.6789836465764258
reward_mean: 893.0
reward_std: 151.0
reward_max: 1044.0
reward_min: 742.0
total_envstep_count: 771218
total_train_sample_count: 771187
total_episode_count: 4382
total_duration: 1534.0537920528884
[2022-12-21 16:04:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1527
train_sample_count: 1527
avg_envstep_per_episode: 218.14285714285714
avg_sample_per_episode: 218.14285714285714
avg_envstep_per_sec: 473.4680273322418
avg_train_sample_per_sec: 473.4680273322418
avg_episode_per_sec: 2.1704493721844744
collect_time: 3.225138577157765
reward_mean: 1296.7142333984375
reward_std: 267.07928466796875
reward_max: 1832.0
reward_min: 1044.0
total_envstep_count: 772219
total_train_sample_count: 772186
total_episode_count: 4389
total_duration: 1537.2789306300463
[2022-12-21 16:04:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 757
train_sample_count: 757
avg_envstep_per_episode: 189.25
avg_sample_per_episode: 189.25
avg_envstep_per_sec: 423.24218854074536
avg_train_sample_per_sec: 423.24218854074536
avg_episode_per_sec: 2.236418433504599
collect_time: 1.788574061130307
reward_mean: 1056.5
reward_std: 446.42047119140625
reward_max: 1652.0
reward_min: 625.0
total_envstep_count: 773232
total_train_sample_count: 773171
total_episode_count: 4393
total_duration: 1539.0675046911765
[2022-12-21 16:04:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 563
train_sample_count: 563
avg_envstep_per_episode: 281.5
avg_sample_per_episode: 281.5
avg_envstep_per_sec: 449.6532622638322
avg_train_sample_per_sec: 449.6532622638322
avg_episode_per_sec: 1.597347290457663
collect_time: 1.2520758710067184
reward_mean: 1596.5
reward_std: 296.5
reward_max: 1893.0
reward_min: 1300.0
total_envstep_count: 774198
total_train_sample_count: 774142
total_episode_count: 4395
total_duration: 1540.3195805621833
[2022-12-21 16:04:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1483
train_sample_count: 1483
avg_envstep_per_episode: 296.6
avg_sample_per_episode: 296.6
avg_envstep_per_sec: 488.62466330703325
avg_train_sample_per_sec: 488.62466330703325
avg_episode_per_sec: 1.6474196335368618
collect_time: 3.03504941801953
reward_mean: 1704.5999755859375
reward_std: 241.5248260498047
reward_max: 1892.0
reward_min: 1299.0
total_envstep_count: 775162
total_train_sample_count: 775121
total_episode_count: 4400
total_duration: 1543.3546299802028
[2022-12-21 16:05:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 831
train_sample_count: 831
avg_envstep_per_episode: 207.75
avg_sample_per_episode: 207.75
avg_envstep_per_sec: 486.66842196860614
avg_train_sample_per_sec: 486.66842196860614
avg_episode_per_sec: 2.342567614770667
collect_time: 1.7075280878889774
reward_mean: 1252.75
reward_std: 417.73638916015625
reward_max: 1895.0
reward_min: 770.0
total_envstep_count: 776160
total_train_sample_count: 776120
total_episode_count: 4404
total_duration: 1545.0621580680918
[2022-12-21 16:05:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1044
train_sample_count: 1044
avg_envstep_per_episode: 208.8
avg_sample_per_episode: 208.8
avg_envstep_per_sec: 501.0032078491404
avg_train_sample_per_sec: 501.0032078491404
avg_episode_per_sec: 2.399440650618488
collect_time: 2.0838189928603494
reward_mean: 1163.0
reward_std: 493.0821533203125
reward_max: 1893.0
reward_min: 585.0
total_envstep_count: 777116
total_train_sample_count: 777092
total_episode_count: 4409
total_duration: 1547.1459770609522
[2022-12-21 16:05:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 995
train_sample_count: 995
avg_envstep_per_episode: 199.0
avg_sample_per_episode: 199.0
avg_envstep_per_sec: 509.21868263687526
avg_train_sample_per_sec: 509.21868263687526
avg_episode_per_sec: 2.558887852446609
collect_time: 1.9539738700230216
reward_mean: 1195.4000244140625
reward_std: 507.72613525390625
reward_max: 1895.0
reward_min: 628.0
total_envstep_count: 778119
total_train_sample_count: 778063
total_episode_count: 4414
total_duration: 1549.0999509309752
[2022-12-21 16:05:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 239.0
avg_sample_per_episode: 239.0
avg_envstep_per_sec: 502.7063935163316
avg_train_sample_per_sec: 502.7063935163316
avg_episode_per_sec: 2.1033740314490865
collect_time: 1.4262798509180021
reward_mean: 1337.3333740234375
reward_std: 41.99470901489258
reward_max: 1396.0
reward_min: 1300.0
total_envstep_count: 779094
total_train_sample_count: 779044
total_episode_count: 4417
total_duration: 1550.5262307818932
[2022-12-21 16:05:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1085
train_sample_count: 1085
avg_envstep_per_episode: 271.25
avg_sample_per_episode: 271.25
avg_envstep_per_sec: 499.40793763241805
avg_train_sample_per_sec: 499.40793763241805
avg_episode_per_sec: 1.8411352539443984
collect_time: 2.172572596950989
reward_mean: 1598.5
reward_std: 295.5693664550781
reward_max: 1895.0
reward_min: 1294.0
total_envstep_count: 780058
total_train_sample_count: 780021
total_episode_count: 4421
total_duration: 1552.698803378844
[2022-12-21 16:05:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 848
train_sample_count: 848
avg_envstep_per_episode: 282.6666666666667
avg_sample_per_episode: 282.6666666666667
avg_envstep_per_sec: 497.96299464318656
avg_train_sample_per_sec: 497.96299464318656
avg_episode_per_sec: 1.7616615376527827
collect_time: 1.7029377867880144
reward_mean: 1365.3333740234375
reward_std: 51.73221969604492
reward_max: 1411.0
reward_min: 1293.0
total_envstep_count: 781039
total_train_sample_count: 781013
total_episode_count: 4424
total_duration: 1554.401741165632
[2022-12-21 16:05:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1033
train_sample_count: 1033
avg_envstep_per_episode: 258.25
avg_sample_per_episode: 258.25
avg_envstep_per_sec: 499.32155605950584
avg_train_sample_per_sec: 499.32155605950584
avg_episode_per_sec: 1.9334813400174478
collect_time: 2.0688071393354663
reward_mean: 1418.25
reward_std: 267.01812744140625
reward_max: 1671.0
reward_min: 1031.0
total_envstep_count: 782037
total_train_sample_count: 781998
total_episode_count: 4428
total_duration: 1556.4705483049675
[2022-12-21 16:05:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1179
train_sample_count: 1179
avg_envstep_per_episode: 235.8
avg_sample_per_episode: 235.8
avg_envstep_per_sec: 497.186762892855
avg_train_sample_per_sec: 497.186762892855
avg_episode_per_sec: 2.1085104448382315
collect_time: 2.3713422962832933
reward_mean: 1358.800048828125
reward_std: 434.78472900390625
reward_max: 1886.0
reward_min: 608.0
total_envstep_count: 783003
total_train_sample_count: 782973
total_episode_count: 4433
total_duration: 1558.8418906012507
[2022-12-21 16:05:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1114
train_sample_count: 1114
avg_envstep_per_episode: 222.8
avg_sample_per_episode: 222.8
avg_envstep_per_sec: 497.6937715216954
avg_train_sample_per_sec: 497.6937715216954
avg_episode_per_sec: 2.2338140553038395
collect_time: 2.2383241739070843
reward_mean: 1308.5999755859375
reward_std: 221.15478515625
reward_max: 1672.0
reward_min: 1038.0
total_envstep_count: 784008
total_train_sample_count: 783979
total_episode_count: 4438
total_duration: 1561.0802147751579
[2022-12-21 16:05:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 794
train_sample_count: 794
avg_envstep_per_episode: 198.5
avg_sample_per_episode: 198.5
avg_envstep_per_sec: 500.07507197749254
avg_train_sample_per_sec: 500.07507197749254
avg_episode_per_sec: 2.5192698840175947
collect_time: 1.5877616071927225
reward_mean: 1128.25
reward_std: 104.14743041992188
reward_max: 1297.0
reward_min: 1039.0
total_envstep_count: 785005
total_train_sample_count: 784965
total_episode_count: 4442
total_duration: 1562.6679763823506
[2022-12-21 16:05:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 225
train_sample_count: 225
avg_envstep_per_episode: 112.5
avg_sample_per_episode: 112.5
avg_envstep_per_sec: 513.6529126181687
avg_train_sample_per_sec: 513.6529126181687
avg_episode_per_sec: 4.565803667717055
collect_time: 0.43803898405469965
reward_mean: 672.0
reward_std: 46.0
reward_max: 718.0
reward_min: 626.0
total_envstep_count: 785987
total_train_sample_count: 785934
total_episode_count: 4444
total_duration: 1563.1060153664052
[2022-12-21 16:05:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1093
train_sample_count: 1093
avg_envstep_per_episode: 273.25
avg_sample_per_episode: 273.25
avg_envstep_per_sec: 515.4612882028259
avg_train_sample_per_sec: 515.4612882028259
avg_episode_per_sec: 1.886409105957277
collect_time: 2.1204308160769614
reward_mean: 1502.5
reward_std: 507.8584899902344
reward_max: 1890.0
reward_min: 634.0
total_envstep_count: 786975
total_train_sample_count: 786943
total_episode_count: 4448
total_duration: 1565.2264461824823
[2022-12-21 16:05:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 663
train_sample_count: 663
avg_envstep_per_episode: 663.0
avg_sample_per_episode: 663.0
avg_envstep_per_sec: 510.87696947130024
avg_train_sample_per_sec: 510.87696947130024
avg_episode_per_sec: 0.7705534984484167
collect_time: 1.297768424922599
reward_mean: 2989.0
reward_std: 0.0
reward_max: 2989.0
reward_min: 2989.0
total_envstep_count: 787950
total_train_sample_count: 787906
total_episode_count: 4449
total_duration: 1566.524214607405
[2022-12-21 16:05:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1816
train_sample_count: 1816
avg_envstep_per_episode: 302.6666666666667
avg_sample_per_episode: 302.6666666666667
avg_envstep_per_sec: 507.6434237021875
avg_train_sample_per_sec: 507.6434237021875
avg_episode_per_sec: 1.6772359813948925
collect_time: 3.5773141445546806
reward_mean: 1697.5
reward_std: 480.38134765625
reward_max: 2331.0
reward_min: 1044.0
total_envstep_count: 788945
total_train_sample_count: 788906
total_episode_count: 4455
total_duration: 1570.1015287519597
[2022-12-21 16:05:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 642
train_sample_count: 642
avg_envstep_per_episode: 321.0
avg_sample_per_episode: 321.0
avg_envstep_per_sec: 492.2992125576191
avg_train_sample_per_sec: 492.2992125576191
avg_episode_per_sec: 1.5336424067215548
collect_time: 1.3040849622014372
reward_mean: 1828.5
reward_std: 503.5
reward_max: 2332.0
reward_min: 1325.0
total_envstep_count: 789951
total_train_sample_count: 789896
total_episode_count: 4457
total_duration: 1571.405613714161
[2022-12-21 16:05:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1191
train_sample_count: 1191
avg_envstep_per_episode: 397.0
avg_sample_per_episode: 397.0
avg_envstep_per_sec: 486.84938962216256
avg_train_sample_per_sec: 486.84938962216256
avg_episode_per_sec: 1.2263208806603592
collect_time: 2.446341775069944
reward_mean: 2098.0
reward_std: 663.66455078125
reward_max: 2994.0
reward_min: 1408.0
total_envstep_count: 790924
total_train_sample_count: 790871
total_episode_count: 4460
total_duration: 1573.851955489231
[2022-12-21 16:05:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 955
train_sample_count: 955
avg_envstep_per_episode: 238.75
avg_sample_per_episode: 238.75
avg_envstep_per_sec: 478.6239466068395
avg_train_sample_per_sec: 478.6239466068395
avg_episode_per_sec: 2.004707629766867
collect_time: 1.9953034251010313
reward_mean: 1421.25
reward_std: 265.0022277832031
reward_max: 1675.0
reward_min: 1038.0
total_envstep_count: 791898
total_train_sample_count: 791862
total_episode_count: 4464
total_duration: 1575.8472589143319
[2022-12-21 16:05:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1334
train_sample_count: 1334
avg_envstep_per_episode: 266.8
avg_sample_per_episode: 266.8
avg_envstep_per_sec: 496.12894467664705
avg_train_sample_per_sec: 496.12894467664705
avg_episode_per_sec: 1.859553765654599
collect_time: 2.68881711964908
reward_mean: 1532.4000244140625
reward_std: 445.6485595703125
reward_max: 2328.0
reward_min: 1036.0
total_envstep_count: 792880
total_train_sample_count: 792848
total_episode_count: 4469
total_duration: 1578.5360760339809
[2022-12-21 16:05:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 529
train_sample_count: 529
avg_envstep_per_episode: 264.5
avg_sample_per_episode: 264.5
avg_envstep_per_sec: 502.49429179470644
avg_train_sample_per_sec: 502.49429179470644
avg_episode_per_sec: 1.899789382966754
collect_time: 1.0527482772204753
reward_mean: 1534.5
reward_std: 127.5
reward_max: 1662.0
reward_min: 1407.0
total_envstep_count: 793855
total_train_sample_count: 793821
total_episode_count: 4471
total_duration: 1579.5888243112013
[2022-12-21 16:06:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1821
train_sample_count: 1821
avg_envstep_per_episode: 260.14285714285717
avg_sample_per_episode: 260.14285714285717
avg_envstep_per_sec: 504.64183001843645
avg_train_sample_per_sec: 504.64183001843645
avg_episode_per_sec: 1.9398642559742203
collect_time: 3.608499913559429
reward_mean: 1370.4285888671875
reward_std: 433.80865478515625
reward_max: 2312.0
reward_min: 810.0
total_envstep_count: 794897
total_train_sample_count: 794862
total_episode_count: 4478
total_duration: 1583.1973242247607
[2022-12-21 16:06:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 403
train_sample_count: 403
avg_envstep_per_episode: 201.5
avg_sample_per_episode: 201.5
avg_envstep_per_sec: 500.7783409765982
avg_train_sample_per_sec: 500.7783409765982
avg_episode_per_sec: 2.485252312538949
collect_time: 0.8047472644565363
reward_mean: 1178.0
reward_std: 132.0
reward_max: 1310.0
reward_min: 1046.0
total_envstep_count: 795888
total_train_sample_count: 795853
total_episode_count: 4480
total_duration: 1584.0020714892173
[2022-12-21 16:06:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1303
train_sample_count: 1303
avg_envstep_per_episode: 217.16666666666666
avg_sample_per_episode: 217.16666666666666
avg_envstep_per_sec: 509.4513846378246
avg_train_sample_per_sec: 509.4513846378246
avg_episode_per_sec: 2.345900466482692
collect_time: 2.5576532703435855
reward_mean: 1156.0
reward_std: 367.10943603515625
reward_max: 1678.0
reward_min: 709.0
total_envstep_count: 796867
total_train_sample_count: 796844
total_episode_count: 4486
total_duration: 1586.5597247595608
[2022-12-21 16:06:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1268
train_sample_count: 1268
avg_envstep_per_episode: 211.33333333333334
avg_sample_per_episode: 211.33333333333334
avg_envstep_per_sec: 495.2867237771724
avg_train_sample_per_sec: 495.2867237771724
avg_episode_per_sec: 2.3436280304913524
collect_time: 2.5601332301619864
reward_mean: 1284.6666259765625
reward_std: 606.3867797851562
reward_max: 2335.0
reward_min: 617.0
total_envstep_count: 797871
total_train_sample_count: 797836
total_episode_count: 4492
total_duration: 1589.1198579897227
[2022-12-21 16:06:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 179.25
avg_sample_per_episode: 179.25
avg_envstep_per_sec: 494.13493927525235
avg_train_sample_per_sec: 494.13493927525235
avg_episode_per_sec: 2.756680274896805
collect_time: 1.4510206484318309
reward_mean: 1071.0
reward_std: 290.0379333496094
reward_max: 1411.0
reward_min: 609.0
total_envstep_count: 798828
total_train_sample_count: 798805
total_episode_count: 4496
total_duration: 1590.5708786381545
[2022-12-21 16:06:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1155
train_sample_count: 1155
avg_envstep_per_episode: 192.5
avg_sample_per_episode: 192.5
avg_envstep_per_sec: 501.05581832163625
avg_train_sample_per_sec: 501.05581832163625
avg_episode_per_sec: 2.6028873679046036
collect_time: 2.3051323979608713
reward_mean: 1137.8333740234375
reward_std: 484.90185546875
reward_max: 1676.0
reward_min: 223.0
total_envstep_count: 799854
total_train_sample_count: 799804
total_episode_count: 4502
total_duration: 1592.8760110361154
[2022-12-21 16:06:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 668
train_sample_count: 668
avg_envstep_per_episode: 222.66666666666666
avg_sample_per_episode: 222.66666666666666
avg_envstep_per_sec: 497.0729802371224
avg_train_sample_per_sec: 497.0729802371224
avg_episode_per_sec: 2.2323636836996514
collect_time: 1.343867050832936
reward_mean: 1107.6666259765625
reward_std: 350.1945495605469
reward_max: 1405.0
reward_min: 616.0
total_envstep_count: 800828
total_train_sample_count: 800796
total_episode_count: 4505
total_duration: 1594.2198780869483
[2022-12-21 16:06:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1274
train_sample_count: 1274
avg_envstep_per_episode: 212.33333333333334
avg_sample_per_episode: 212.33333333333334
avg_envstep_per_sec: 501.6121276426003
avg_train_sample_per_sec: 501.6121276426003
avg_episode_per_sec: 2.362380506951022
collect_time: 2.5398110009567545
reward_mean: 1343.6666259765625
reward_std: 411.9836730957031
reward_max: 1890.0
reward_min: 627.0
total_envstep_count: 801810
total_train_sample_count: 801782
total_episode_count: 4511
total_duration: 1596.759689087905
[2022-12-21 16:06:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 674
train_sample_count: 674
avg_envstep_per_episode: 224.66666666666666
avg_sample_per_episode: 224.66666666666666
avg_envstep_per_sec: 503.73802334441996
avg_train_sample_per_sec: 503.73802334441996
avg_episode_per_sec: 2.2421573739365876
collect_time: 1.3379970714244993
reward_mean: 1394.3333740234375
reward_std: 549.7467651367188
reward_max: 1891.0
reward_min: 628.0
total_envstep_count: 802799
total_train_sample_count: 802756
total_episode_count: 4514
total_duration: 1598.0976861593294
[2022-12-21 16:07:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1247
train_sample_count: 1247
avg_envstep_per_episode: 249.4
avg_sample_per_episode: 249.4
avg_envstep_per_sec: 511.61550961666893
avg_train_sample_per_sec: 511.61550961666893
avg_episode_per_sec: 2.0513853633386887
collect_time: 2.4373772424028397
reward_mean: 1484.800048828125
reward_std: 443.5391540527344
reward_max: 2339.0
reward_min: 1048.0
total_envstep_count: 803795
total_train_sample_count: 803751
total_episode_count: 4519
total_duration: 1600.5350634017323
[2022-12-21 16:07:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 492
train_sample_count: 492
avg_envstep_per_episode: 246.0
avg_sample_per_episode: 246.0
avg_envstep_per_sec: 511.58127216694345
avg_train_sample_per_sec: 511.58127216694345
avg_episode_per_sec: 2.079598667345299
collect_time: 0.9617240246422595
reward_mean: 1494.0
reward_std: 182.0
reward_max: 1676.0
reward_min: 1312.0
total_envstep_count: 804761
total_train_sample_count: 804723
total_episode_count: 4521
total_duration: 1601.4967874263746
[2022-12-21 16:07:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1705
train_sample_count: 1705
avg_envstep_per_episode: 284.1666666666667
avg_sample_per_episode: 284.1666666666667
avg_envstep_per_sec: 509.82770948097726
avg_train_sample_per_sec: 509.82770948097726
avg_episode_per_sec: 1.794115106677926
collect_time: 3.3442670303968973
reward_mean: 1704.6666259765625
reward_std: 407.10797119140625
reward_max: 2328.0
reward_min: 1037.0
total_envstep_count: 805756
total_train_sample_count: 805708
total_episode_count: 4527
total_duration: 1604.8410544567714
[2022-12-21 16:07:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 427
train_sample_count: 427
avg_envstep_per_episode: 213.5
avg_sample_per_episode: 213.5
avg_envstep_per_sec: 500.9008554743784
avg_train_sample_per_sec: 500.9008554743784
avg_episode_per_sec: 2.3461398382874865
collect_time: 0.8524641060866416
reward_mean: 1002.0
reward_std: 393.0
reward_max: 1395.0
reward_min: 609.0
total_envstep_count: 806714
total_train_sample_count: 806675
total_episode_count: 4529
total_duration: 1605.6935185628581
[2022-12-21 16:07:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1349
train_sample_count: 1349
avg_envstep_per_episode: 192.71428571428572
avg_sample_per_episode: 192.71428571428572
avg_envstep_per_sec: 498.0143856425429
avg_train_sample_per_sec: 498.0143856425429
avg_episode_per_sec: 2.5842110448464046
collect_time: 2.708757093953235
reward_mean: 1209.5714111328125
reward_std: 652.8436279296875
reward_max: 1893.0
reward_min: 223.0
total_envstep_count: 807735
total_train_sample_count: 807676
total_episode_count: 4536
total_duration: 1608.4022756568113
[2022-12-21 16:07:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1157
train_sample_count: 1157
avg_envstep_per_episode: 231.4
avg_sample_per_episode: 231.4
avg_envstep_per_sec: 498.35373264217924
avg_train_sample_per_sec: 498.35373264217924
avg_episode_per_sec: 2.153646208479599
collect_time: 2.321644093776122
reward_mean: 1352.199951171875
reward_std: 414.2006530761719
reward_max: 1891.0
reward_min: 750.0
total_envstep_count: 808731
total_train_sample_count: 808701
total_episode_count: 4541
total_duration: 1610.7239197505874
[2022-12-21 16:07:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 495
train_sample_count: 495
avg_envstep_per_episode: 247.5
avg_sample_per_episode: 247.5
avg_envstep_per_sec: 498.76766548592235
avg_train_sample_per_sec: 498.76766548592235
avg_episode_per_sec: 2.0152228908522116
collect_time: 0.9924460510441235
reward_mean: 1480.0
reward_std: 69.0
reward_max: 1549.0
reward_min: 1411.0
total_envstep_count: 809706
total_train_sample_count: 809664
total_episode_count: 4543
total_duration: 1611.7163658016316
[2022-12-21 16:07:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1282
train_sample_count: 1282
avg_envstep_per_episode: 256.4
avg_sample_per_episode: 256.4
avg_envstep_per_sec: 507.58564805419223
avg_train_sample_per_sec: 507.58564805419223
avg_episode_per_sec: 1.9796632139399073
collect_time: 2.5256821285520816
reward_mean: 1565.5999755859375
reward_std: 299.3356628417969
reward_max: 1896.0
reward_min: 1130.0
total_envstep_count: 810662
total_train_sample_count: 810634
total_episode_count: 4548
total_duration: 1614.2420479301836
[2022-12-21 16:07:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 715
train_sample_count: 715
avg_envstep_per_episode: 238.33333333333334
avg_sample_per_episode: 238.33333333333334
avg_envstep_per_sec: 384.42978690718985
avg_train_sample_per_sec: 384.42978690718985
avg_episode_per_sec: 1.6129921128973
collect_time: 1.85989750105555
reward_mean: 1373.3333740234375
reward_std: 241.3715362548828
reward_max: 1547.0
reward_min: 1032.0
total_envstep_count: 811651
total_train_sample_count: 811613
total_episode_count: 4551
total_duration: 1616.101945431239
[2022-12-21 16:07:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 833
train_sample_count: 833
avg_envstep_per_episode: 208.25
avg_sample_per_episode: 208.25
avg_envstep_per_sec: 498.5772220066133
avg_train_sample_per_sec: 498.5772220066133
avg_episode_per_sec: 2.3941283169585272
collect_time: 1.6707542246864837
reward_mean: 1123.75
reward_std: 319.2830810546875
reward_max: 1410.0
reward_min: 633.0
total_envstep_count: 812608
total_train_sample_count: 812590
total_episode_count: 4555
total_duration: 1617.7726996559256
[2022-12-21 16:07:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1759
train_sample_count: 1759
avg_envstep_per_episode: 251.28571428571428
avg_sample_per_episode: 251.28571428571428
avg_envstep_per_sec: 514.1835400514053
avg_train_sample_per_sec: 514.1835400514053
avg_episode_per_sec: 2.046210790426286
collect_time: 3.4209574266499168
reward_mean: 1493.142822265625
reward_std: 268.1707458496094
reward_max: 1892.0
reward_min: 1132.0
total_envstep_count: 813617
total_train_sample_count: 813569
total_episode_count: 4562
total_duration: 1621.1936570825756
[2022-12-21 16:07:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 307
train_sample_count: 307
avg_envstep_per_episode: 307.0
avg_sample_per_episode: 307.0
avg_envstep_per_sec: 513.7034192300287
avg_train_sample_per_sec: 513.7034192300287
avg_episode_per_sec: 1.673301039837227
collect_time: 0.5976210951839703
reward_mean: 1892.0
reward_std: 0.0
reward_max: 1892.0
reward_min: 1892.0
total_envstep_count: 814576
total_train_sample_count: 814536
total_episode_count: 4563
total_duration: 1621.7912781777595
[2022-12-21 16:07:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 564
train_sample_count: 564
avg_envstep_per_episode: 282.0
avg_sample_per_episode: 282.0
avg_envstep_per_sec: 493.12871072657987
avg_train_sample_per_sec: 493.12871072657987
avg_episode_per_sec: 1.7486833713708507
collect_time: 1.1437176293568423
reward_mean: 1647.0
reward_std: 241.0
reward_max: 1888.0
reward_min: 1406.0
total_envstep_count: 815536
total_train_sample_count: 815508
total_episode_count: 4565
total_duration: 1622.9349958071164
[2022-12-21 16:07:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 927
train_sample_count: 927
avg_envstep_per_episode: 309.0
avg_sample_per_episode: 309.0
avg_envstep_per_sec: 492.0217791292157
avg_train_sample_per_sec: 492.0217791292157
avg_episode_per_sec: 1.5923034923275587
collect_time: 1.8840629405483076
reward_mean: 1818.3333740234375
reward_std: 104.20919036865234
reward_max: 1895.0
reward_min: 1671.0
total_envstep_count: 816519
total_train_sample_count: 816495
total_episode_count: 4568
total_duration: 1624.8190587476647
[2022-12-21 16:07:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 869
train_sample_count: 869
avg_envstep_per_episode: 217.25
avg_sample_per_episode: 217.25
avg_envstep_per_sec: 498.0704005770007
avg_train_sample_per_sec: 498.0704005770007
avg_episode_per_sec: 2.2926140417813614
collect_time: 1.744733272632318
reward_mean: 1147.25
reward_std: 394.8096923828125
reward_max: 1659.0
reward_min: 578.0
total_envstep_count: 817539
total_train_sample_count: 817484
total_episode_count: 4572
total_duration: 1626.5637920202971
[2022-12-21 16:07:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1610
train_sample_count: 1610
avg_envstep_per_episode: 402.5
avg_sample_per_episode: 402.5
avg_envstep_per_sec: 493.8972843432355
avg_train_sample_per_sec: 493.8972843432355
avg_episode_per_sec: 1.227073998368287
collect_time: 3.2597871076390152
reward_mean: 2160.0
reward_std: 938.366943359375
reward_max: 3011.0
reward_min: 737.0
total_envstep_count: 818520
total_train_sample_count: 818482
total_episode_count: 4576
total_duration: 1629.8235791279362
[2022-12-21 16:07:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1102
train_sample_count: 1102
avg_envstep_per_episode: 275.5
avg_sample_per_episode: 275.5
avg_envstep_per_sec: 498.40421710654175
avg_train_sample_per_sec: 498.40421710654175
avg_episode_per_sec: 1.8090897172651244
collect_time: 2.2110567330220445
reward_mean: 1614.25
reward_std: 473.4988708496094
reward_max: 2340.0
reward_min: 1045.0
total_envstep_count: 819508
total_train_sample_count: 819476
total_episode_count: 4580
total_duration: 1632.0346358609584
[2022-12-21 16:07:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1174
train_sample_count: 1174
avg_envstep_per_episode: 234.8
avg_sample_per_episode: 234.8
avg_envstep_per_sec: 503.43316448133334
avg_train_sample_per_sec: 503.43316448133334
avg_episode_per_sec: 2.1440935454911982
collect_time: 2.331987804596712
reward_mean: 1353.4000244140625
reward_std: 561.1611328125
reward_max: 1893.0
reward_min: 633.0
total_envstep_count: 820519
total_train_sample_count: 820470
total_episode_count: 4585
total_duration: 1634.3666236655552
[2022-12-21 16:08:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 731
train_sample_count: 731
avg_envstep_per_episode: 243.66666666666666
avg_sample_per_episode: 243.66666666666666
avg_envstep_per_sec: 498.9202659987653
avg_train_sample_per_sec: 498.9202659987653
avg_episode_per_sec: 2.047552391239803
collect_time: 1.4651639747217826
reward_mean: 1520.0
reward_std: 235.31398010253906
reward_max: 1847.0
reward_min: 1303.0
total_envstep_count: 821476
total_train_sample_count: 821441
total_episode_count: 4588
total_duration: 1635.8317876402768
[2022-12-21 16:08:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 769
train_sample_count: 769
avg_envstep_per_episode: 256.3333333333333
avg_sample_per_episode: 256.3333333333333
avg_envstep_per_sec: 501.33617563447643
avg_train_sample_per_sec: 501.33617563447643
avg_episode_per_sec: 1.9557978243217546
collect_time: 1.5339008780421162
reward_mean: 1447.0
reward_std: 479.8861083984375
reward_max: 1893.0
reward_min: 781.0
total_envstep_count: 822457
total_train_sample_count: 822414
total_episode_count: 4591
total_duration: 1637.3656885183188
[2022-12-21 16:08:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1141
train_sample_count: 1141
avg_envstep_per_episode: 285.25
avg_sample_per_episode: 285.25
avg_envstep_per_sec: 495.1432016953038
avg_train_sample_per_sec: 495.1432016953038
avg_episode_per_sec: 1.7358219165479536
collect_time: 2.304383855202635
reward_mean: 1661.5
reward_std: 367.8209533691406
reward_max: 1895.0
reward_min: 1026.0
total_envstep_count: 823462
total_train_sample_count: 823435
total_episode_count: 4595
total_duration: 1639.6700723735214
[2022-12-21 16:08:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1277
train_sample_count: 1277
avg_envstep_per_episode: 255.4
avg_sample_per_episode: 255.4
avg_envstep_per_sec: 501.5917612491151
avg_train_sample_per_sec: 501.5917612491151
avg_episode_per_sec: 1.9639458153841625
collect_time: 2.545895085716488
reward_mean: 1513.0
reward_std: 442.4915771484375
reward_max: 1894.0
reward_min: 704.0
total_envstep_count: 824466
total_train_sample_count: 824436
total_episode_count: 4600
total_duration: 1642.2159674592378
[2022-12-21 16:08:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 816
train_sample_count: 816
avg_envstep_per_episode: 272.0
avg_sample_per_episode: 272.0
avg_envstep_per_sec: 504.21046486751675
avg_train_sample_per_sec: 504.21046486751675
avg_episode_per_sec: 1.8537149443658703
collect_time: 1.6183718047470657
reward_mean: 1533.0
reward_std: 259.7421875
reward_max: 1895.0
reward_min: 1298.0
total_envstep_count: 825464
total_train_sample_count: 825432
total_episode_count: 4603
total_duration: 1643.834339263985
[2022-12-21 16:08:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 981
train_sample_count: 981
avg_envstep_per_episode: 196.2
avg_sample_per_episode: 196.2
avg_envstep_per_sec: 503.2427385453636
avg_train_sample_per_sec: 503.2427385453636
avg_episode_per_sec: 2.5649476990079694
collect_time: 1.949357486678509
reward_mean: 1162.800048828125
reward_std: 294.6817932128906
reward_max: 1409.0
reward_min: 636.0
total_envstep_count: 826444
total_train_sample_count: 826413
total_episode_count: 4608
total_duration: 1645.7836967506635
[2022-12-21 16:08:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 544
train_sample_count: 544
avg_envstep_per_episode: 181.33333333333334
avg_sample_per_episode: 181.33333333333334
avg_envstep_per_sec: 482.2451137489378
avg_train_sample_per_sec: 482.2451137489378
avg_episode_per_sec: 2.6594399655272305
collect_time: 1.1280570491860131
reward_mean: 1112.0
reward_std: 429.9031066894531
reward_max: 1672.0
reward_min: 627.0
total_envstep_count: 827426
total_train_sample_count: 827389
total_episode_count: 4611
total_duration: 1646.9117537998495
[2022-12-21 16:08:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1227
train_sample_count: 1227
avg_envstep_per_episode: 306.75
avg_sample_per_episode: 306.75
avg_envstep_per_sec: 497.15774771691315
avg_train_sample_per_sec: 497.15774771691315
avg_episode_per_sec: 1.6207261539263673
collect_time: 2.4680295251049102
reward_mean: 1538.0
reward_std: 620.9436645507812
reward_max: 2313.0
reward_min: 625.0
total_envstep_count: 828416
total_train_sample_count: 828388
total_episode_count: 4615
total_duration: 1649.3797833249544
[2022-12-21 16:08:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1223
train_sample_count: 1223
avg_envstep_per_episode: 244.6
avg_sample_per_episode: 244.6
avg_envstep_per_sec: 497.8299046642198
avg_train_sample_per_sec: 497.8299046642198
avg_episode_per_sec: 2.03528170345143
collect_time: 2.4566623831585583
reward_mean: 1555.4000244140625
reward_std: 414.7011413574219
reward_max: 1895.0
reward_min: 1046.0
total_envstep_count: 829412
total_train_sample_count: 829371
total_episode_count: 4620
total_duration: 1651.836445708113
[2022-12-21 16:08:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 689
train_sample_count: 689
avg_envstep_per_episode: 172.25
avg_sample_per_episode: 172.25
avg_envstep_per_sec: 502.6084465480277
avg_train_sample_per_sec: 502.6084465480277
avg_episode_per_sec: 2.9179009959246893
collect_time: 1.3708484302882906
reward_mean: 946.25
reward_std: 569.5631713867188
reward_max: 1674.0
reward_min: 231.0
total_envstep_count: 830385
total_train_sample_count: 830360
total_episode_count: 4624
total_duration: 1653.2072941384013
[2022-12-21 16:08:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1529
train_sample_count: 1529
avg_envstep_per_episode: 218.42857142857142
avg_sample_per_episode: 218.42857142857142
avg_envstep_per_sec: 501.12225135731006
avg_train_sample_per_sec: 501.12225135731006
avg_episode_per_sec: 2.294215670046547
collect_time: 3.051151681767555
reward_mean: 1271.142822265625
reward_std: 653.2302856445312
reward_max: 2325.0
reward_min: 231.0
total_envstep_count: 831435
total_train_sample_count: 831397
total_episode_count: 4631
total_duration: 1656.2584458201688
[2022-12-21 16:08:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 801
train_sample_count: 801
avg_envstep_per_episode: 200.25
avg_sample_per_episode: 200.25
avg_envstep_per_sec: 492.92031423548457
avg_train_sample_per_sec: 492.92031423548457
avg_episode_per_sec: 2.4615246653457405
collect_time: 1.6250091076938968
reward_mean: 1232.25
reward_std: 379.3865966796875
reward_max: 1673.0
reward_min: 626.0
total_envstep_count: 832407
total_train_sample_count: 832366
total_episode_count: 4635
total_duration: 1657.8834549278627
[2022-12-21 16:08:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 761
train_sample_count: 761
avg_envstep_per_episode: 253.66666666666666
avg_sample_per_episode: 253.66666666666666
avg_envstep_per_sec: 491.13516159110367
avg_train_sample_per_sec: 491.13516159110367
avg_episode_per_sec: 1.9361438696101327
collect_time: 1.5494716312605883
reward_mean: 1571.0
reward_std: 228.39585876464844
reward_max: 1894.0
reward_min: 1409.0
total_envstep_count: 833375
total_train_sample_count: 833343
total_episode_count: 4638
total_duration: 1659.4329265591232
[2022-12-21 16:08:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 970
train_sample_count: 970
avg_envstep_per_episode: 242.5
avg_sample_per_episode: 242.5
avg_envstep_per_sec: 505.09518299760447
avg_train_sample_per_sec: 505.09518299760447
avg_episode_per_sec: 2.0828667340107403
collect_time: 1.9204301142673943
reward_mean: 1514.0
reward_std: 181.87083435058594
reward_max: 1829.0
reward_min: 1407.0
total_envstep_count: 834373
total_train_sample_count: 834325
total_episode_count: 4642
total_duration: 1661.3533566733906
[2022-12-21 16:08:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1674
train_sample_count: 1674
avg_envstep_per_episode: 239.14285714285714
avg_sample_per_episode: 239.14285714285714
avg_envstep_per_sec: 502.699653035151
avg_train_sample_per_sec: 502.699653035151
avg_episode_per_sec: 2.1020893496093533
collect_time: 3.330020201710675
reward_mean: 1375.2857666015625
reward_std: 819.9121704101562
reward_max: 3013.0
reward_min: 231.0
total_envstep_count: 835423
total_train_sample_count: 835387
total_episode_count: 4649
total_duration: 1664.6833768751012
[2022-12-21 16:08:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 640
train_sample_count: 640
avg_envstep_per_episode: 213.33333333333334
avg_sample_per_episode: 213.33333333333334
avg_envstep_per_sec: 504.6391871587085
avg_train_sample_per_sec: 504.6391871587085
avg_episode_per_sec: 2.3654961898064464
collect_time: 1.268232860795887
reward_mean: 1250.3333740234375
reward_std: 155.91949462890625
reward_max: 1408.0
reward_min: 1038.0
total_envstep_count: 836420
total_train_sample_count: 836375
total_episode_count: 4652
total_duration: 1665.9516097358971
[2022-12-21 16:08:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 499
train_sample_count: 499
avg_envstep_per_episode: 166.33333333333334
avg_sample_per_episode: 166.33333333333334
avg_envstep_per_sec: 508.5013432655298
avg_train_sample_per_sec: 508.5013432655298
avg_episode_per_sec: 3.057122304201582
collect_time: 0.9813150085218785
reward_mean: 892.0
reward_std: 292.2818298339844
reward_max: 1299.0
reward_min: 626.0
total_envstep_count: 837385
total_train_sample_count: 837354
total_episode_count: 4655
total_duration: 1666.932924744419
[2022-12-21 16:08:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1729
train_sample_count: 1729
avg_envstep_per_episode: 247.0
avg_sample_per_episode: 247.0
avg_envstep_per_sec: 518.0124340735367
avg_train_sample_per_sec: 518.0124340735367
avg_episode_per_sec: 2.0972163322815254
collect_time: 3.337757718291666
reward_mean: 1331.4285888671875
reward_std: 548.3632202148438
reward_max: 2337.0
reward_min: 760.0
total_envstep_count: 838387
total_train_sample_count: 838351
total_episode_count: 4662
total_duration: 1670.2706824627107
[2022-12-21 16:09:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 522
train_sample_count: 522
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 507.50643344368893
avg_train_sample_per_sec: 507.50643344368893
avg_episode_per_sec: 1.9444690936539806
collect_time: 1.028558389807918
reward_mean: 1479.5
reward_std: 853.5
reward_max: 2333.0
reward_min: 626.0
total_envstep_count: 839369
total_train_sample_count: 839329
total_episode_count: 4664
total_duration: 1671.2992408525186
[2022-12-21 16:09:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 461
train_sample_count: 461
avg_envstep_per_episode: 230.5
avg_sample_per_episode: 230.5
avg_envstep_per_sec: 507.5436535813002
avg_train_sample_per_sec: 507.5436535813002
avg_episode_per_sec: 2.2019247443874197
collect_time: 0.9082962554001384
reward_mean: 1354.5
reward_std: 49.5
reward_max: 1404.0
reward_min: 1305.0
total_envstep_count: 840343
total_train_sample_count: 840306
total_episode_count: 4666
total_duration: 1672.2075371079186
[2022-12-21 16:09:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2002
train_sample_count: 2002
avg_envstep_per_episode: 286.0
avg_sample_per_episode: 286.0
avg_envstep_per_sec: 495.2554260431668
avg_train_sample_per_sec: 495.2554260431668
avg_episode_per_sec: 1.7316623288222615
collect_time: 4.042358538087989
reward_mean: 1726.7142333984375
reward_std: 291.7663879394531
reward_max: 1891.0
reward_min: 1038.0
total_envstep_count: 841362
total_train_sample_count: 841324
total_episode_count: 4673
total_duration: 1676.2498956460065
[2022-12-21 16:09:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 120
train_sample_count: 120
avg_envstep_per_episode: 120.0
avg_sample_per_episode: 120.0
avg_envstep_per_sec: 480.06349241525226
avg_train_sample_per_sec: 480.06349241525226
avg_episode_per_sec: 4.000529103460435
collect_time: 0.2499669354073704
reward_mean: 585.0
reward_std: 0.0
reward_max: 585.0
reward_min: 585.0
total_envstep_count: 842321
total_train_sample_count: 842284
total_episode_count: 4674
total_duration: 1676.499862581414
[2022-12-21 16:09:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2077
train_sample_count: 2077
avg_envstep_per_episode: 230.77777777777777
avg_sample_per_episode: 230.77777777777777
avg_envstep_per_sec: 492.02415703796515
avg_train_sample_per_sec: 492.02415703796515
avg_episode_per_sec: 2.13202571658242
collect_time: 4.221337449168652
reward_mean: 1359.5555419921875
reward_std: 506.6986999511719
reward_max: 1893.0
reward_min: 223.0
total_envstep_count: 843332
total_train_sample_count: 843305
total_episode_count: 4683
total_duration: 1680.7212000305826
[2022-12-21 16:09:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 542
train_sample_count: 542
avg_envstep_per_episode: 135.5
avg_sample_per_episode: 135.5
avg_envstep_per_sec: 511.4738794777226
avg_train_sample_per_sec: 511.4738794777226
avg_episode_per_sec: 3.77471497769537
collect_time: 1.0596826577995504
reward_mean: 828.5
reward_std: 445.3731689453125
reward_max: 1413.0
reward_min: 226.0
total_envstep_count: 844314
total_train_sample_count: 844279
total_episode_count: 4687
total_duration: 1681.7808826883822
[2022-12-21 16:09:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 487
train_sample_count: 487
avg_envstep_per_episode: 243.5
avg_sample_per_episode: 243.5
avg_envstep_per_sec: 497.21765368673323
avg_train_sample_per_sec: 497.21765368673323
avg_episode_per_sec: 2.041961616783299
collect_time: 0.9794503400855297
reward_mean: 1307.0
reward_std: 2.0
reward_max: 1309.0
reward_min: 1305.0
total_envstep_count: 845272
total_train_sample_count: 845246
total_episode_count: 4689
total_duration: 1682.7603330284678
[2022-12-21 16:09:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 365
train_sample_count: 365
avg_envstep_per_episode: 121.66666666666667
avg_sample_per_episode: 121.66666666666667
avg_envstep_per_sec: 499.1600993016151
avg_train_sample_per_sec: 499.1600993016151
avg_episode_per_sec: 4.102685747684508
collect_time: 0.7312283183505228
reward_mean: 754.0
reward_std: 486.6915588378906
reward_max: 1403.0
reward_min: 231.0
total_envstep_count: 846262
total_train_sample_count: 846223
total_episode_count: 4692
total_duration: 1683.4915613468183
[2022-12-21 16:09:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1571
train_sample_count: 1571
avg_envstep_per_episode: 392.75
avg_sample_per_episode: 392.75
avg_envstep_per_sec: 497.7584084340908
avg_train_sample_per_sec: 497.7584084340908
avg_episode_per_sec: 1.2673670488455528
collect_time: 3.156149596633121
reward_mean: 2106.25
reward_std: 212.5327911376953
reward_max: 2334.0
reward_min: 1894.0
total_envstep_count: 847258
total_train_sample_count: 847218
total_episode_count: 4696
total_duration: 1686.6477109434516
[2022-12-21 16:09:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1506
train_sample_count: 1506
avg_envstep_per_episode: 301.2
avg_sample_per_episode: 301.2
avg_envstep_per_sec: 498.7101851773999
avg_train_sample_per_sec: 498.7101851773999
avg_episode_per_sec: 1.655744306697875
collect_time: 3.0197899396506
reward_mean: 1868.800048828125
reward_std: 322.22003173828125
reward_max: 2337.0
reward_min: 1323.0
total_envstep_count: 848271
total_train_sample_count: 848232
total_episode_count: 4701
total_duration: 1689.667500883102
[2022-12-21 16:09:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 898
train_sample_count: 898
avg_envstep_per_episode: 179.6
avg_sample_per_episode: 179.6
avg_envstep_per_sec: 494.0792589944071
avg_train_sample_per_sec: 494.0792589944071
avg_episode_per_sec: 2.750998101305162
collect_time: 1.8175221559141894
reward_mean: 1113.0
reward_std: 418.3739929199219
reward_max: 1679.0
reward_min: 627.0
total_envstep_count: 849251
total_train_sample_count: 849226
total_episode_count: 4706
total_duration: 1691.4850230390164
[2022-12-21 16:09:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 775
train_sample_count: 775
avg_envstep_per_episode: 193.75
avg_sample_per_episode: 193.75
avg_envstep_per_sec: 501.75618881618504
avg_train_sample_per_sec: 501.75618881618504
avg_episode_per_sec: 2.5897093616319227
collect_time: 1.5445748697758783
reward_mean: 1001.75
reward_std: 313.70318603515625
reward_max: 1309.0
reward_min: 585.0
total_envstep_count: 850240
total_train_sample_count: 850205
total_episode_count: 4710
total_duration: 1693.0295979087923
[2022-12-21 16:09:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1110
train_sample_count: 1110
avg_envstep_per_episode: 370.0
avg_sample_per_episode: 370.0
avg_envstep_per_sec: 505.1451930013388
avg_train_sample_per_sec: 505.1451930013388
avg_episode_per_sec: 1.3652572783819967
collect_time: 2.197388028984091
reward_mean: 2069.0
reward_std: 702.4319458007812
reward_max: 3003.0
reward_min: 1309.0
total_envstep_count: 851215
total_train_sample_count: 851183
total_episode_count: 4713
total_duration: 1695.2269859377764
[2022-12-21 16:09:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1134
train_sample_count: 1134
avg_envstep_per_episode: 226.8
avg_sample_per_episode: 226.8
avg_envstep_per_sec: 504.57067430199015
avg_train_sample_per_sec: 504.57067430199015
avg_episode_per_sec: 2.224738422848281
collect_time: 2.247455228286396
reward_mean: 1426.0
reward_std: 466.4388427734375
reward_max: 1892.0
reward_min: 626.0
total_envstep_count: 852251
total_train_sample_count: 852221
total_episode_count: 4718
total_duration: 1697.4744411660627
[2022-12-21 16:09:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1009
train_sample_count: 1009
avg_envstep_per_episode: 252.25
avg_sample_per_episode: 252.25
avg_envstep_per_sec: 498.1437119145459
avg_train_sample_per_sec: 498.1437119145459
avg_episode_per_sec: 1.9748016329615299
collect_time: 2.025519896902942
reward_mean: 1534.5
reward_std: 370.2745666503906
reward_max: 1894.0
reward_min: 1045.0
total_envstep_count: 853265
total_train_sample_count: 853242
total_episode_count: 4722
total_duration: 1699.4999610629657
[2022-12-21 16:09:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 788
train_sample_count: 788
avg_envstep_per_episode: 262.6666666666667
avg_sample_per_episode: 262.6666666666667
avg_envstep_per_sec: 494.35126629179143
avg_train_sample_per_sec: 494.35126629179143
avg_episode_per_sec: 1.8820479681159572
collect_time: 1.5940082563374725
reward_mean: 1404.0
reward_std: 468.1331787109375
reward_max: 1893.0
reward_min: 773.0
total_envstep_count: 854255
total_train_sample_count: 854222
total_episode_count: 4725
total_duration: 1701.0939693193031
[2022-12-21 16:09:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1379
train_sample_count: 1379
avg_envstep_per_episode: 275.8
avg_sample_per_episode: 275.8
avg_envstep_per_sec: 491.01513839468964
avg_train_sample_per_sec: 491.01513839468964
avg_episode_per_sec: 1.7803304510322322
collect_time: 2.8084673814914582
reward_mean: 1755.5999755859375
reward_std: 537.8009033203125
reward_max: 2608.0
reward_min: 1049.0
total_envstep_count: 855235
total_train_sample_count: 855205
total_episode_count: 4730
total_duration: 1703.9024367007946
[2022-12-21 16:09:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1267
train_sample_count: 1267
avg_envstep_per_episode: 181.0
avg_sample_per_episode: 181.0
avg_envstep_per_sec: 492.6318369811922
avg_train_sample_per_sec: 492.6318369811922
avg_episode_per_sec: 2.7217228562496802
collect_time: 2.5719003622747425
reward_mean: 1098.7142333984375
reward_std: 565.1512451171875
reward_max: 1895.0
reward_min: 626.0
total_envstep_count: 856231
total_train_sample_count: 856184
total_episode_count: 4737
total_duration: 1706.4743370630695
[2022-12-21 16:10:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 216
train_sample_count: 216
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 493.70433680872736
avg_train_sample_per_sec: 493.70433680872736
avg_episode_per_sec: 2.2856682259663303
collect_time: 0.43750881630129057
reward_mean: 1404.0
reward_std: 0.0
reward_max: 1404.0
reward_min: 1404.0
total_envstep_count: 857190
total_train_sample_count: 857144
total_episode_count: 4738
total_duration: 1706.9118458793707
[2022-12-21 16:10:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1195
train_sample_count: 1195
avg_envstep_per_episode: 239.0
avg_sample_per_episode: 239.0
avg_envstep_per_sec: 495.28899627928195
avg_train_sample_per_sec: 495.28899627928195
avg_episode_per_sec: 2.072338896566033
collect_time: 2.4127327862663988
reward_mean: 1510.4000244140625
reward_std: 335.3252868652344
reward_max: 1895.0
reward_min: 1043.0
total_envstep_count: 858185
total_train_sample_count: 858147
total_episode_count: 4743
total_duration: 1709.324578665637
[2022-12-21 16:10:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1075
train_sample_count: 1075
avg_envstep_per_episode: 268.75
avg_sample_per_episode: 268.75
avg_envstep_per_sec: 501.36689707327946
avg_train_sample_per_sec: 501.36689707327946
avg_episode_per_sec: 1.8655512449238305
collect_time: 2.144138367082657
reward_mean: 1688.25
reward_std: 638.2935180664062
reward_max: 2337.0
reward_min: 628.0
total_envstep_count: 859150
total_train_sample_count: 859126
total_episode_count: 4747
total_duration: 1711.4687170327197
[2022-12-21 16:10:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 682
train_sample_count: 682
avg_envstep_per_episode: 227.33333333333334
avg_sample_per_episode: 227.33333333333334
avg_envstep_per_sec: 502.99220494580703
avg_train_sample_per_sec: 502.99220494580703
avg_episode_per_sec: 2.2125756815797963
collect_time: 1.35588582346615
reward_mean: 1444.3333740234375
reward_std: 163.81764221191406
reward_max: 1676.0
reward_min: 1327.0
total_envstep_count: 860108
total_train_sample_count: 860096
total_episode_count: 4750
total_duration: 1712.824602856186
[2022-12-21 16:10:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 719
train_sample_count: 719
avg_envstep_per_episode: 359.5
avg_sample_per_episode: 359.5
avg_envstep_per_sec: 494.6848308100418
avg_train_sample_per_sec: 494.6848308100418
avg_episode_per_sec: 1.3760356907094347
collect_time: 1.4534506724668397
reward_mean: 1873.5
reward_std: 455.5
reward_max: 2329.0
reward_min: 1418.0
total_envstep_count: 861122
total_train_sample_count: 861067
total_episode_count: 4752
total_duration: 1714.278053528653
[2022-12-21 16:10:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1528
train_sample_count: 1528
avg_envstep_per_episode: 305.6
avg_sample_per_episode: 305.6
avg_envstep_per_sec: 501.58936248908367
avg_train_sample_per_sec: 501.58936248908367
avg_episode_per_sec: 1.6413264479354832
collect_time: 3.0463165973406277
reward_mean: 1697.800048828125
reward_std: 649.846923828125
reward_max: 2336.0
reward_min: 626.0
total_envstep_count: 862111
total_train_sample_count: 862079
total_episode_count: 4757
total_duration: 1717.3243701259935
[2022-12-21 16:10:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 645
train_sample_count: 645
avg_envstep_per_episode: 129.0
avg_sample_per_episode: 129.0
avg_envstep_per_sec: 508.47284173118214
avg_train_sample_per_sec: 508.47284173118214
avg_episode_per_sec: 3.941649935900637
collect_time: 1.268504327200619
reward_mean: 743.2000122070312
reward_std: 610.0116577148438
reward_max: 1891.0
reward_min: 226.0
total_envstep_count: 863106
total_train_sample_count: 863072
total_episode_count: 4762
total_duration: 1718.592874453194
[2022-12-21 16:10:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1905
train_sample_count: 1905
avg_envstep_per_episode: 272.14285714285717
avg_sample_per_episode: 272.14285714285717
avg_envstep_per_sec: 508.62232311697846
avg_train_sample_per_sec: 508.62232311697846
avg_episode_per_sec: 1.868953418277611
collect_time: 3.7454117002290275
reward_mean: 1582.4285888671875
reward_std: 541.4187622070312
reward_max: 2317.0
reward_min: 628.0
total_envstep_count: 864131
total_train_sample_count: 864089
total_episode_count: 4769
total_duration: 1722.338286153423
[2022-12-21 16:10:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 297
train_sample_count: 297
avg_envstep_per_episode: 297.0
avg_sample_per_episode: 297.0
avg_envstep_per_sec: 491.1978305656103
avg_train_sample_per_sec: 491.1978305656103
avg_episode_per_sec: 1.6538647493791592
collect_time: 0.6046443642839524
reward_mean: 1892.0
reward_std: 0.0
reward_max: 1892.0
reward_min: 1892.0
total_envstep_count: 865187
total_train_sample_count: 865154
total_episode_count: 4770
total_duration: 1722.942930517707
[2022-12-21 16:10:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 993
train_sample_count: 993
avg_envstep_per_episode: 248.25
avg_sample_per_episode: 248.25
avg_envstep_per_sec: 483.80902535668235
avg_train_sample_per_sec: 483.80902535668235
avg_episode_per_sec: 1.948878249170926
collect_time: 2.052462744505278
reward_mean: 1572.5
reward_std: 229.23187255859375
reward_max: 1897.0
reward_min: 1310.0
total_envstep_count: 866225
total_train_sample_count: 866183
total_episode_count: 4774
total_duration: 1724.9953932622122
[2022-12-21 16:10:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 499
train_sample_count: 499
avg_envstep_per_episode: 249.5
avg_sample_per_episode: 249.5
avg_envstep_per_sec: 490.5308325919822
avg_train_sample_per_sec: 490.5308325919822
avg_episode_per_sec: 1.9660554412504296
collect_time: 1.0172653110575465
reward_mean: 1462.0
reward_std: 430.0
reward_max: 1892.0
reward_min: 1032.0
total_envstep_count: 867199
total_train_sample_count: 867162
total_episode_count: 4776
total_duration: 1726.0126585732698
[2022-12-21 16:10:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1197
train_sample_count: 1197
avg_envstep_per_episode: 299.25
avg_sample_per_episode: 299.25
avg_envstep_per_sec: 493.32317311545694
avg_train_sample_per_sec: 493.32317311545694
avg_episode_per_sec: 1.6485319068185695
collect_time: 2.426401323174525
reward_mean: 1883.5
reward_std: 328.29901123046875
reward_max: 2336.0
reward_min: 1408.0
total_envstep_count: 868211
total_train_sample_count: 868167
total_episode_count: 4780
total_duration: 1728.4390598964444
[2022-12-21 16:10:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1260
train_sample_count: 1260
avg_envstep_per_episode: 252.0
avg_sample_per_episode: 252.0
avg_envstep_per_sec: 503.225348683356
avg_train_sample_per_sec: 503.225348683356
avg_episode_per_sec: 1.9969259868387144
collect_time: 2.5038484315161726
reward_mean: 1582.5999755859375
reward_std: 320.0428771972656
reward_max: 1892.0
reward_min: 1049.0
total_envstep_count: 869183
total_train_sample_count: 869151
total_episode_count: 4785
total_duration: 1730.9429083279606
[2022-12-21 16:10:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1287
train_sample_count: 1287
avg_envstep_per_episode: 429.0
avg_sample_per_episode: 429.0
avg_envstep_per_sec: 498.6341906975904
avg_train_sample_per_sec: 498.6341906975904
avg_episode_per_sec: 1.162317460833544
collect_time: 2.581050445416677
reward_mean: 2057.333251953125
reward_std: 695.2286376953125
reward_max: 2979.0
reward_min: 1300.0
total_envstep_count: 870165
total_train_sample_count: 870126
total_episode_count: 4788
total_duration: 1733.5239587733772
[2022-12-21 16:10:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1095
train_sample_count: 1095
avg_envstep_per_episode: 182.5
avg_sample_per_episode: 182.5
avg_envstep_per_sec: 507.4605998327428
avg_train_sample_per_sec: 507.4605998327428
avg_episode_per_sec: 2.780606026480782
collect_time: 2.1578029907364398
reward_mean: 1072.5
reward_std: 530.7584838867188
reward_max: 1891.0
reward_min: 231.0
total_envstep_count: 871136
total_train_sample_count: 871101
total_episode_count: 4794
total_duration: 1735.6817617641136
[2022-12-21 16:10:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 631
train_sample_count: 631
avg_envstep_per_episode: 210.33333333333334
avg_sample_per_episode: 210.33333333333334
avg_envstep_per_sec: 507.23832964696135
avg_train_sample_per_sec: 507.23832964696135
avg_episode_per_sec: 2.4115926924578193
collect_time: 1.2439911637576304
reward_mean: 1333.3333740234375
reward_std: 214.57606506347656
reward_max: 1550.0
reward_min: 1041.0
total_envstep_count: 872093
total_train_sample_count: 872068
total_episode_count: 4797
total_duration: 1736.9257529278711
[2022-12-21 16:10:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 910
train_sample_count: 910
avg_envstep_per_episode: 303.3333333333333
avg_sample_per_episode: 303.3333333333333
avg_envstep_per_sec: 502.29754740906407
avg_train_sample_per_sec: 502.29754740906407
avg_episode_per_sec: 1.655925980469442
collect_time: 1.8116751807647367
reward_mean: 1650.6666259765625
reward_std: 196.77793884277344
reward_max: 1891.0
reward_min: 1409.0
total_envstep_count: 873107
total_train_sample_count: 873074
total_episode_count: 4800
total_duration: 1738.7374281086359
[2022-12-21 16:11:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1285
train_sample_count: 1285
avg_envstep_per_episode: 321.25
avg_sample_per_episode: 321.25
avg_envstep_per_sec: 499.8838045965059
avg_train_sample_per_sec: 499.8838045965059
avg_episode_per_sec: 1.5560585357089678
collect_time: 2.5705973832003237
reward_mean: 1796.75
reward_std: 372.47039794921875
reward_max: 2331.0
reward_min: 1300.0
total_envstep_count: 874095
total_train_sample_count: 874059
total_episode_count: 4804
total_duration: 1741.3080254918361
[2022-12-21 16:11:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 537
train_sample_count: 537
avg_envstep_per_episode: 268.5
avg_sample_per_episode: 268.5
avg_envstep_per_sec: 495.71497204964584
avg_train_sample_per_sec: 495.71497204964584
avg_episode_per_sec: 1.8462382571681408
collect_time: 1.083283802745864
reward_mean: 1675.0
reward_std: 0.0
reward_max: 1675.0
reward_min: 1675.0
total_envstep_count: 875069
total_train_sample_count: 875040
total_episode_count: 4806
total_duration: 1742.391309294582
[2022-12-21 16:11:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1252
train_sample_count: 1252
avg_envstep_per_episode: 250.4
avg_sample_per_episode: 250.4
avg_envstep_per_sec: 500.86512573033133
avg_train_sample_per_sec: 500.86512573033133
avg_episode_per_sec: 2.0002600867824736
collect_time: 2.49967493379462
reward_mean: 1595.800048828125
reward_std: 492.08795166015625
reward_max: 1895.0
reward_min: 626.0
total_envstep_count: 876044
total_train_sample_count: 876016
total_episode_count: 4811
total_duration: 1744.8909842283767
[2022-12-21 16:11:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1096
train_sample_count: 1096
avg_envstep_per_episode: 274.0
avg_sample_per_episode: 274.0
avg_envstep_per_sec: 504.8484599552824
avg_train_sample_per_sec: 504.8484599552824
avg_episode_per_sec: 1.8425126275740236
collect_time: 2.170948486397442
reward_mean: 1623.0
reward_std: 266.624267578125
reward_max: 1888.0
reward_min: 1311.0
total_envstep_count: 877049
total_train_sample_count: 877016
total_episode_count: 4815
total_duration: 1747.0619327147742
[2022-12-21 16:11:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 848
train_sample_count: 848
avg_envstep_per_episode: 212.0
avg_sample_per_episode: 212.0
avg_envstep_per_sec: 497.3878645735866
avg_train_sample_per_sec: 497.3878645735866
avg_episode_per_sec: 2.346169172516918
collect_time: 1.7049068954004238
reward_mean: 1346.5
reward_std: 350.2845153808594
reward_max: 1895.0
reward_min: 1034.0
total_envstep_count: 878014
total_train_sample_count: 877984
total_episode_count: 4819
total_duration: 1748.7668396101747
[2022-12-21 16:11:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1053
train_sample_count: 1053
avg_envstep_per_episode: 263.25
avg_sample_per_episode: 263.25
avg_envstep_per_sec: 499.2749447923007
avg_train_sample_per_sec: 499.2749447923007
avg_episode_per_sec: 1.8965809868653398
collect_time: 2.109058367505403
reward_mean: 1584.75
reward_std: 618.9653930664062
reward_max: 2328.0
reward_min: 627.0
total_envstep_count: 879011
total_train_sample_count: 878965
total_episode_count: 4823
total_duration: 1750.87589797768
[2022-12-21 16:11:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 546
train_sample_count: 546
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 496.1666114706067
avg_train_sample_per_sec: 496.1666114706067
avg_episode_per_sec: 1.8174601152769476
collect_time: 1.1004368036407977
reward_mean: 1598.5
reward_std: 296.5
reward_max: 1895.0
reward_min: 1302.0
total_envstep_count: 879985
total_train_sample_count: 879931
total_episode_count: 4825
total_duration: 1751.976334781321
[2022-12-21 16:11:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1800
train_sample_count: 1800
avg_envstep_per_episode: 257.14285714285717
avg_sample_per_episode: 257.14285714285717
avg_envstep_per_sec: 500.4278481087231
avg_train_sample_per_sec: 500.4278481087231
avg_episode_per_sec: 1.9461082982005897
collect_time: 3.5969221273411858
reward_mean: 1457.142822265625
reward_std: 689.823486328125
reward_max: 2589.0
reward_min: 231.0
total_envstep_count: 880971
total_train_sample_count: 880939
total_episode_count: 4832
total_duration: 1755.5732569086622
[2022-12-21 16:11:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 288
train_sample_count: 288
avg_envstep_per_episode: 288.0
avg_sample_per_episode: 288.0
avg_envstep_per_sec: 499.01473051937666
avg_train_sample_per_sec: 499.01473051937666
avg_episode_per_sec: 1.7326900365256135
collect_time: 0.5771372714794378
reward_mean: 1892.0
reward_std: 0.0
reward_max: 1892.0
reward_min: 1892.0
total_envstep_count: 881931
total_train_sample_count: 881899
total_episode_count: 4833
total_duration: 1756.1503941801416
[2022-12-21 16:11:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1420
train_sample_count: 1420
avg_envstep_per_episode: 284.0
avg_sample_per_episode: 284.0
avg_envstep_per_sec: 491.94932654931347
avg_train_sample_per_sec: 491.94932654931347
avg_episode_per_sec: 1.7322159385539206
collect_time: 2.8864761538761003
reward_mean: 1761.199951171875
reward_std: 233.8370361328125
reward_max: 1894.0
reward_min: 1296.0
total_envstep_count: 882945
total_train_sample_count: 882911
total_episode_count: 4838
total_duration: 1759.0368703340177
[2022-12-21 16:11:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 610
train_sample_count: 610
avg_envstep_per_episode: 203.33333333333334
avg_sample_per_episode: 203.33333333333334
avg_envstep_per_sec: 493.373717817417
avg_train_sample_per_sec: 493.373717817417
avg_episode_per_sec: 2.4264281204135263
collect_time: 1.2363852754429512
reward_mean: 1252.3333740234375
reward_std: 150.3558807373047
reward_max: 1400.0
reward_min: 1046.0
total_envstep_count: 883927
total_train_sample_count: 883893
total_episode_count: 4841
total_duration: 1760.2732556094606
[2022-12-21 16:11:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1621
train_sample_count: 1621
avg_envstep_per_episode: 324.2
avg_sample_per_episode: 324.2
avg_envstep_per_sec: 492.2712528194644
avg_train_sample_per_sec: 492.2712528194644
avg_episode_per_sec: 1.5184184232555964
collect_time: 3.292899982917519
reward_mean: 1593.800048828125
reward_std: 645.2606811523438
reward_max: 2315.0
reward_min: 627.0
total_envstep_count: 884922
total_train_sample_count: 884878
total_episode_count: 4846
total_duration: 1763.5661555923782
[2022-12-21 16:11:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 327
train_sample_count: 327
avg_envstep_per_episode: 163.5
avg_sample_per_episode: 163.5
avg_envstep_per_sec: 497.8374408138381
avg_train_sample_per_sec: 497.8374408138381
avg_episode_per_sec: 3.0448773138461047
collect_time: 0.6568409147078971
reward_mean: 780.5
reward_std: 28.5
reward_max: 809.0
reward_min: 752.0
total_envstep_count: 885880
total_train_sample_count: 885841
total_episode_count: 4848
total_duration: 1764.222996507086
[2022-12-21 16:11:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 532
train_sample_count: 532
avg_envstep_per_episode: 266.0
avg_sample_per_episode: 266.0
avg_envstep_per_sec: 345.015556786796
avg_train_sample_per_sec: 345.015556786796
avg_episode_per_sec: 1.2970509653638949
collect_time: 1.5419594552623372
reward_mean: 1603.0
reward_std: 291.0
reward_max: 1894.0
reward_min: 1312.0
total_envstep_count: 886871
total_train_sample_count: 886841
total_episode_count: 4850
total_duration: 1765.7649559623483
[2022-12-21 16:11:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1074
train_sample_count: 1074
avg_envstep_per_episode: 268.5
avg_sample_per_episode: 268.5
avg_envstep_per_sec: 491.7802237300463
avg_train_sample_per_sec: 491.7802237300463
avg_episode_per_sec: 1.8315837010430032
collect_time: 2.18390237788324
reward_mean: 1656.75
reward_std: 873.0390014648438
reward_max: 2607.0
reward_min: 231.0
total_envstep_count: 887859
total_train_sample_count: 887831
total_episode_count: 4854
total_duration: 1767.9488583402315
[2022-12-21 16:11:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1470
train_sample_count: 1470
avg_envstep_per_episode: 490.0
avg_sample_per_episode: 490.0
avg_envstep_per_sec: 495.42277516225954
avg_train_sample_per_sec: 495.42277516225954
avg_episode_per_sec: 1.0110668880862441
collect_time: 2.9671627420006064
reward_mean: 2282.333251953125
reward_std: 581.9234619140625
reward_max: 2976.0
reward_min: 1552.0
total_envstep_count: 888848
total_train_sample_count: 888821
total_episode_count: 4857
total_duration: 1770.9160210822322
[2022-12-21 16:11:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 789
train_sample_count: 789
avg_envstep_per_episode: 197.25
avg_sample_per_episode: 197.25
avg_envstep_per_sec: 512.0396539065935
avg_train_sample_per_sec: 512.0396539065935
avg_episode_per_sec: 2.5958917815289912
collect_time: 1.540896284067737
reward_mean: 1215.75
reward_std: 460.5889587402344
reward_max: 1895.0
reward_min: 626.0
total_envstep_count: 889837
total_train_sample_count: 889802
total_episode_count: 4861
total_duration: 1772.4569173662999
[2022-12-21 16:11:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1243
train_sample_count: 1243
avg_envstep_per_episode: 248.6
avg_sample_per_episode: 248.6
avg_envstep_per_sec: 508.65292190309543
avg_train_sample_per_sec: 508.65292190309543
avg_episode_per_sec: 2.046069677808107
collect_time: 2.443709544318329
reward_mean: 1234.199951171875
reward_std: 556.3931274414062
reward_max: 1874.0
reward_min: 231.0
total_envstep_count: 890810
total_train_sample_count: 890781
total_episode_count: 4866
total_duration: 1774.9006269106183
[2022-12-21 16:11:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1215
train_sample_count: 1215
avg_envstep_per_episode: 405.0
avg_sample_per_episode: 405.0
avg_envstep_per_sec: 502.1235449056657
avg_train_sample_per_sec: 502.1235449056657
avg_episode_per_sec: 1.239811221989298
collect_time: 2.4197232181738517
reward_mean: 2068.0
reward_std: 685.8123779296875
reward_max: 2982.0
reward_min: 1330.0
total_envstep_count: 891783
total_train_sample_count: 891744
total_episode_count: 4869
total_duration: 1777.3203501287921
[2022-12-21 16:11:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 265
train_sample_count: 265
avg_envstep_per_episode: 265.0
avg_sample_per_episode: 265.0
avg_envstep_per_sec: 498.94002276457206
avg_train_sample_per_sec: 498.94002276457206
avg_episode_per_sec: 1.8827925387342344
collect_time: 0.5311259628595517
reward_mean: 1553.0
reward_std: 0.0
reward_max: 1553.0
reward_min: 1553.0
total_envstep_count: 892742
total_train_sample_count: 892705
total_episode_count: 4870
total_duration: 1777.8514760916516
[2022-12-21 16:12:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 942
train_sample_count: 942
avg_envstep_per_episode: 235.5
avg_sample_per_episode: 235.5
avg_envstep_per_sec: 501.669091350381
avg_train_sample_per_sec: 501.669091350381
avg_episode_per_sec: 2.1302296872627644
collect_time: 1.8777317882278668
reward_mean: 1491.5
reward_std: 518.83642578125
reward_max: 1895.0
reward_min: 626.0
total_envstep_count: 893714
total_train_sample_count: 893671
total_episode_count: 4874
total_duration: 1779.7292078798796
[2022-12-21 16:12:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1138
train_sample_count: 1138
avg_envstep_per_episode: 284.5
avg_sample_per_episode: 284.5
avg_envstep_per_sec: 496.22048371142427
avg_train_sample_per_sec: 496.22048371142427
avg_episode_per_sec: 1.7441844770173085
collect_time: 2.293335396976077
reward_mean: 1714.0
reward_std: 593.2221069335938
reward_max: 2337.0
reward_min: 736.0
total_envstep_count: 894687
total_train_sample_count: 894653
total_episode_count: 4878
total_duration: 1782.0225432768557
[2022-12-21 16:12:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1182
train_sample_count: 1182
avg_envstep_per_episode: 295.5
avg_sample_per_episode: 295.5
avg_envstep_per_sec: 496.7963174707249
avg_train_sample_per_sec: 496.7963174707249
avg_episode_per_sec: 1.6812058120836713
collect_time: 2.3792446892878845
reward_mean: 1586.5
reward_std: 866.14794921875
reward_max: 2993.0
reward_min: 629.0
total_envstep_count: 895699
total_train_sample_count: 895655
total_episode_count: 4882
total_duration: 1784.4017879661435
[2022-12-21 16:12:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1243
train_sample_count: 1243
avg_envstep_per_episode: 248.6
avg_sample_per_episode: 248.6
avg_envstep_per_sec: 499.6462192057309
avg_train_sample_per_sec: 499.6462192057309
avg_episode_per_sec: 2.0098399807149274
collect_time: 2.4877602435898565
reward_mean: 1385.0
reward_std: 648.4677124023438
reward_max: 2321.0
reward_min: 625.0
total_envstep_count: 896679
total_train_sample_count: 896634
total_episode_count: 4887
total_duration: 1786.8895482097334
[2022-12-21 16:12:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 722
train_sample_count: 722
avg_envstep_per_episode: 361.0
avg_sample_per_episode: 361.0
avg_envstep_per_sec: 494.9112226038242
avg_train_sample_per_sec: 494.9112226038242
avg_episode_per_sec: 1.3709452149690422
collect_time: 1.4588475003686874
reward_mean: 2089.5
reward_std: 238.5
reward_max: 2328.0
reward_min: 1851.0
total_envstep_count: 897654
total_train_sample_count: 897620
total_episode_count: 4889
total_duration: 1788.348395710102
[2022-12-21 16:12:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1160
train_sample_count: 1160
avg_envstep_per_episode: 290.0
avg_sample_per_episode: 290.0
avg_envstep_per_sec: 487.60677629942916
avg_train_sample_per_sec: 487.60677629942916
avg_episode_per_sec: 1.6814026768945833
collect_time: 2.378966118566958
reward_mean: 1748.75
reward_std: 504.9100646972656
reward_max: 2593.0
reward_min: 1315.0
total_envstep_count: 898637
total_train_sample_count: 898600
total_episode_count: 4893
total_duration: 1790.727361828669
[2022-12-21 16:12:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 705
train_sample_count: 705
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 488.82027635142595
avg_train_sample_per_sec: 488.82027635142595
avg_episode_per_sec: 2.0800862823464934
collect_time: 1.442247865129794
reward_mean: 1513.0
reward_std: 268.0460205078125
reward_max: 1892.0
reward_min: 1317.0
total_envstep_count: 899636
total_train_sample_count: 899593
total_episode_count: 4896
total_duration: 1792.1696096937987
[2022-12-21 16:12:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1146
train_sample_count: 1146
avg_envstep_per_episode: 286.5
avg_sample_per_episode: 286.5
avg_envstep_per_sec: 496.63049052466073
avg_train_sample_per_sec: 496.63049052466073
avg_episode_per_sec: 1.7334397575031788
collect_time: 2.307550627407751
reward_mean: 1590.0
reward_std: 586.9463500976562
reward_max: 2318.0
reward_min: 740.0
total_envstep_count: 900608
total_train_sample_count: 900571
total_episode_count: 4900
total_duration: 1794.4771603212066
[2022-12-21 16:12:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 873
train_sample_count: 873
avg_envstep_per_episode: 218.25
avg_sample_per_episode: 218.25
avg_envstep_per_sec: 502.1503660347721
avg_train_sample_per_sec: 502.1503660347721
avg_episode_per_sec: 2.300803509895863
collect_time: 1.7385230780446108
reward_mean: 1349.5
reward_std: 345.8066711425781
reward_max: 1892.0
reward_min: 1049.0
total_envstep_count: 901598
total_train_sample_count: 901552
total_episode_count: 4904
total_duration: 1796.2156833992512
[2022-12-21 16:13:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 934
train_sample_count: 934
avg_envstep_per_episode: 311.3333333333333
avg_sample_per_episode: 311.3333333333333
avg_envstep_per_sec: 496.82520555166303
avg_train_sample_per_sec: 496.82520555166303
avg_episode_per_sec: 1.5957983047697957
collect_time: 1.8799368259967977
reward_mean: 1847.3333740234375
reward_std: 414.4629821777344
reward_max: 2330.0
reward_min: 1318.0
total_envstep_count: 902556
total_train_sample_count: 902522
total_episode_count: 4907
total_duration: 1798.095620225248
[2022-12-21 16:13:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 577
train_sample_count: 577
avg_envstep_per_episode: 144.25
avg_sample_per_episode: 144.25
avg_envstep_per_sec: 495.93320993125354
avg_train_sample_per_sec: 495.93320993125354
avg_episode_per_sec: 3.438011853942832
collect_time: 1.1634631205278307
reward_mean: 882.25
reward_std: 458.3854064941406
reward_max: 1676.0
reward_min: 601.0
total_envstep_count: 903538
total_train_sample_count: 903507
total_episode_count: 4911
total_duration: 1799.259083345776
[2022-12-21 16:13:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1777
train_sample_count: 1777
avg_envstep_per_episode: 355.4
avg_sample_per_episode: 355.4
avg_envstep_per_sec: 499.6423202401469
avg_train_sample_per_sec: 499.6423202401469
avg_episode_per_sec: 1.4058590890268623
collect_time: 3.5565442077562746
reward_mean: 2031.4000244140625
reward_std: 647.3399658203125
reward_max: 3013.0
reward_min: 1030.0
total_envstep_count: 904550
total_train_sample_count: 904504
total_episode_count: 4916
total_duration: 1802.8156275535323
[2022-12-21 16:13:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 342
train_sample_count: 342
avg_envstep_per_episode: 171.0
avg_sample_per_episode: 171.0
avg_envstep_per_sec: 504.46294049945885
avg_train_sample_per_sec: 504.46294049945885
avg_episode_per_sec: 2.9500756754354316
collect_time: 0.6779487104868249
reward_mean: 1049.0
reward_std: 0.0
reward_max: 1049.0
reward_min: 1049.0
total_envstep_count: 905509
total_train_sample_count: 905470
total_episode_count: 4918
total_duration: 1803.493576264019
[2022-12-21 16:13:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 818
train_sample_count: 818
avg_envstep_per_episode: 409.0
avg_sample_per_episode: 409.0
avg_envstep_per_sec: 502.78881099451866
avg_train_sample_per_sec: 502.78881099451866
avg_episode_per_sec: 1.2293124963191164
collect_time: 1.6269256238657979
reward_mean: 2015.0
reward_std: 978.0
reward_max: 2993.0
reward_min: 1037.0
total_envstep_count: 906476
total_train_sample_count: 906432
total_episode_count: 4920
total_duration: 1805.120501887885
[2022-12-21 16:13:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1627
train_sample_count: 1627
avg_envstep_per_episode: 325.4
avg_sample_per_episode: 325.4
avg_envstep_per_sec: 507.87205074883263
avg_train_sample_per_sec: 507.87205074883263
avg_episode_per_sec: 1.5607622948642674
collect_time: 3.2035627823997554
reward_mean: 1966.0
reward_std: 178.69415283203125
reward_max: 2320.0
reward_min: 1830.0
total_envstep_count: 907448
total_train_sample_count: 907411
total_episode_count: 4925
total_duration: 1808.3240646702848
[2022-12-21 16:13:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1360
train_sample_count: 1360
avg_envstep_per_episode: 272.0
avg_sample_per_episode: 272.0
avg_envstep_per_sec: 497.1959279628259
avg_train_sample_per_sec: 497.1959279628259
avg_episode_per_sec: 1.8279262057456835
collect_time: 2.735340181832068
reward_mean: 1689.5999755859375
reward_std: 625.6646728515625
reward_max: 2603.0
reward_min: 740.0
total_envstep_count: 908443
total_train_sample_count: 908399
total_episode_count: 4930
total_duration: 1811.0594048521168
[2022-12-21 16:13:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 766
train_sample_count: 766
avg_envstep_per_episode: 255.33333333333334
avg_sample_per_episode: 255.33333333333334
avg_envstep_per_sec: 501.5528334933669
avg_train_sample_per_sec: 501.5528334933669
avg_episode_per_sec: 1.9643061363969982
collect_time: 1.5272568488243432
reward_mean: 1603.3333740234375
reward_std: 181.65963745117188
reward_max: 1847.0
reward_min: 1411.0
total_envstep_count: 909408
total_train_sample_count: 909381
total_episode_count: 4933
total_duration: 1812.5866617009412
[2022-12-21 16:13:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 612
train_sample_count: 612
avg_envstep_per_episode: 204.0
avg_sample_per_episode: 204.0
avg_envstep_per_sec: 494.8483181362
avg_train_sample_per_sec: 494.8483181362
avg_episode_per_sec: 2.425727049687255
collect_time: 1.236742608937302
reward_mean: 1287.3333740234375
reward_std: 115.28033447265625
reward_max: 1410.0
reward_min: 1133.0
total_envstep_count: 910415
total_train_sample_count: 910377
total_episode_count: 4936
total_duration: 1813.8234043098785
[2022-12-21 16:13:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1118
train_sample_count: 1118
avg_envstep_per_episode: 372.6666666666667
avg_sample_per_episode: 372.6666666666667
avg_envstep_per_sec: 495.4454197750549
avg_train_sample_per_sec: 495.4454197750549
avg_episode_per_sec: 1.3294599815073032
collect_time: 2.2565553245150616
reward_mean: 2188.0
reward_std: 210.07777404785156
reward_max: 2343.0
reward_min: 1891.0
total_envstep_count: 911389
total_train_sample_count: 911351
total_episode_count: 4939
total_duration: 1816.0799596343936
[2022-12-21 16:13:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1155
train_sample_count: 1155
avg_envstep_per_episode: 231.0
avg_sample_per_episode: 231.0
avg_envstep_per_sec: 493.66248400399144
avg_train_sample_per_sec: 493.66248400399144
avg_episode_per_sec: 2.137067030320309
collect_time: 2.3396552045681913
reward_mean: 1417.4000244140625
reward_std: 706.1211547851562
reward_max: 2333.0
reward_min: 231.0
total_envstep_count: 912377
total_train_sample_count: 912326
total_episode_count: 4944
total_duration: 1818.4196148389617
[2022-12-21 16:14:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 629
train_sample_count: 629
avg_envstep_per_episode: 209.66666666666666
avg_sample_per_episode: 209.66666666666666
avg_envstep_per_sec: 487.1535790645951
avg_train_sample_per_sec: 487.1535790645951
avg_episode_per_sec: 2.323466990769134
collect_time: 1.2911739275482086
reward_mean: 1224.6666259765625
reward_std: 486.90130615234375
reward_max: 1892.0
reward_min: 744.0
total_envstep_count: 913351
total_train_sample_count: 913315
total_episode_count: 4947
total_duration: 1819.71078876651
[2022-12-21 16:14:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1102
train_sample_count: 1102
avg_envstep_per_episode: 275.5
avg_sample_per_episode: 275.5
avg_envstep_per_sec: 492.4672564430279
avg_train_sample_per_sec: 492.4672564430279
avg_episode_per_sec: 1.7875399507913898
collect_time: 2.237712224685718
reward_mean: 1534.75
reward_std: 468.9740905761719
reward_max: 1891.0
reward_min: 736.0
total_envstep_count: 914364
total_train_sample_count: 914333
total_episode_count: 4951
total_duration: 1821.9485009911957
[2022-12-21 16:14:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1485
train_sample_count: 1485
avg_envstep_per_episode: 297.0
avg_sample_per_episode: 297.0
avg_envstep_per_sec: 501.87065218181846
avg_train_sample_per_sec: 501.87065218181846
avg_episode_per_sec: 1.6898001756963583
collect_time: 2.9589297432399215
reward_mean: 1541.0
reward_std: 676.0517578125
reward_max: 2325.0
reward_min: 629.0
total_envstep_count: 915345
total_train_sample_count: 915314
total_episode_count: 4956
total_duration: 1824.9074307344356
[2022-12-21 16:14:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 650
train_sample_count: 650
avg_envstep_per_episode: 216.66666666666666
avg_sample_per_episode: 216.66666666666666
avg_envstep_per_sec: 508.8844365708843
avg_train_sample_per_sec: 508.8844365708843
avg_episode_per_sec: 2.3486973995579277
collect_time: 1.277303751673017
reward_mean: 1315.6666259765625
reward_std: 131.28680419921875
reward_max: 1409.0
reward_min: 1130.0
total_envstep_count: 916342
total_train_sample_count: 916300
total_episode_count: 4959
total_duration: 1826.1847344861087
[2022-12-21 16:14:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1199
train_sample_count: 1199
avg_envstep_per_episode: 199.83333333333334
avg_sample_per_episode: 199.83333333333334
avg_envstep_per_sec: 504.76634729069764
avg_train_sample_per_sec: 504.76634729069764
avg_episode_per_sec: 2.5259366836898964
collect_time: 2.3753564524171606
reward_mean: 1242.0
reward_std: 528.9054565429688
reward_max: 1892.0
reward_min: 231.0
total_envstep_count: 917313
total_train_sample_count: 917283
total_episode_count: 4965
total_duration: 1828.560090938526
[2022-12-21 16:14:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 871
train_sample_count: 871
avg_envstep_per_episode: 290.3333333333333
avg_sample_per_episode: 290.3333333333333
avg_envstep_per_sec: 504.47139556638245
avg_train_sample_per_sec: 504.47139556638245
avg_episode_per_sec: 1.7375593417900659
collect_time: 1.726559736894709
reward_mean: 1730.0
reward_std: 228.43963623046875
reward_max: 1897.0
reward_min: 1407.0
total_envstep_count: 918272
total_train_sample_count: 918250
total_episode_count: 4968
total_duration: 1830.2866506754206
[2022-12-21 16:14:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1330
train_sample_count: 1330
avg_envstep_per_episode: 221.66666666666666
avg_sample_per_episode: 221.66666666666666
avg_envstep_per_sec: 485.92749501336164
avg_train_sample_per_sec: 485.92749501336164
avg_episode_per_sec: 2.192154112842233
collect_time: 2.7370338448608034
reward_mean: 1377.5
reward_std: 561.3705444335938
reward_max: 1895.0
reward_min: 226.0
total_envstep_count: 919291
total_train_sample_count: 919244
total_episode_count: 4974
total_duration: 1833.0236845202814
[2022-12-21 16:14:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 605
train_sample_count: 605
avg_envstep_per_episode: 151.25
avg_sample_per_episode: 151.25
avg_envstep_per_sec: 482.37915443384304
avg_train_sample_per_sec: 482.37915443384304
avg_episode_per_sec: 3.1892836656783015
collect_time: 1.2542001337310567
reward_mean: 929.5
reward_std: 473.483642578125
reward_max: 1411.0
reward_min: 231.0
total_envstep_count: 920257
total_train_sample_count: 920221
total_episode_count: 4978
total_duration: 1834.2778846540125
[2022-12-21 16:14:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 899
train_sample_count: 899
avg_envstep_per_episode: 224.75
avg_sample_per_episode: 224.75
avg_envstep_per_sec: 504.62315179435006
avg_train_sample_per_sec: 504.62315179435006
avg_episode_per_sec: 2.245264301643382
collect_time: 1.7815274562875605
reward_mean: 1380.0
reward_std: 226.1382293701172
reward_max: 1674.0
reward_min: 1038.0
total_envstep_count: 921246
total_train_sample_count: 921204
total_episode_count: 4982
total_duration: 1836.0594121103
[2022-12-21 16:14:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 403
train_sample_count: 403
avg_envstep_per_episode: 201.5
avg_sample_per_episode: 201.5
avg_envstep_per_sec: 514.0887081067023
avg_train_sample_per_sec: 514.0887081067023
avg_episode_per_sec: 2.551308725095297
collect_time: 0.783911402147263
reward_mean: 1317.0
reward_std: 2.0
reward_max: 1319.0
reward_min: 1315.0
total_envstep_count: 922205
total_train_sample_count: 922183
total_episode_count: 4984
total_duration: 1836.8433235124471
[2022-12-21 16:14:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1459
train_sample_count: 1459
avg_envstep_per_episode: 291.8
avg_sample_per_episode: 291.8
avg_envstep_per_sec: 507.5992203877381
avg_train_sample_per_sec: 507.5992203877381
avg_episode_per_sec: 1.7395449636317275
collect_time: 2.874314895293808
reward_mean: 1822.5999755859375
reward_std: 459.83416748046875
reward_max: 2609.0
reward_min: 1315.0
total_envstep_count: 923241
total_train_sample_count: 923210
total_episode_count: 4989
total_duration: 1839.7176384077409
[2022-12-21 16:14:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1059
train_sample_count: 1059
avg_envstep_per_episode: 353.0
avg_sample_per_episode: 353.0
avg_envstep_per_sec: 499.1950042806487
avg_train_sample_per_sec: 499.1950042806487
avg_episode_per_sec: 1.4141501537695431
collect_time: 2.121415460729706
reward_mean: 1700.0
reward_std: 1129.88232421875
reward_max: 2979.0
reward_min: 231.0
total_envstep_count: 924254
total_train_sample_count: 924197
total_episode_count: 4992
total_duration: 1841.8390538684705
[2022-12-21 16:14:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1244
train_sample_count: 1244
avg_envstep_per_episode: 248.8
avg_sample_per_episode: 248.8
avg_envstep_per_sec: 422.17400643089405
avg_train_sample_per_sec: 422.17400643089405
avg_episode_per_sec: 1.6968408618605066
collect_time: 2.9466522833011775
reward_mean: 1469.199951171875
reward_std: 129.0447998046875
reward_max: 1673.0
reward_min: 1303.0
total_envstep_count: 925225
total_train_sample_count: 925189
total_episode_count: 4997
total_duration: 1844.7857061517716
[2022-12-21 16:14:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 741
train_sample_count: 741
avg_envstep_per_episode: 185.25
avg_sample_per_episode: 185.25
avg_envstep_per_sec: 506.9995533524395
avg_train_sample_per_sec: 506.9995533524395
avg_episode_per_sec: 2.7368396942102
collect_time: 1.461539749098942
reward_mean: 1125.0
reward_std: 260.9185791015625
reward_max: 1400.0
reward_min: 733.0
total_envstep_count: 926205
total_train_sample_count: 926170
total_episode_count: 5001
total_duration: 1846.2472459008704
[2022-12-21 16:14:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1203
train_sample_count: 1203
avg_envstep_per_episode: 240.6
avg_sample_per_episode: 240.6
avg_envstep_per_sec: 500.7689488936035
avg_train_sample_per_sec: 500.7689488936035
avg_episode_per_sec: 2.081333952176241
collect_time: 2.402305499687835
reward_mean: 1186.0
reward_std: 688.2830810546875
reward_max: 2307.0
reward_min: 231.0
total_envstep_count: 927208
total_train_sample_count: 927157
total_episode_count: 5006
total_duration: 1848.6495514005583
[2022-12-21 16:14:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1005
train_sample_count: 1005
avg_envstep_per_episode: 201.0
avg_sample_per_episode: 201.0
avg_envstep_per_sec: 504.8680935979446
avg_train_sample_per_sec: 504.8680935979446
avg_episode_per_sec: 2.511781560188779
collect_time: 1.9906189611584746
reward_mean: 1232.5999755859375
reward_std: 516.296630859375
reward_max: 1673.0
reward_min: 231.0
total_envstep_count: 928204
total_train_sample_count: 928174
total_episode_count: 5011
total_duration: 1850.6401703617166
[2022-12-21 16:14:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 296
train_sample_count: 296
avg_envstep_per_episode: 296.0
avg_sample_per_episode: 296.0
avg_envstep_per_sec: 510.61563486410853
avg_train_sample_per_sec: 510.61563486410853
avg_episode_per_sec: 1.7250528204868532
collect_time: 0.5796923944147837
reward_mean: 1893.0
reward_std: 0.0
reward_max: 1893.0
reward_min: 1893.0
total_envstep_count: 929371
total_train_sample_count: 929334
total_episode_count: 5012
total_duration: 1851.2198627561313
[2022-12-21 16:15:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2059
train_sample_count: 2059
avg_envstep_per_episode: 257.375
avg_sample_per_episode: 257.375
avg_envstep_per_sec: 508.55704545582455
avg_train_sample_per_sec: 508.55704545582455
avg_episode_per_sec: 1.9759380105131599
collect_time: 4.048710008833913
reward_mean: 1469.875
reward_std: 784.948486328125
reward_max: 2334.0
reward_min: 231.0
total_envstep_count: 930379
total_train_sample_count: 930337
total_episode_count: 5020
total_duration: 1855.2685727649653
[2022-12-21 16:15:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 895
train_sample_count: 895
avg_envstep_per_episode: 223.75
avg_sample_per_episode: 223.75
avg_envstep_per_sec: 505.45642014181544
avg_train_sample_per_sec: 505.45642014181544
avg_episode_per_sec: 2.2590231067790634
collect_time: 1.770676885949714
reward_mean: 1419.0
reward_std: 304.8729248046875
reward_max: 1893.0
reward_min: 1047.0
total_envstep_count: 931351
total_train_sample_count: 931316
total_episode_count: 5024
total_duration: 1857.039249650915
[2022-12-21 16:15:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 687
train_sample_count: 687
avg_envstep_per_episode: 229.0
avg_sample_per_episode: 229.0
avg_envstep_per_sec: 499.06160564883015
avg_train_sample_per_sec: 499.06160564883015
avg_episode_per_sec: 2.179308321610612
collect_time: 1.3765835564666031
reward_mean: 1433.6666259765625
reward_std: 167.33267211914062
reward_max: 1670.0
reward_min: 1305.0
total_envstep_count: 932310
total_train_sample_count: 932279
total_episode_count: 5027
total_duration: 1858.4158332073816
[2022-12-21 16:15:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 819
train_sample_count: 819
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 501.01642911021787
avg_train_sample_per_sec: 501.01642911021787
avg_episode_per_sec: 1.8352250150557432
collect_time: 1.6346769335578601
reward_mean: 1654.0
reward_std: 194.65525817871094
reward_max: 1884.0
reward_min: 1408.0
total_envstep_count: 933307
total_train_sample_count: 933254
total_episode_count: 5030
total_duration: 1860.0505101409394
[2022-12-21 16:15:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 632
train_sample_count: 632
avg_envstep_per_episode: 210.66666666666666
avg_sample_per_episode: 210.66666666666666
avg_envstep_per_sec: 504.41639309739315
avg_train_sample_per_sec: 504.41639309739315
avg_episode_per_sec: 2.3943816128040813
collect_time: 1.2529331097254266
reward_mean: 1339.3333740234375
reward_std: 783.7109375
reward_max: 1895.0
reward_min: 231.0
total_envstep_count: 934288
total_train_sample_count: 934258
total_episode_count: 5033
total_duration: 1861.303443250665
[2022-12-21 16:15:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 702
train_sample_count: 702
avg_envstep_per_episode: 234.0
avg_sample_per_episode: 234.0
avg_envstep_per_sec: 509.74111875726413
avg_train_sample_per_sec: 509.74111875726413
avg_episode_per_sec: 2.1783808493900176
collect_time: 1.3771696537086475
reward_mean: 1290.6666259765625
reward_std: 978.9049682617188
reward_max: 2592.0
reward_min: 231.0
total_envstep_count: 935285
total_train_sample_count: 935236
total_episode_count: 5036
total_duration: 1862.6806129043737
[2022-12-21 16:15:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 986
train_sample_count: 986
avg_envstep_per_episode: 493.0
avg_sample_per_episode: 493.0
avg_envstep_per_sec: 506.8341441535075
avg_train_sample_per_sec: 506.8341441535075
avg_episode_per_sec: 1.0280611443276013
collect_time: 1.9454095809720449
reward_mean: 2457.5
reward_std: 147.5
reward_max: 2605.0
reward_min: 2310.0
total_envstep_count: 936267
total_train_sample_count: 936222
total_episode_count: 5038
total_duration: 1864.6260224853456
[2022-12-21 16:15:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1214
train_sample_count: 1214
avg_envstep_per_episode: 404.6666666666667
avg_sample_per_episode: 404.6666666666667
avg_envstep_per_sec: 506.5827592768425
avg_train_sample_per_sec: 506.5827592768425
avg_episode_per_sec: 1.2518519586742403
collect_time: 2.3964494996493966
reward_mean: 2107.0
reward_std: 995.4540405273438
reward_max: 3000.0
reward_min: 718.0
total_envstep_count: 937233
total_train_sample_count: 937208
total_episode_count: 5041
total_duration: 1867.022471984995
[2022-12-21 16:15:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 898
train_sample_count: 898
avg_envstep_per_episode: 449.0
avg_sample_per_episode: 449.0
avg_envstep_per_sec: 502.57584335151853
avg_train_sample_per_sec: 502.57584335151853
avg_episode_per_sec: 1.1193225909833375
collect_time: 1.7867949919986672
reward_mean: 2447.0
reward_std: 561.0
reward_max: 3008.0
reward_min: 1886.0
total_envstep_count: 938223
total_train_sample_count: 938178
total_episode_count: 5043
total_duration: 1868.8092669769937
[2022-12-21 16:16:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1755
train_sample_count: 1755
avg_envstep_per_episode: 250.71428571428572
avg_sample_per_episode: 250.71428571428572
avg_envstep_per_sec: 500.5891394062362
avg_train_sample_per_sec: 500.5891394062362
avg_episode_per_sec: 1.9966518380875518
collect_time: 3.5058691087099056
reward_mean: 1497.5714111328125
reward_std: 623.79296875
reward_max: 2342.0
reward_min: 765.0
total_envstep_count: 939209
total_train_sample_count: 939165
total_episode_count: 5050
total_duration: 1872.3151360857037
[2022-12-21 16:16:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 794
train_sample_count: 794
avg_envstep_per_episode: 397.0
avg_sample_per_episode: 397.0
avg_envstep_per_sec: 498.81963913728106
avg_train_sample_per_sec: 498.81963913728106
avg_episode_per_sec: 1.2564726426631765
collect_time: 1.5917576969768863
reward_mean: 1815.0
reward_std: 1179.0
reward_max: 2994.0
reward_min: 636.0
total_envstep_count: 940175
total_train_sample_count: 940139
total_episode_count: 5052
total_duration: 1873.9068937826805
[2022-12-21 16:16:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 512
train_sample_count: 512
avg_envstep_per_episode: 256.0
avg_sample_per_episode: 256.0
avg_envstep_per_sec: 503.22608275551266
avg_train_sample_per_sec: 503.22608275551266
avg_episode_per_sec: 1.9657268857637213
collect_time: 1.0174353387973136
reward_mean: 1649.0
reward_std: 246.0
reward_max: 1895.0
reward_min: 1403.0
total_envstep_count: 941134
total_train_sample_count: 941107
total_episode_count: 5054
total_duration: 1874.9243291214777
[2022-12-21 16:16:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1905
train_sample_count: 1905
avg_envstep_per_episode: 317.5
avg_sample_per_episode: 317.5
avg_envstep_per_sec: 504.6261327639225
avg_train_sample_per_sec: 504.6261327639225
avg_episode_per_sec: 1.5893736465005435
collect_time: 3.775072031180774
reward_mean: 1928.1666259765625
reward_std: 474.22967529296875
reward_max: 2341.0
reward_min: 1049.0
total_envstep_count: 942129
total_train_sample_count: 942100
total_episode_count: 5060
total_duration: 1878.6994011526585
[2022-12-21 16:16:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 227
train_sample_count: 227
avg_envstep_per_episode: 227.0
avg_sample_per_episode: 227.0
avg_envstep_per_sec: 497.5425294989031
avg_train_sample_per_sec: 497.5425294989031
avg_episode_per_sec: 2.191817310567855
collect_time: 0.4562424045008206
reward_mean: 1425.0
reward_std: 0.0
reward_max: 1425.0
reward_min: 1425.0
total_envstep_count: 943104
total_train_sample_count: 943071
total_episode_count: 5061
total_duration: 1879.1556435571595
[2022-12-21 16:16:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1795
train_sample_count: 1795
avg_envstep_per_episode: 224.375
avg_sample_per_episode: 224.375
avg_envstep_per_sec: 501.5205028267248
avg_train_sample_per_sec: 501.5205028267248
avg_episode_per_sec: 2.235188870536935
collect_time: 3.579115888349179
reward_mean: 1373.375
reward_std: 613.7705078125
reward_max: 2335.0
reward_min: 231.0
total_envstep_count: 944121
total_train_sample_count: 944086
total_episode_count: 5069
total_duration: 1882.7347594455086
[2022-12-21 16:16:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 460
train_sample_count: 460
avg_envstep_per_episode: 153.33333333333334
avg_sample_per_episode: 153.33333333333334
avg_envstep_per_sec: 511.291603824672
avg_train_sample_per_sec: 511.291603824672
avg_episode_per_sec: 3.3345104597261215
collect_time: 0.8996822880700766
reward_mean: 866.6666870117188
reward_std: 132.147216796875
reward_max: 1049.0
reward_min: 740.0
total_envstep_count: 945094
total_train_sample_count: 945074
total_episode_count: 5072
total_duration: 1883.6344417335788
[2022-12-21 16:16:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 944
train_sample_count: 944
avg_envstep_per_episode: 236.0
avg_sample_per_episode: 236.0
avg_envstep_per_sec: 521.4324386802123
avg_train_sample_per_sec: 521.4324386802123
avg_episode_per_sec: 2.209459485933103
collect_time: 1.810397531824718
reward_mean: 1451.25
reward_std: 562.739013671875
reward_max: 2006.0
reward_min: 589.0
total_envstep_count: 946107
total_train_sample_count: 946054
total_episode_count: 5076
total_duration: 1885.4448392654035
[2022-12-21 16:16:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1202
train_sample_count: 1202
avg_envstep_per_episode: 400.6666666666667
avg_sample_per_episode: 400.6666666666667
avg_envstep_per_sec: 511.63456568588424
avg_train_sample_per_sec: 511.63456568588424
avg_episode_per_sec: 1.2769581506303267
collect_time: 2.349333060381934
reward_mean: 2260.333251953125
reward_std: 522.3168334960938
reward_max: 2999.0
reward_min: 1890.0
total_envstep_count: 947064
total_train_sample_count: 947016
total_episode_count: 5079
total_duration: 1887.7941723257854
[2022-12-21 16:16:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1144
train_sample_count: 1144
avg_envstep_per_episode: 286.0
avg_sample_per_episode: 286.0
avg_envstep_per_sec: 508.6411862799293
avg_train_sample_per_sec: 508.6411862799293
avg_episode_per_sec: 1.7784656862934591
collect_time: 2.2491297025451704
reward_mean: 1659.0
reward_std: 415.4678039550781
reward_max: 2333.0
reward_min: 1312.0
total_envstep_count: 948044
total_train_sample_count: 948016
total_episode_count: 5083
total_duration: 1890.0433020283306
[2022-12-21 16:16:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 976
train_sample_count: 976
avg_envstep_per_episode: 162.66666666666666
avg_sample_per_episode: 162.66666666666666
avg_envstep_per_sec: 504.23592559983655
avg_train_sample_per_sec: 504.23592559983655
avg_episode_per_sec: 3.099811018031782
collect_time: 1.935601868984157
reward_mean: 968.6666870117188
reward_std: 455.31439208984375
reward_max: 1675.0
reward_min: 231.0
total_envstep_count: 949057
total_train_sample_count: 949004
total_episode_count: 5089
total_duration: 1891.9789038973147
[2022-12-21 16:16:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 974
train_sample_count: 974
avg_envstep_per_episode: 243.5
avg_sample_per_episode: 243.5
avg_envstep_per_sec: 502.44216112740907
avg_train_sample_per_sec: 502.44216112740907
avg_episode_per_sec: 2.0634174994965466
collect_time: 1.9385315870278121
reward_mean: 1526.0
reward_std: 636.2880859375
reward_max: 2345.0
reward_min: 627.0
total_envstep_count: 950054
total_train_sample_count: 950038
total_episode_count: 5093
total_duration: 1893.9174354843426
[2022-12-21 16:16:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 731
train_sample_count: 731
avg_envstep_per_episode: 243.66666666666666
avg_sample_per_episode: 243.66666666666666
avg_envstep_per_sec: 506.4188644056295
avg_train_sample_per_sec: 506.4188644056295
avg_episode_per_sec: 2.07832639290956
collect_time: 1.4434691347012822
reward_mean: 1216.3333740234375
reward_std: 487.46783447265625
reward_max: 1883.0
reward_min: 731.0
total_envstep_count: 951044
total_train_sample_count: 951009
total_episode_count: 5096
total_duration: 1895.3609046190438
[2022-12-21 16:16:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1409
train_sample_count: 1409
avg_envstep_per_episode: 234.83333333333334
avg_sample_per_episode: 234.83333333333334
avg_envstep_per_sec: 507.0150614570539
avg_train_sample_per_sec: 507.0150614570539
avg_episode_per_sec: 2.1590421353742535
collect_time: 2.7790101460710703
reward_mean: 1411.1666259765625
reward_std: 547.4417724609375
reward_max: 2333.0
reward_min: 740.0
total_envstep_count: 952038
total_train_sample_count: 951998
total_episode_count: 5102
total_duration: 1898.1399147651148
[2022-12-21 16:17:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 632
train_sample_count: 632
avg_envstep_per_episode: 210.66666666666666
avg_sample_per_episode: 210.66666666666666
avg_envstep_per_sec: 504.06937165333335
avg_train_sample_per_sec: 504.06937165333335
avg_episode_per_sec: 2.392734359113924
collect_time: 1.2537956788111482
reward_mean: 1327.0
reward_std: 400.9463806152344
reward_max: 1894.0
reward_min: 1039.0
total_envstep_count: 953021
total_train_sample_count: 952990
total_episode_count: 5105
total_duration: 1899.393710443926
[2022-12-21 16:17:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 863
train_sample_count: 863
avg_envstep_per_episode: 287.6666666666667
avg_sample_per_episode: 287.6666666666667
avg_envstep_per_sec: 500.6586486198125
avg_train_sample_per_sec: 500.6586486198125
avg_episode_per_sec: 1.7404124517490585
collect_time: 1.72372933610369
reward_mean: 1872.0
reward_std: 28.284271240234375
reward_max: 1892.0
reward_min: 1832.0
total_envstep_count: 953996
total_train_sample_count: 953961
total_episode_count: 5108
total_duration: 1901.1174397800296
[2022-12-21 16:17:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 200.0
avg_sample_per_episode: 200.0
avg_envstep_per_sec: 502.0866202338831
avg_train_sample_per_sec: 502.0866202338831
avg_episode_per_sec: 2.5104331011694154
collect_time: 1.991688206178802
reward_mean: 1197.4000244140625
reward_std: 548.8419189453125
reward_max: 1847.0
reward_min: 231.0
total_envstep_count: 954993
total_train_sample_count: 954949
total_episode_count: 5113
total_duration: 1903.1091279862085
[2022-12-21 16:17:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 567
train_sample_count: 567
avg_envstep_per_episode: 283.5
avg_sample_per_episode: 283.5
avg_envstep_per_sec: 495.0231348302702
avg_train_sample_per_sec: 495.0231348302702
avg_episode_per_sec: 1.7461133503713235
collect_time: 1.1454010128120753
reward_mean: 1686.0
reward_std: 648.0
reward_max: 2334.0
reward_min: 1038.0
total_envstep_count: 955967
total_train_sample_count: 955924
total_episode_count: 5115
total_duration: 1904.2545289990205
[2022-12-21 16:17:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1595
train_sample_count: 1595
avg_envstep_per_episode: 398.75
avg_sample_per_episode: 398.75
avg_envstep_per_sec: 496.4515302046115
avg_train_sample_per_sec: 496.4515302046115
avg_episode_per_sec: 1.2450195114849192
collect_time: 3.212801055004552
reward_mean: 2280.75
reward_std: 452.7308044433594
reward_max: 2999.0
reward_min: 1893.0
total_envstep_count: 956956
total_train_sample_count: 956919
total_episode_count: 5119
total_duration: 1907.467330054025
[2022-12-21 16:17:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 358.5
avg_sample_per_episode: 358.5
avg_envstep_per_sec: 502.0536929508774
avg_train_sample_per_sec: 502.0536929508774
avg_episode_per_sec: 1.4004287111600486
collect_time: 1.4281341021231242
reward_mean: 2115.5
reward_std: 222.5
reward_max: 2338.0
reward_min: 1893.0
total_envstep_count: 957914
total_train_sample_count: 957888
total_episode_count: 5121
total_duration: 1908.8954641561481
[2022-12-21 16:17:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 885
train_sample_count: 885
avg_envstep_per_episode: 295.0
avg_sample_per_episode: 295.0
avg_envstep_per_sec: 511.20736091635115
avg_train_sample_per_sec: 511.20736091635115
avg_episode_per_sec: 1.7329063081910208
collect_time: 1.7311957292900024
reward_mean: 1757.0
reward_std: 531.6069946289062
reward_max: 2330.0
reward_min: 1049.0
total_envstep_count: 958896
total_train_sample_count: 958857
total_episode_count: 5124
total_duration: 1910.6266598854381
[2022-12-21 16:17:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 944
train_sample_count: 944
avg_envstep_per_episode: 314.6666666666667
avg_sample_per_episode: 314.6666666666667
avg_envstep_per_sec: 517.0660664209298
avg_train_sample_per_sec: 517.0660664209298
avg_episode_per_sec: 1.6432184314224465
collect_time: 1.8256854613072104
reward_mean: 1905.3333740234375
reward_std: 613.2994995117188
reward_max: 2341.0
reward_min: 1038.0
total_envstep_count: 959862
total_train_sample_count: 959825
total_episode_count: 5127
total_duration: 1912.4523453467452
[2022-12-21 16:17:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1055
train_sample_count: 1055
avg_envstep_per_episode: 263.75
avg_sample_per_episode: 263.75
avg_envstep_per_sec: 517.5531321069
avg_train_sample_per_sec: 517.5531321069
avg_episode_per_sec: 1.9622867568034121
collect_time: 2.0384380550557486
reward_mean: 1458.25
reward_std: 432.5744934082031
reward_max: 1895.0
reward_min: 746.0
total_envstep_count: 960858
total_train_sample_count: 960808
total_episode_count: 5131
total_duration: 1914.490783401801
[2022-12-21 16:17:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1373
train_sample_count: 1373
avg_envstep_per_episode: 274.6
avg_sample_per_episode: 274.6
avg_envstep_per_sec: 489.021316354176
avg_train_sample_per_sec: 489.021316354176
avg_episode_per_sec: 1.7808496589736929
collect_time: 2.807648570897057
reward_mean: 1587.800048828125
reward_std: 626.4080200195312
reward_max: 2592.0
reward_min: 715.0
total_envstep_count: 961816
total_train_sample_count: 961797
total_episode_count: 5136
total_duration: 1917.2984319726982
[2022-12-21 16:17:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 494
train_sample_count: 494
avg_envstep_per_episode: 247.0
avg_sample_per_episode: 247.0
avg_envstep_per_sec: 491.4942263855005
avg_train_sample_per_sec: 491.4942263855005
avg_episode_per_sec: 1.9898551675526335
collect_time: 1.005098276805665
reward_mean: 1480.0
reward_std: 854.0
reward_max: 2334.0
reward_min: 626.0
total_envstep_count: 962774
total_train_sample_count: 962759
total_episode_count: 5138
total_duration: 1918.3035302495039
[2022-12-21 16:17:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 763
train_sample_count: 763
avg_envstep_per_episode: 381.5
avg_sample_per_episode: 381.5
avg_envstep_per_sec: 479.61353610915955
avg_train_sample_per_sec: 479.61353610915955
avg_episode_per_sec: 1.2571783384250577
collect_time: 1.5908641907603334
reward_mean: 1788.0
reward_std: 1206.0
reward_max: 2994.0
reward_min: 582.0
total_envstep_count: 963764
total_train_sample_count: 963726
total_episode_count: 5140
total_duration: 1919.8943944402643
[2022-12-21 16:17:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 877
train_sample_count: 877
avg_envstep_per_episode: 292.3333333333333
avg_sample_per_episode: 292.3333333333333
avg_envstep_per_sec: 438.43851553253097
avg_train_sample_per_sec: 438.43851553253097
avg_episode_per_sec: 1.4997896768501628
collect_time: 2.000280470192699
reward_mean: 1646.0
reward_std: 481.5412902832031
reward_max: 2327.0
reward_min: 1304.0
total_envstep_count: 964761
total_train_sample_count: 964699
total_episode_count: 5143
total_duration: 1921.8946749104568
[2022-12-21 16:17:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1493
train_sample_count: 1493
avg_envstep_per_episode: 497.6666666666667
avg_sample_per_episode: 497.6666666666667
avg_envstep_per_sec: 464.29852607868463
avg_train_sample_per_sec: 464.29852607868463
avg_episode_per_sec: 0.9329508226631306
collect_time: 3.2156035742981905
reward_mean: 2735.333251953125
reward_std: 194.9261932373047
reward_max: 3011.0
reward_min: 2597.0
total_envstep_count: 965726
total_train_sample_count: 965676
total_episode_count: 5146
total_duration: 1925.110278484755
[2022-12-21 16:17:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 200
train_sample_count: 200
avg_envstep_per_episode: 200.0
avg_sample_per_episode: 200.0
avg_envstep_per_sec: 491.2412687194014
avg_train_sample_per_sec: 491.2412687194014
avg_episode_per_sec: 2.4562063435970067
collect_time: 0.40713191813336974
reward_mean: 1315.0
reward_std: 0.0
reward_max: 1315.0
reward_min: 1315.0
total_envstep_count: 966685
total_train_sample_count: 966644
total_episode_count: 5147
total_duration: 1925.5174104028886
[2022-12-21 16:18:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1319
train_sample_count: 1319
avg_envstep_per_episode: 329.75
avg_sample_per_episode: 329.75
avg_envstep_per_sec: 476.72956657253803
avg_train_sample_per_sec: 476.72956657253803
avg_episode_per_sec: 1.445730300447424
collect_time: 2.7667677704216906
reward_mean: 1887.25
reward_std: 668.7212524414062
reward_max: 2997.0
reward_min: 1315.0
total_envstep_count: 967659
total_train_sample_count: 967627
total_episode_count: 5151
total_duration: 1928.2841781733102
[2022-12-21 16:18:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 754
train_sample_count: 754
avg_envstep_per_episode: 377.0
avg_sample_per_episode: 377.0
avg_envstep_per_sec: 488.3131087829074
avg_train_sample_per_sec: 488.3131087829074
avg_episode_per_sec: 1.2952602354984282
collect_time: 1.5440912530062976
reward_mean: 2248.0
reward_std: 355.0
reward_max: 2603.0
reward_min: 1893.0
total_envstep_count: 968633
total_train_sample_count: 968597
total_episode_count: 5153
total_duration: 1929.8282694263166
[2022-12-21 16:18:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1720
train_sample_count: 1720
avg_envstep_per_episode: 430.0
avg_sample_per_episode: 430.0
avg_envstep_per_sec: 491.18372659477495
avg_train_sample_per_sec: 491.18372659477495
avg_episode_per_sec: 1.1422877362669186
collect_time: 3.501744676934288
reward_mean: 2200.0
reward_std: 793.012939453125
reward_max: 2997.0
reward_min: 1402.0
total_envstep_count: 969607
total_train_sample_count: 969573
total_episode_count: 5157
total_duration: 1933.330014103251
[2022-12-21 16:18:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 664
train_sample_count: 664
avg_envstep_per_episode: 221.33333333333334
avg_sample_per_episode: 221.33333333333334
avg_envstep_per_sec: 491.3638592915579
avg_train_sample_per_sec: 491.3638592915579
avg_episode_per_sec: 2.2200174365582437
collect_time: 1.351340737508344
reward_mean: 1451.6666259765625
reward_std: 584.3654174804688
reward_max: 1895.0
reward_min: 626.0
total_envstep_count: 970580
total_train_sample_count: 970549
total_episode_count: 5160
total_duration: 1934.6813548407592
[2022-12-21 16:18:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1194
train_sample_count: 1194
avg_envstep_per_episode: 298.5
avg_sample_per_episode: 298.5
avg_envstep_per_sec: 493.05117132321163
avg_train_sample_per_sec: 493.05117132321163
avg_episode_per_sec: 1.6517627180007088
collect_time: 2.4216553360894317
reward_mean: 1569.0
reward_std: 572.6286010742188
reward_max: 2323.0
reward_min: 798.0
total_envstep_count: 971561
total_train_sample_count: 971527
total_episode_count: 5164
total_duration: 1937.1030101768488
[2022-12-21 16:18:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 934
train_sample_count: 934
avg_envstep_per_episode: 311.3333333333333
avg_sample_per_episode: 311.3333333333333
avg_envstep_per_sec: 499.3681893415746
avg_train_sample_per_sec: 499.3681893415746
avg_episode_per_sec: 1.6039663469215457
collect_time: 1.8703634311017985
reward_mean: 1829.6666259765625
reward_std: 406.2186279296875
reward_max: 2325.0
reward_min: 1330.0
total_envstep_count: 972544
total_train_sample_count: 972509
total_episode_count: 5167
total_duration: 1938.9733736079506
[2022-12-21 16:18:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1134
train_sample_count: 1134
avg_envstep_per_episode: 283.5
avg_sample_per_episode: 283.5
avg_envstep_per_sec: 496.60258408138014
avg_train_sample_per_sec: 496.60258408138014
avg_episode_per_sec: 1.7516845999343216
collect_time: 2.283516107951156
reward_mean: 1646.5
reward_std: 500.8300476074219
reward_max: 2332.0
reward_min: 1040.0
total_envstep_count: 973540
total_train_sample_count: 973499
total_episode_count: 5171
total_duration: 1941.2568897159017
[2022-12-21 16:18:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 931
train_sample_count: 931
avg_envstep_per_episode: 186.2
avg_sample_per_episode: 186.2
avg_envstep_per_sec: 496.93911985692887
avg_train_sample_per_sec: 496.93911985692887
avg_episode_per_sec: 2.668845971304666
collect_time: 1.8734689276787855
reward_mean: 1186.5999755859375
reward_std: 418.10028076171875
reward_max: 1892.0
reward_min: 626.0
total_envstep_count: 974511
total_train_sample_count: 974466
total_episode_count: 5176
total_duration: 1943.1303586435804
[2022-12-21 16:18:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 814
train_sample_count: 814
avg_envstep_per_episode: 203.5
avg_sample_per_episode: 203.5
avg_envstep_per_sec: 501.9644814084211
avg_train_sample_per_sec: 501.9644814084211
avg_episode_per_sec: 2.4666559282969094
collect_time: 1.6216286812088059
reward_mean: 1323.5
reward_std: 670.1378784179688
reward_max: 1895.0
reward_min: 231.0
total_envstep_count: 975531
total_train_sample_count: 975496
total_episode_count: 5180
total_duration: 1944.7519873247893
[2022-12-21 16:18:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 607
train_sample_count: 607
avg_envstep_per_episode: 202.33333333333334
avg_sample_per_episode: 202.33333333333334
avg_envstep_per_sec: 498.2875459952971
avg_train_sample_per_sec: 498.2875459952971
avg_episode_per_sec: 2.4627061581316165
collect_time: 1.2181721274762283
reward_mean: 1324.3333740234375
reward_std: 773.3517456054688
reward_max: 1895.0
reward_min: 231.0
total_envstep_count: 976512
total_train_sample_count: 976475
total_episode_count: 5183
total_duration: 1945.9701594522655
[2022-12-21 16:18:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1776
train_sample_count: 1776
avg_envstep_per_episode: 355.2
avg_sample_per_episode: 355.2
avg_envstep_per_sec: 503.27060203821054
avg_train_sample_per_sec: 503.27060203821054
avg_episode_per_sec: 1.4168654336661333
collect_time: 3.5289166361144977
reward_mean: 1975.800048828125
reward_std: 730.9813842773438
reward_max: 3003.0
reward_min: 1035.0
total_envstep_count: 977540
total_train_sample_count: 977495
total_episode_count: 5188
total_duration: 1949.49907608838
[2022-12-21 16:18:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 403
train_sample_count: 403
avg_envstep_per_episode: 403.0
avg_sample_per_episode: 403.0
avg_envstep_per_sec: 505.38631733123214
avg_train_sample_per_sec: 505.38631733123214
avg_episode_per_sec: 1.2540603407722881
collect_time: 0.7974097955957764
reward_mean: 2333.0
reward_std: 0.0
reward_max: 2333.0
reward_min: 2333.0
total_envstep_count: 978507
total_train_sample_count: 978462
total_episode_count: 5189
total_duration: 1950.2964858839757
[2022-12-21 16:18:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1359
train_sample_count: 1359
avg_envstep_per_episode: 339.75
avg_sample_per_episode: 339.75
avg_envstep_per_sec: 503.4944122415405
avg_train_sample_per_sec: 503.4944122415405
avg_episode_per_sec: 1.4819555915865799
collect_time: 2.699136210767021
reward_mean: 1983.25
reward_std: 199.970458984375
reward_max: 2327.0
reward_min: 1829.0
total_envstep_count: 979504
total_train_sample_count: 979449
total_episode_count: 5193
total_duration: 1952.9956220947427
[2022-12-21 16:18:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1089
train_sample_count: 1089
avg_envstep_per_episode: 272.25
avg_sample_per_episode: 272.25
avg_envstep_per_sec: 495.32177235791306
avg_train_sample_per_sec: 495.32177235791306
avg_episode_per_sec: 1.8193637184863656
collect_time: 2.1985708296567728
reward_mean: 1671.25
reward_std: 475.1448974609375
reward_max: 2334.0
reward_min: 1126.0
total_envstep_count: 980493
total_train_sample_count: 980466
total_episode_count: 5197
total_duration: 1955.1941929243994
[2022-12-21 16:18:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 478
train_sample_count: 478
avg_envstep_per_episode: 478.0
avg_sample_per_episode: 478.0
avg_envstep_per_sec: 500.6089600865435
avg_train_sample_per_sec: 500.6089600865435
avg_episode_per_sec: 1.0472990796789614
collect_time: 0.95483708465259
reward_mean: 2320.0
reward_std: 0.0
reward_max: 2320.0
reward_min: 2320.0
total_envstep_count: 981485
total_train_sample_count: 981436
total_episode_count: 5198
total_duration: 1956.149030009052
[2022-12-21 16:18:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 268
train_sample_count: 268
avg_envstep_per_episode: 268.0
avg_sample_per_episode: 268.0
avg_envstep_per_sec: 498.0480275983278
avg_train_sample_per_sec: 498.0480275983278
avg_episode_per_sec: 1.8583881626803276
collect_time: 0.5381007154919206
reward_mean: 1680.0
reward_std: 0.0
reward_max: 1680.0
reward_min: 1680.0
total_envstep_count: 982541
total_train_sample_count: 982496
total_episode_count: 5199
total_duration: 1956.687130724544
[2022-12-21 16:18:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 3002
train_sample_count: 3002
avg_envstep_per_episode: 300.2
avg_sample_per_episode: 300.2
avg_envstep_per_sec: 497.9610495823761
avg_train_sample_per_sec: 497.9610495823761
avg_episode_per_sec: 1.6587643223929918
collect_time: 6.028583967596824
reward_mean: 1728.0
reward_std: 741.7569580078125
reward_max: 2343.0
reward_min: 626.0
total_envstep_count: 983572
total_train_sample_count: 983530
total_episode_count: 5209
total_duration: 1962.7157146921409
[2022-12-21 16:19:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 280
train_sample_count: 280
avg_envstep_per_episode: 280.0
avg_sample_per_episode: 280.0
avg_envstep_per_sec: 494.7017114883814
avg_train_sample_per_sec: 494.7017114883814
avg_episode_per_sec: 1.7667918267442193
collect_time: 0.5659976375613895
reward_mean: 1666.0
reward_std: 0.0
reward_max: 1666.0
reward_min: 1666.0
total_envstep_count: 985027
total_train_sample_count: 984974
total_episode_count: 5210
total_duration: 1963.2817123297023
[2022-12-21 16:19:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 525
train_sample_count: 525
avg_envstep_per_episode: 262.5
avg_sample_per_episode: 262.5
avg_envstep_per_sec: 494.81994327675227
avg_train_sample_per_sec: 494.81994327675227
avg_episode_per_sec: 1.8850283553400085
collect_time: 1.0609919974595043
reward_mean: 1673.0
reward_std: 1.0
reward_max: 1674.0
reward_min: 1672.0
total_envstep_count: 985985
total_train_sample_count: 985943
total_episode_count: 5212
total_duration: 1964.3427043271618
[2022-12-21 16:19:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 901
train_sample_count: 901
avg_envstep_per_episode: 300.3333333333333
avg_sample_per_episode: 300.3333333333333
avg_envstep_per_sec: 495.96273598010885
avg_train_sample_per_sec: 495.96273598010885
avg_episode_per_sec: 1.6513742596452015
collect_time: 1.816668742701943
reward_mean: 1805.6666259765625
reward_std: 753.5429077148438
reward_max: 2341.0
reward_min: 740.0
total_envstep_count: 986975
total_train_sample_count: 986940
total_episode_count: 5215
total_duration: 1966.1593730698637
[2022-12-21 16:19:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1874
train_sample_count: 1874
avg_envstep_per_episode: 468.5
avg_sample_per_episode: 468.5
avg_envstep_per_sec: 495.2950371448448
avg_train_sample_per_sec: 495.2950371448448
avg_episode_per_sec: 1.0571932489751223
collect_time: 3.7836034271669163
reward_mean: 2338.25
reward_std: 800.4561767578125
reward_max: 2999.0
reward_min: 1038.0
total_envstep_count: 987956
total_train_sample_count: 987926
total_episode_count: 5219
total_duration: 1969.9429764970307
[2022-12-21 16:19:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 411
train_sample_count: 411
avg_envstep_per_episode: 411.0
avg_sample_per_episode: 411.0
avg_envstep_per_sec: 497.62982945011265
avg_train_sample_per_sec: 497.62982945011265
avg_episode_per_sec: 1.2107781738445564
collect_time: 0.8259151193853477
reward_mean: 1649.0
reward_std: 0.0
reward_max: 1649.0
reward_min: 1649.0
total_envstep_count: 988915
total_train_sample_count: 988889
total_episode_count: 5220
total_duration: 1970.768891616416
[2022-12-21 16:19:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 772
train_sample_count: 772
avg_envstep_per_episode: 257.3333333333333
avg_sample_per_episode: 257.3333333333333
avg_envstep_per_sec: 506.81698881181967
avg_train_sample_per_sec: 506.81698881181967
avg_episode_per_sec: 1.9694960705122526
collect_time: 1.523232285109216
reward_mean: 1686.3333740234375
reward_std: 263.2430114746094
reward_max: 1895.0
reward_min: 1315.0
total_envstep_count: 989936
total_train_sample_count: 989889
total_episode_count: 5223
total_duration: 1972.2921239015254
[2022-12-21 16:19:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 937
train_sample_count: 937
avg_envstep_per_episode: 468.5
avg_sample_per_episode: 468.5
avg_envstep_per_sec: 504.84912621300623
avg_train_sample_per_sec: 504.84912621300623
avg_episode_per_sec: 1.0775861818847519
collect_time: 1.8560000430795247
reward_mean: 2422.0
reward_std: 577.0
reward_max: 2999.0
reward_min: 1845.0
total_envstep_count: 990895
total_train_sample_count: 990862
total_episode_count: 5225
total_duration: 1974.148123944605
[2022-12-21 16:19:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1296
train_sample_count: 1296
avg_envstep_per_episode: 432.0
avg_sample_per_episode: 432.0
avg_envstep_per_sec: 503.91761767096193
avg_train_sample_per_sec: 503.91761767096193
avg_episode_per_sec: 1.1664759668309304
collect_time: 2.5718489581490207
reward_mean: 2244.0
reward_std: 649.82666015625
reward_max: 2998.0
reward_min: 1412.0
total_envstep_count: 991853
total_train_sample_count: 991834
total_episode_count: 5228
total_duration: 1976.719972902754
[2022-12-21 16:19:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1437
train_sample_count: 1437
avg_envstep_per_episode: 479.0
avg_sample_per_episode: 479.0
avg_envstep_per_sec: 502.46029383904124
avg_train_sample_per_sec: 502.46029383904124
avg_episode_per_sec: 1.0489776489332803
collect_time: 2.8599274761008884
reward_mean: 2326.0
reward_std: 534.8220825195312
reward_max: 2984.0
reward_min: 1674.0
total_envstep_count: 992811
total_train_sample_count: 992803
total_episode_count: 5231
total_duration: 1979.579900378855
[2022-12-21 16:19:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 547
train_sample_count: 547
avg_envstep_per_episode: 182.33333333333334
avg_sample_per_episode: 182.33333333333334
avg_envstep_per_sec: 510.30925936110737
avg_train_sample_per_sec: 510.30925936110737
avg_episode_per_sec: 2.7987710751066217
collect_time: 1.071899029786033
reward_mean: 1175.6666259765625
reward_std: 702.2484130859375
reward_max: 1895.0
reward_min: 223.0
total_envstep_count: 993824
total_train_sample_count: 993782
total_episode_count: 5234
total_duration: 1980.651799408641
[2022-12-21 16:19:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 411
train_sample_count: 411
avg_envstep_per_episode: 411.0
avg_sample_per_episode: 411.0
avg_envstep_per_sec: 498.9199072442431
avg_train_sample_per_sec: 498.9199072442431
avg_episode_per_sec: 1.213917049256066
collect_time: 0.8237795165763901
reward_mean: 2333.0
reward_std: 0.0
reward_max: 2333.0
reward_min: 2333.0
total_envstep_count: 994783
total_train_sample_count: 994745
total_episode_count: 5235
total_duration: 1981.4755789252174
[2022-12-21 16:19:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1818
train_sample_count: 1818
avg_envstep_per_episode: 454.5
avg_sample_per_episode: 454.5
avg_envstep_per_sec: 504.8189435538134
avg_train_sample_per_sec: 504.8189435538134
avg_episode_per_sec: 1.1107127470930989
collect_time: 3.601291162335714
reward_mean: 1926.5
reward_std: 410.9412841796875
reward_max: 2320.0
reward_min: 1302.0
total_envstep_count: 995803
total_train_sample_count: 995759
total_episode_count: 5239
total_duration: 1985.076870087553
[2022-12-21 16:19:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 758
train_sample_count: 758
avg_envstep_per_episode: 252.66666666666666
avg_sample_per_episode: 252.66666666666666
avg_envstep_per_sec: 496.0591240466038
avg_train_sample_per_sec: 496.0591240466038
avg_episode_per_sec: 1.963294686200279
collect_time: 1.5280436610390566
reward_mean: 1471.3333740234375
reward_std: 606.485107421875
reward_max: 2329.0
reward_min: 1036.0
total_envstep_count: 996768
total_train_sample_count: 996733
total_episode_count: 5242
total_duration: 1986.604913748592
[2022-12-21 16:19:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2015
train_sample_count: 2015
avg_envstep_per_episode: 335.8333333333333
avg_sample_per_episode: 335.8333333333333
avg_envstep_per_sec: 497.08906377269255
avg_train_sample_per_sec: 497.08906377269255
avg_episode_per_sec: 1.4801659467176949
collect_time: 4.053599539501061
reward_mean: 1798.0
reward_std: 604.7114868164062
reward_max: 2589.0
reward_min: 1049.0
total_envstep_count: 997741
total_train_sample_count: 997716
total_episode_count: 5248
total_duration: 1990.658513288093
[2022-12-21 16:19:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 461
train_sample_count: 461
avg_envstep_per_episode: 153.66666666666666
avg_sample_per_episode: 153.66666666666666
avg_envstep_per_sec: 511.2807973716247
avg_train_sample_per_sec: 511.2807973716247
avg_episode_per_sec: 3.327206924327276
collect_time: 0.9016571761933823
reward_mean: 985.6666870117188
reward_std: 534.8933715820312
reward_max: 1408.0
reward_min: 231.0
total_envstep_count: 998763
total_train_sample_count: 998705
total_episode_count: 5251
total_duration: 1991.5601704642863
[2022-12-21 16:19:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1338
train_sample_count: 1338
avg_envstep_per_episode: 267.6
avg_sample_per_episode: 267.6
avg_envstep_per_sec: 515.9887870831855
avg_train_sample_per_sec: 515.9887870831855
avg_episode_per_sec: 1.928209219294415
collect_time: 2.5930796046238376
reward_mean: 1687.5999755859375
reward_std: 226.33302307128906
reward_max: 1894.0
reward_min: 1412.0
total_envstep_count: 999759
total_train_sample_count: 999719
total_episode_count: 5256
total_duration: 1994.1532500689102
[2022-12-21 16:19:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 220
train_sample_count: 220
avg_envstep_per_episode: 220.0
avg_sample_per_episode: 220.0
avg_envstep_per_sec: 494.03289846128007
avg_train_sample_per_sec: 494.03289846128007
avg_episode_per_sec: 2.2456040839149094
collect_time: 0.4453144733583821
reward_mean: 1409.0
reward_std: 0.0
reward_max: 1409.0
reward_min: 1409.0
total_envstep_count: 1000718
total_train_sample_count: 1000683
total_episode_count: 5257
total_duration: 1994.5985645422686
[2022-12-21 16:19:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 918
train_sample_count: 918
avg_envstep_per_episode: 306.0
avg_sample_per_episode: 306.0
avg_envstep_per_sec: 500.57380676394996
avg_train_sample_per_sec: 500.57380676394996
avg_episode_per_sec: 1.6358621136076796
collect_time: 1.83389539683384
reward_mean: 1879.6666259765625
reward_std: 377.3392333984375
reward_max: 2335.0
reward_min: 1411.0
total_envstep_count: 1001683
total_train_sample_count: 1001649
total_episode_count: 5260
total_duration: 1996.4324599391025
[2022-12-21 16:20:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1628
train_sample_count: 1628
avg_envstep_per_episode: 271.3333333333333
avg_sample_per_episode: 271.3333333333333
avg_envstep_per_sec: 448.52824376980425
avg_train_sample_per_sec: 448.52824376980425
avg_episode_per_sec: 1.653052495466109
collect_time: 3.629648796064512
reward_mean: 1539.0
reward_std: 811.7711181640625
reward_max: 3011.0
reward_min: 589.0
total_envstep_count: 1002663
total_train_sample_count: 1002641
total_episode_count: 5266
total_duration: 2000.062108735167
[2022-12-21 16:20:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 891
train_sample_count: 891
avg_envstep_per_episode: 297.0
avg_sample_per_episode: 297.0
avg_envstep_per_sec: 506.72211135852496
avg_train_sample_per_sec: 506.72211135852496
avg_episode_per_sec: 1.7061350550792085
collect_time: 1.758360213670613
reward_mean: 1680.6666259765625
reward_std: 992.4703979492188
reward_max: 3011.0
reward_min: 628.0
total_envstep_count: 1003630
total_train_sample_count: 1003604
total_episode_count: 5269
total_duration: 2001.8204689488375
[2022-12-21 16:20:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 508
train_sample_count: 508
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 500.7799849892367
avg_train_sample_per_sec: 500.7799849892367
avg_episode_per_sec: 1.9715747440521132
collect_time: 1.0144175390933774
reward_mean: 1491.5
reward_std: 176.5
reward_max: 1668.0
reward_min: 1315.0
total_envstep_count: 1004636
total_train_sample_count: 1004580
total_episode_count: 5271
total_duration: 2002.8348864879308
[2022-12-21 16:20:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1167
train_sample_count: 1167
avg_envstep_per_episode: 291.75
avg_sample_per_episode: 291.75
avg_envstep_per_sec: 500.31114493501764
avg_train_sample_per_sec: 500.31114493501764
avg_episode_per_sec: 1.7148625361954333
collect_time: 2.3325484787103323
reward_mean: 1726.0
reward_std: 405.3356628417969
reward_max: 2333.0
reward_min: 1309.0
total_envstep_count: 1005593
total_train_sample_count: 1005555
total_episode_count: 5275
total_duration: 2005.1674349666412
[2022-12-21 16:20:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1659
train_sample_count: 1659
avg_envstep_per_episode: 276.5
avg_sample_per_episode: 276.5
avg_envstep_per_sec: 500.1254204224987
avg_train_sample_per_sec: 500.1254204224987
avg_episode_per_sec: 1.8087718640958361
collect_time: 3.317167918796251
reward_mean: 1653.8333740234375
reward_std: 662.2672119140625
reward_max: 2609.0
reward_min: 788.0
total_envstep_count: 1006588
total_train_sample_count: 1006554
total_episode_count: 5281
total_duration: 2008.4846028854374
[2022-12-21 16:20:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 369
train_sample_count: 369
avg_envstep_per_episode: 369.0
avg_sample_per_episode: 369.0
avg_envstep_per_sec: 495.77128397835287
avg_train_sample_per_sec: 495.77128397835287
avg_episode_per_sec: 1.3435536151174874
collect_time: 0.7442948228847233
reward_mean: 2342.0
reward_std: 0.0
reward_max: 2342.0
reward_min: 2342.0
total_envstep_count: 1007555
total_train_sample_count: 1007523
total_episode_count: 5282
total_duration: 2009.2288977083222
[2022-12-21 16:20:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 708
train_sample_count: 708
avg_envstep_per_episode: 236.0
avg_sample_per_episode: 236.0
avg_envstep_per_sec: 497.0459570213703
avg_train_sample_per_sec: 497.0459570213703
avg_episode_per_sec: 2.10612693653123
collect_time: 1.4244155696241982
reward_mean: 1394.0
reward_std: 483.77886962890625
reward_max: 1895.0
reward_min: 740.0
total_envstep_count: 1008568
total_train_sample_count: 1008507
total_episode_count: 5285
total_duration: 2010.6533132779464
[2022-12-21 16:20:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 793
train_sample_count: 793
avg_envstep_per_episode: 396.5
avg_sample_per_episode: 396.5
avg_envstep_per_sec: 503.6482247538386
avg_train_sample_per_sec: 503.6482247538386
avg_episode_per_sec: 1.2702351191773986
collect_time: 1.5745116552085219
reward_mean: 2245.0
reward_std: 351.0
reward_max: 2596.0
reward_min: 1894.0
total_envstep_count: 1009534
total_train_sample_count: 1009492
total_episode_count: 5287
total_duration: 2012.2278249331548
[2022-12-21 16:20:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 894
train_sample_count: 894
avg_envstep_per_episode: 447.0
avg_sample_per_episode: 447.0
avg_envstep_per_sec: 504.4732197922621
avg_train_sample_per_sec: 504.4732197922621
avg_episode_per_sec: 1.1285754357768727
collect_time: 1.7721456063973857
reward_mean: 2466.0
reward_std: 138.0
reward_max: 2604.0
reward_min: 2328.0
total_envstep_count: 1010516
total_train_sample_count: 1010482
total_episode_count: 5289
total_duration: 2013.9999705395521
[2022-12-21 16:20:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1249
train_sample_count: 1249
avg_envstep_per_episode: 416.3333333333333
avg_sample_per_episode: 416.3333333333333
avg_envstep_per_sec: 502.49986338464026
avg_train_sample_per_sec: 502.49986338464026
avg_episode_per_sec: 1.2069652443185914
collect_time: 2.485572815059551
reward_mean: 2239.0
reward_std: 534.4848022460938
reward_max: 2994.0
reward_min: 1830.0
total_envstep_count: 1011489
total_train_sample_count: 1011455
total_episode_count: 5292
total_duration: 2016.4855433546118
[2022-12-21 16:20:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 874
train_sample_count: 874
avg_envstep_per_episode: 291.3333333333333
avg_sample_per_episode: 291.3333333333333
avg_envstep_per_sec: 495.605587428351
avg_train_sample_per_sec: 495.605587428351
avg_episode_per_sec: 1.7011633435755755
collect_time: 1.7634990850993038
reward_mean: 1779.0
reward_std: 648.896484375
reward_max: 2619.0
reward_min: 1039.0
total_envstep_count: 1012462
total_train_sample_count: 1012425
total_episode_count: 5295
total_duration: 2018.249042439711
[2022-12-21 16:20:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 792
train_sample_count: 792
avg_envstep_per_episode: 264.0
avg_sample_per_episode: 264.0
avg_envstep_per_sec: 494.2742086726772
avg_train_sample_per_sec: 494.2742086726772
avg_episode_per_sec: 1.8722507904268075
collect_time: 1.6023494370196554
reward_mean: 1566.0
reward_std: 622.6690063476562
reward_max: 2336.0
reward_min: 811.0
total_envstep_count: 1013460
total_train_sample_count: 1013421
total_episode_count: 5298
total_duration: 2019.8513918767308
[2022-12-21 16:20:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1323
train_sample_count: 1323
avg_envstep_per_episode: 441.0
avg_sample_per_episode: 441.0
avg_envstep_per_sec: 501.1922939578976
avg_train_sample_per_sec: 501.1922939578976
avg_episode_per_sec: 1.1364904624895638
collect_time: 2.6397053904247336
reward_mean: 2353.333251953125
reward_std: 922.3507080078125
reward_max: 3017.0
reward_min: 1049.0
total_envstep_count: 1014433
total_train_sample_count: 1014396
total_episode_count: 5301
total_duration: 2022.4910972671555
[2022-12-21 16:20:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1268
train_sample_count: 1268
avg_envstep_per_episode: 317.0
avg_sample_per_episode: 317.0
avg_envstep_per_sec: 502.1032427012839
avg_train_sample_per_sec: 502.1032427012839
avg_episode_per_sec: 1.5839219012658796
collect_time: 2.525377038352192
reward_mean: 1935.0
reward_std: 431.0208740234375
reward_max: 2608.0
reward_min: 1408.0
total_envstep_count: 1015391
total_train_sample_count: 1015364
total_episode_count: 5305
total_duration: 2025.0164743055077
[2022-12-21 16:20:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 226
train_sample_count: 226
avg_envstep_per_episode: 226.0
avg_sample_per_episode: 226.0
avg_envstep_per_sec: 505.55742170260663
avg_train_sample_per_sec: 505.55742170260663
avg_episode_per_sec: 2.236979742046932
collect_time: 0.4470313169152606
reward_mean: 1425.0
reward_std: 0.0
reward_max: 1425.0
reward_min: 1425.0
total_envstep_count: 1016454
total_train_sample_count: 1016430
total_episode_count: 5306
total_duration: 2025.4635056224229
[2022-12-21 16:20:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1774
train_sample_count: 1774
avg_envstep_per_episode: 354.8
avg_sample_per_episode: 354.8
avg_envstep_per_sec: 503.8733555201588
avg_train_sample_per_sec: 503.8733555201588
avg_episode_per_sec: 1.4201616559192751
collect_time: 3.5207259533869646
reward_mean: 2084.60009765625
reward_std: 459.69061279296875
reward_max: 2603.0
reward_min: 1305.0
total_envstep_count: 1017473
total_train_sample_count: 1017436
total_episode_count: 5311
total_duration: 2028.9842315758099
[2022-12-21 16:20:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 386
train_sample_count: 386
avg_envstep_per_episode: 193.0
avg_sample_per_episode: 193.0
avg_envstep_per_sec: 492.76469608579174
avg_train_sample_per_sec: 492.76469608579174
avg_episode_per_sec: 2.5531849538123925
collect_time: 0.7833353384813029
reward_mean: 1175.5
reward_std: 137.5
reward_max: 1313.0
reward_min: 1038.0
total_envstep_count: 1018472
total_train_sample_count: 1018422
total_episode_count: 5313
total_duration: 2029.7675669142911
[2022-12-21 16:20:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 864
train_sample_count: 864
avg_envstep_per_episode: 432.0
avg_sample_per_episode: 432.0
avg_envstep_per_sec: 500.7128138014597
avg_train_sample_per_sec: 500.7128138014597
avg_episode_per_sec: 1.1590574393552306
collect_time: 1.725540022513962
reward_mean: 2451.5
reward_std: 557.5
reward_max: 3009.0
reward_min: 1894.0
total_envstep_count: 1019455
total_train_sample_count: 1019394
total_episode_count: 5315
total_duration: 2031.4931069368051
[2022-12-21 16:21:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1403
train_sample_count: 1403
avg_envstep_per_episode: 350.75
avg_sample_per_episode: 350.75
avg_envstep_per_sec: 504.18716797758054
avg_train_sample_per_sec: 504.18716797758054
avg_episode_per_sec: 1.4374545059945276
collect_time: 2.7826967624499055
reward_mean: 1998.75
reward_std: 191.31175231933594
reward_max: 2330.0
reward_min: 1881.0
total_envstep_count: 1020403
total_train_sample_count: 1020365
total_episode_count: 5319
total_duration: 2034.275803699255
[2022-12-21 16:21:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 314
train_sample_count: 314
avg_envstep_per_episode: 314.0
avg_sample_per_episode: 314.0
avg_envstep_per_sec: 508.81705682438684
avg_train_sample_per_sec: 508.81705682438684
avg_episode_per_sec: 1.6204364867018688
collect_time: 0.6171176767534623
reward_mean: 1892.0
reward_std: 0.0
reward_max: 1892.0
reward_min: 1892.0
total_envstep_count: 1021362
total_train_sample_count: 1021327
total_episode_count: 5320
total_duration: 2034.8929213760084
[2022-12-21 16:21:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 701
train_sample_count: 701
avg_envstep_per_episode: 350.5
avg_sample_per_episode: 350.5
avg_envstep_per_sec: 502.6964823662723
avg_train_sample_per_sec: 502.6964823662723
avg_episode_per_sec: 1.434226768520035
collect_time: 1.394479620585928
reward_mean: 2136.0
reward_std: 469.0
reward_max: 2605.0
reward_min: 1667.0
total_envstep_count: 1022536
total_train_sample_count: 1022484
total_episode_count: 5322
total_duration: 2036.2874009965944
[2022-12-21 16:21:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1172
train_sample_count: 1172
avg_envstep_per_episode: 293.0
avg_sample_per_episode: 293.0
avg_envstep_per_sec: 499.6161225450074
avg_train_sample_per_sec: 499.6161225450074
avg_episode_per_sec: 1.7051744796757933
collect_time: 2.345801000235779
reward_mean: 1772.5
reward_std: 855.0770263671875
reward_max: 3016.0
reward_min: 626.0
total_envstep_count: 1023493
total_train_sample_count: 1023452
total_episode_count: 5326
total_duration: 2038.6332019968302
[2022-12-21 16:21:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1265
train_sample_count: 1265
avg_envstep_per_episode: 421.6666666666667
avg_sample_per_episode: 421.6666666666667
avg_envstep_per_sec: 504.1703620244029
avg_train_sample_per_sec: 504.1703620244029
avg_episode_per_sec: 1.1956609376072795
collect_time: 2.50907251850471
reward_mean: 2118.333251953125
reward_std: 814.0963745117188
reward_max: 3005.0
reward_min: 1039.0
total_envstep_count: 1024458
total_train_sample_count: 1024429
total_episode_count: 5329
total_duration: 2041.142274515335
[2022-12-21 16:21:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 649
train_sample_count: 649
avg_envstep_per_episode: 216.33333333333334
avg_sample_per_episode: 216.33333333333334
avg_envstep_per_sec: 506.74873133700686
avg_train_sample_per_sec: 506.74873133700686
avg_episode_per_sec: 2.342444058568599
collect_time: 1.280713615774976
reward_mean: 1262.6666259765625
reward_std: 324.19061279296875
reward_max: 1552.0
reward_min: 810.0
total_envstep_count: 1025447
total_train_sample_count: 1025402
total_episode_count: 5332
total_duration: 2042.42298813111
[2022-12-21 16:21:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 451
train_sample_count: 451
avg_envstep_per_episode: 225.5
avg_sample_per_episode: 225.5
avg_envstep_per_sec: 506.8291122505744
avg_train_sample_per_sec: 506.8291122505744
avg_episode_per_sec: 2.24757921175421
collect_time: 0.8898462797398018
reward_mean: 1471.5
reward_std: 423.5
reward_max: 1895.0
reward_min: 1048.0
total_envstep_count: 1026430
total_train_sample_count: 1026381
total_episode_count: 5334
total_duration: 2043.31283441085
[2022-12-21 16:21:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1014
train_sample_count: 1014
avg_envstep_per_episode: 338.0
avg_sample_per_episode: 338.0
avg_envstep_per_sec: 508.00796110837496
avg_train_sample_per_sec: 508.00796110837496
avg_episode_per_sec: 1.5029821334567306
collect_time: 1.996031711368555
reward_mean: 2054.666748046875
reward_std: 401.0289611816406
reward_max: 2607.0
reward_min: 1667.0
total_envstep_count: 1027420
total_train_sample_count: 1027383
total_episode_count: 5337
total_duration: 2045.3088661222184
[2022-12-21 16:21:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 203
train_sample_count: 203
avg_envstep_per_episode: 203.0
avg_sample_per_episode: 203.0
avg_envstep_per_sec: 516.3985583350947
avg_train_sample_per_sec: 516.3985583350947
avg_episode_per_sec: 2.543835262734457
collect_time: 0.393107216748409
reward_mean: 1319.0
reward_std: 0.0
reward_max: 1319.0
reward_min: 1319.0
total_envstep_count: 1028483
total_train_sample_count: 1028450
total_episode_count: 5338
total_duration: 2045.7019733389668
[2022-12-21 16:21:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1794
train_sample_count: 1794
avg_envstep_per_episode: 448.5
avg_sample_per_episode: 448.5
avg_envstep_per_sec: 509.9564186481242
avg_train_sample_per_sec: 509.9564186481242
avg_episode_per_sec: 1.1370265744662746
collect_time: 3.5179476802269267
reward_mean: 2373.75
reward_std: 412.55084228515625
reward_max: 3005.0
reward_min: 1848.0
total_envstep_count: 1029474
total_train_sample_count: 1029440
total_episode_count: 5342
total_duration: 2049.219921019194
[2022-12-21 16:21:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2619
train_sample_count: 2619
avg_envstep_per_episode: 873.0
avg_sample_per_episode: 873.0
avg_envstep_per_sec: 506.73920627292614
avg_train_sample_per_sec: 506.73920627292614
avg_episode_per_sec: 0.5804572809540964
collect_time: 5.168338994850588
reward_mean: 1898.3333740234375
reward_std: 893.7957153320312
reward_max: 2586.0
reward_min: 636.0
total_envstep_count: 1030431
total_train_sample_count: 1030403
total_episode_count: 5345
total_duration: 2054.3882600140446
[2022-12-21 16:21:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1224
train_sample_count: 1224
avg_envstep_per_episode: 306.0
avg_sample_per_episode: 306.0
avg_envstep_per_sec: 515.8344847661964
avg_train_sample_per_sec: 515.8344847661964
avg_episode_per_sec: 1.685733610347047
collect_time: 2.372854154089333
reward_mean: 1712.75
reward_std: 456.1175231933594
reward_max: 2315.0
reward_min: 1038.0
total_envstep_count: 1031412
total_train_sample_count: 1031375
total_episode_count: 5349
total_duration: 2056.761114168134
[2022-12-21 16:21:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 773
train_sample_count: 773
avg_envstep_per_episode: 386.5
avg_sample_per_episode: 386.5
avg_envstep_per_sec: 516.1468790714347
avg_train_sample_per_sec: 516.1468790714347
avg_episode_per_sec: 1.3354382382184597
collect_time: 1.4976357144513837
reward_mean: 2074.5
reward_std: 245.5
reward_max: 2320.0
reward_min: 1829.0
total_envstep_count: 1032410
total_train_sample_count: 1032364
total_episode_count: 5351
total_duration: 2058.2587498825856
[2022-12-21 16:21:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 748
train_sample_count: 748
avg_envstep_per_episode: 374.0
avg_sample_per_episode: 374.0
avg_envstep_per_sec: 505.569484603978
avg_train_sample_per_sec: 505.569484603978
avg_episode_per_sec: 1.3517900657860376
collect_time: 1.4795196758877216
reward_mean: 2086.0
reward_std: 237.0
reward_max: 2323.0
reward_min: 1849.0
total_envstep_count: 1033560
total_train_sample_count: 1033520
total_episode_count: 5353
total_duration: 2059.7382695584733
[2022-12-21 16:21:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1485
train_sample_count: 1485
avg_envstep_per_episode: 297.0
avg_sample_per_episode: 297.0
avg_envstep_per_sec: 507.39258772097907
avg_train_sample_per_sec: 507.39258772097907
avg_episode_per_sec: 1.7083925512490878
collect_time: 2.926727815772938
reward_mean: 1655.199951171875
reward_std: 1010.2709350585938
reward_max: 3021.0
reward_min: 231.0
total_envstep_count: 1034547
total_train_sample_count: 1034501
total_episode_count: 5358
total_duration: 2062.6649973742465
[2022-12-21 16:21:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 602
train_sample_count: 602
avg_envstep_per_episode: 301.0
avg_sample_per_episode: 301.0
avg_envstep_per_sec: 505.74518968194207
avg_train_sample_per_sec: 505.74518968194207
avg_episode_per_sec: 1.6802165770164188
collect_time: 1.1903227401502159
reward_mean: 1820.0
reward_std: 783.0
reward_max: 2603.0
reward_min: 1037.0
total_envstep_count: 1035513
total_train_sample_count: 1035487
total_episode_count: 5360
total_duration: 2063.855320114397
[2022-12-21 16:21:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 812
train_sample_count: 812
avg_envstep_per_episode: 270.6666666666667
avg_sample_per_episode: 270.6666666666667
avg_envstep_per_sec: 498.7694136982729
avg_train_sample_per_sec: 498.7694136982729
avg_episode_per_sec: 1.8427441392793333
collect_time: 1.6280068057485453
reward_mean: 1619.0
reward_std: 243.0528106689453
reward_max: 1891.0
reward_min: 1301.0
total_envstep_count: 1036510
total_train_sample_count: 1036455
total_episode_count: 5363
total_duration: 2065.4833269201454
[2022-12-21 16:22:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1262
train_sample_count: 1262
avg_envstep_per_episode: 420.6666666666667
avg_sample_per_episode: 420.6666666666667
avg_envstep_per_sec: 496.9041857970456
avg_train_sample_per_sec: 496.9041857970456
avg_episode_per_sec: 1.1812302356506632
collect_time: 2.539725033661617
reward_mean: 2061.333251953125
reward_std: 685.25146484375
reward_max: 2972.0
reward_min: 1319.0
total_envstep_count: 1037476
total_train_sample_count: 1037429
total_episode_count: 5366
total_duration: 2068.0230519538068
[2022-12-21 16:22:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 439
train_sample_count: 439
avg_envstep_per_episode: 219.5
avg_sample_per_episode: 219.5
avg_envstep_per_sec: 497.4826656219742
avg_train_sample_per_sec: 497.4826656219742
avg_episode_per_sec: 2.266435834268675
collect_time: 0.8824428072305662
reward_mean: 1355.0
reward_std: 322.0
reward_max: 1677.0
reward_min: 1033.0
total_envstep_count: 1038442
total_train_sample_count: 1038396
total_episode_count: 5368
total_duration: 2068.9054947610375
[2022-12-21 16:22:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1002
train_sample_count: 1002
avg_envstep_per_episode: 501.0
avg_sample_per_episode: 501.0
avg_envstep_per_sec: 499.83904260190724
avg_train_sample_per_sec: 499.83904260190724
avg_episode_per_sec: 0.9976827197642859
collect_time: 2.004645324991219
reward_mean: 2816.0
reward_std: 194.0
reward_max: 3010.0
reward_min: 2622.0
total_envstep_count: 1039400
total_train_sample_count: 1039362
total_episode_count: 5370
total_duration: 2070.9101400860286
[2022-12-21 16:22:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 474
train_sample_count: 474
avg_envstep_per_episode: 237.0
avg_sample_per_episode: 237.0
avg_envstep_per_sec: 491.1950313014231
avg_train_sample_per_sec: 491.1950313014231
avg_episode_per_sec: 2.0725528746895487
collect_time: 0.9649934746777369
reward_mean: 1426.5
reward_std: 390.5
reward_max: 1817.0
reward_min: 1036.0
total_envstep_count: 1040358
total_train_sample_count: 1040328
total_episode_count: 5372
total_duration: 2071.875133560706
[2022-12-21 16:22:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1641
train_sample_count: 1641
avg_envstep_per_episode: 410.25
avg_sample_per_episode: 410.25
avg_envstep_per_sec: 431.90323967245297
avg_train_sample_per_sec: 431.90323967245297
avg_episode_per_sec: 1.052780596398423
collect_time: 3.7994621231470793
reward_mean: 2350.75
reward_std: 475.5456848144531
reward_max: 3004.0
reward_min: 1896.0
total_envstep_count: 1041354
total_train_sample_count: 1041309
total_episode_count: 5376
total_duration: 2075.674595683853
[2022-12-21 16:22:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1494
train_sample_count: 1494
avg_envstep_per_episode: 498.0
avg_sample_per_episode: 498.0
avg_envstep_per_sec: 493.1795827345871
avg_train_sample_per_sec: 493.1795827345871
avg_episode_per_sec: 0.990320447258207
collect_time: 3.029322486782713
reward_mean: 1808.6666259765625
reward_std: 377.69683837890625
reward_max: 2222.0
reward_min: 1309.0
total_envstep_count: 1042343
total_train_sample_count: 1042311
total_episode_count: 5379
total_duration: 2078.703918170636
[2022-12-21 16:22:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 539
train_sample_count: 539
avg_envstep_per_episode: 269.5
avg_sample_per_episode: 269.5
avg_envstep_per_sec: 502.7567568939374
avg_train_sample_per_sec: 502.7567568939374
avg_episode_per_sec: 1.865516723168599
collect_time: 1.0720890223932058
reward_mean: 1717.0
reward_std: 164.0
reward_max: 1881.0
reward_min: 1553.0
total_envstep_count: 1043301
total_train_sample_count: 1043282
total_episode_count: 5381
total_duration: 2079.7760071930293
[2022-12-21 16:22:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1814
train_sample_count: 1814
avg_envstep_per_episode: 362.8
avg_sample_per_episode: 362.8
avg_envstep_per_sec: 496.56995563371936
avg_train_sample_per_sec: 496.56995563371936
avg_episode_per_sec: 1.3687154234667016
collect_time: 3.6530603179263736
reward_mean: 2083.60009765625
reward_std: 458.46246337890625
reward_max: 2615.0
reward_min: 1319.0
total_envstep_count: 1044329
total_train_sample_count: 1044304
total_episode_count: 5386
total_duration: 2083.4290675109555
[2022-12-21 16:22:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 283
train_sample_count: 283
avg_envstep_per_episode: 283.0
avg_sample_per_episode: 283.0
avg_envstep_per_sec: 500.1342924402578
avg_train_sample_per_sec: 500.1342924402578
avg_episode_per_sec: 1.7672589838878368
collect_time: 0.5658480217766811
reward_mean: 1848.0
reward_std: 0.0
reward_max: 1848.0
reward_min: 1848.0
total_envstep_count: 1045305
total_train_sample_count: 1045271
total_episode_count: 5387
total_duration: 2083.994915532732
[2022-12-21 16:22:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 290
train_sample_count: 290
avg_envstep_per_episode: 290.0
avg_sample_per_episode: 290.0
avg_envstep_per_sec: 506.78791229377015
avg_train_sample_per_sec: 506.78791229377015
avg_episode_per_sec: 1.7475445251509316
collect_time: 0.572231485726312
reward_mean: 1833.0
reward_std: 0.0
reward_max: 1833.0
reward_min: 1833.0
total_envstep_count: 1046272
total_train_sample_count: 1046233
total_episode_count: 5388
total_duration: 2084.5671470184584
[2022-12-21 16:22:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 885
train_sample_count: 885
avg_envstep_per_episode: 442.5
avg_sample_per_episode: 442.5
avg_envstep_per_sec: 508.9755085225649
avg_train_sample_per_sec: 508.9755085225649
avg_episode_per_sec: 1.1502271379041014
collect_time: 1.7387870048382976
reward_mean: 2325.5
reward_std: 6.5
reward_max: 2332.0
reward_min: 2319.0
total_envstep_count: 1047231
total_train_sample_count: 1047202
total_episode_count: 5390
total_duration: 2086.3059340232967
[2022-12-21 16:22:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2030
train_sample_count: 2030
avg_envstep_per_episode: 507.5
avg_sample_per_episode: 507.5
avg_envstep_per_sec: 508.6370355834161
avg_train_sample_per_sec: 508.6370355834161
avg_episode_per_sec: 1.0022404642037757
collect_time: 3.9910581770192026
reward_mean: 2320.0
reward_std: 462.5527038574219
reward_max: 2979.0
reward_min: 1671.0
total_envstep_count: 1048243
total_train_sample_count: 1048188
total_episode_count: 5394
total_duration: 2090.296992200316
[2022-12-21 16:22:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1315
train_sample_count: 1315
avg_envstep_per_episode: 328.75
avg_sample_per_episode: 328.75
avg_envstep_per_sec: 514.0883158252644
avg_train_sample_per_sec: 514.0883158252644
avg_episode_per_sec: 1.5637667401528959
collect_time: 2.557926254147664
reward_mean: 1952.0
reward_std: 771.3232421875
reward_max: 3010.0
reward_min: 1047.0
total_envstep_count: 1049217
total_train_sample_count: 1049179
total_episode_count: 5398
total_duration: 2092.8549184544636
[2022-12-21 16:22:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 752
train_sample_count: 752
avg_envstep_per_episode: 250.66666666666666
avg_sample_per_episode: 250.66666666666666
avg_envstep_per_sec: 515.3446845685371
avg_train_sample_per_sec: 515.3446845685371
avg_episode_per_sec: 2.055896348012781
collect_time: 1.45921753443445
reward_mean: 1453.3333740234375
reward_std: 579.9088134765625
reward_max: 1894.0
reward_min: 634.0
total_envstep_count: 1050215
total_train_sample_count: 1050171
total_episode_count: 5401
total_duration: 2094.314135988898
[2022-12-21 16:23:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 288
train_sample_count: 288
avg_envstep_per_episode: 288.0
avg_sample_per_episode: 288.0
avg_envstep_per_sec: 500.5920670524004
avg_train_sample_per_sec: 500.5920670524004
avg_episode_per_sec: 1.7381668994875015
collect_time: 0.5753187454523786
reward_mean: 1849.0
reward_std: 0.0
reward_max: 1849.0
reward_min: 1849.0
total_envstep_count: 1051175
total_train_sample_count: 1051131
total_episode_count: 5402
total_duration: 2094.8894547343507
[2022-12-21 16:23:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 833
train_sample_count: 833
avg_envstep_per_episode: 416.5
avg_sample_per_episode: 416.5
avg_envstep_per_sec: 507.2534717081669
avg_train_sample_per_sec: 507.2534717081669
avg_episode_per_sec: 1.2178954902957189
collect_time: 1.6421770307355168
reward_mean: 2453.0
reward_std: 560.0
reward_max: 3013.0
reward_min: 1893.0
total_envstep_count: 1052133
total_train_sample_count: 1052096
total_episode_count: 5404
total_duration: 2096.5316317650863
[2022-12-21 16:23:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1340
train_sample_count: 1340
avg_envstep_per_episode: 446.6666666666667
avg_sample_per_episode: 446.6666666666667
avg_envstep_per_sec: 508.07283450410483
avg_train_sample_per_sec: 508.07283450410483
avg_episode_per_sec: 1.1374764951584437
collect_time: 2.637417135887382
reward_mean: 2405.666748046875
reward_std: 453.4654235839844
reward_max: 2995.0
reward_min: 1892.0
total_envstep_count: 1053147
total_train_sample_count: 1053100
total_episode_count: 5407
total_duration: 2099.169048900974
[2022-12-21 16:23:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 875
train_sample_count: 875
avg_envstep_per_episode: 437.5
avg_sample_per_episode: 437.5
avg_envstep_per_sec: 501.17937518161796
avg_train_sample_per_sec: 501.17937518161796
avg_episode_per_sec: 1.1455528575579839
collect_time: 1.7458819004331863
reward_mean: 2158.0
reward_std: 832.0
reward_max: 2990.0
reward_min: 1326.0
total_envstep_count: 1054129
total_train_sample_count: 1054071
total_episode_count: 5409
total_duration: 2100.914930801407
[2022-12-21 16:23:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1729
train_sample_count: 1729
avg_envstep_per_episode: 432.25
avg_sample_per_episode: 432.25
avg_envstep_per_sec: 502.74856458576136
avg_train_sample_per_sec: 502.74856458576136
avg_episode_per_sec: 1.163096737040512
collect_time: 3.4390948513689064
reward_mean: 2334.75
reward_std: 469.9624328613281
reward_max: 3008.0
reward_min: 1679.0
total_envstep_count: 1055111
total_train_sample_count: 1055056
total_episode_count: 5413
total_duration: 2104.354025652776
[2022-12-21 16:23:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 312
train_sample_count: 312
avg_envstep_per_episode: 156.0
avg_sample_per_episode: 156.0
avg_envstep_per_sec: 491.1187689176029
avg_train_sample_per_sec: 491.1187689176029
avg_episode_per_sec: 3.1481972366513005
collect_time: 0.6352842117755544
reward_mean: 952.0
reward_std: 363.0
reward_max: 1315.0
reward_min: 589.0
total_envstep_count: 1056077
total_train_sample_count: 1056052
total_episode_count: 5415
total_duration: 2104.989309864551
[2022-12-21 16:23:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1333
train_sample_count: 1333
avg_envstep_per_episode: 444.3333333333333
avg_sample_per_episode: 444.3333333333333
avg_envstep_per_sec: 502.4567065027639
avg_train_sample_per_sec: 502.4567065027639
avg_episode_per_sec: 1.1308102922042698
collect_time: 2.6529648878169914
reward_mean: 2427.666748046875
reward_std: 559.2651977539062
reward_max: 3010.0
reward_min: 1673.0
total_envstep_count: 1057058
total_train_sample_count: 1057025
total_episode_count: 5418
total_duration: 2107.642274752368
[2022-12-21 16:23:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1518
train_sample_count: 1518
avg_envstep_per_episode: 303.6
avg_sample_per_episode: 303.6
avg_envstep_per_sec: 505.4984926886398
avg_train_sample_per_sec: 505.4984926886398
avg_episode_per_sec: 1.6650147980521732
collect_time: 3.002976313393297
reward_mean: 1782.4000244140625
reward_std: 591.6331787109375
reward_max: 2610.0
reward_min: 758.0
total_envstep_count: 1058055
total_train_sample_count: 1058015
total_episode_count: 5423
total_duration: 2110.6452510657614
[2022-12-21 16:23:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 746
train_sample_count: 746
avg_envstep_per_episode: 248.66666666666666
avg_sample_per_episode: 248.66666666666666
avg_envstep_per_sec: 511.45914741874253
avg_train_sample_per_sec: 511.45914741874253
avg_episode_per_sec: 2.056806222863576
collect_time: 1.458572016484503
reward_mean: 1431.6666259765625
reward_std: 174.3948211669922
reward_max: 1678.0
reward_min: 1298.0
total_envstep_count: 1059020
total_train_sample_count: 1058989
total_episode_count: 5426
total_duration: 2112.103823082246
[2022-12-21 16:23:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 163
train_sample_count: 163
avg_envstep_per_episode: 163.0
avg_sample_per_episode: 163.0
avg_envstep_per_sec: 505.5100680785551
avg_train_sample_per_sec: 505.5100680785551
avg_episode_per_sec: 3.1012887612181292
collect_time: 0.32244659462384867
reward_mean: 811.0
reward_std: 0.0
reward_max: 811.0
reward_min: 811.0
total_envstep_count: 1059987
total_train_sample_count: 1059968
total_episode_count: 5427
total_duration: 2112.4262696768697
[2022-12-21 16:23:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1453
train_sample_count: 1453
avg_envstep_per_episode: 290.6
avg_sample_per_episode: 290.6
avg_envstep_per_sec: 509.1883814179051
avg_train_sample_per_sec: 509.1883814179051
avg_episode_per_sec: 1.752196770192378
collect_time: 2.8535607901223545
reward_mean: 1710.199951171875
reward_std: 752.3641357421875
reward_max: 2608.0
reward_min: 589.0
total_envstep_count: 1060999
total_train_sample_count: 1060965
total_episode_count: 5432
total_duration: 2115.279830466992
[2022-12-21 16:23:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 751
train_sample_count: 751
avg_envstep_per_episode: 375.5
avg_sample_per_episode: 375.5
avg_envstep_per_sec: 515.2195562370388
avg_train_sample_per_sec: 515.2195562370388
avg_episode_per_sec: 1.3720893641465746
collect_time: 1.4576310058667201
reward_mean: 2026.5
reward_std: 980.5
reward_max: 3007.0
reward_min: 1046.0
total_envstep_count: 1061958
total_train_sample_count: 1061932
total_episode_count: 5434
total_duration: 2116.7374614728587
[2022-12-21 16:23:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 316
train_sample_count: 316
avg_envstep_per_episode: 316.0
avg_sample_per_episode: 316.0
avg_envstep_per_sec: 506.88434873282904
avg_train_sample_per_sec: 506.88434873282904
avg_episode_per_sec: 1.6040643947241426
collect_time: 0.6234163686252596
reward_mean: 1823.0
reward_std: 0.0
reward_max: 1823.0
reward_min: 1823.0
total_envstep_count: 1062933
total_train_sample_count: 1062896
total_episode_count: 5435
total_duration: 2117.360877841484
[2022-12-21 16:23:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1418
train_sample_count: 1418
avg_envstep_per_episode: 472.6666666666667
avg_sample_per_episode: 472.6666666666667
avg_envstep_per_sec: 509.5451855114097
avg_train_sample_per_sec: 509.5451855114097
avg_episode_per_sec: 1.0780222542554507
collect_time: 2.7828739046504998
reward_mean: 1956.0
reward_std: 1003.084228515625
reward_max: 2978.0
reward_min: 593.0
total_envstep_count: 1063892
total_train_sample_count: 1063870
total_episode_count: 5438
total_duration: 2120.1437517461345
[2022-12-21 16:23:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1446
train_sample_count: 1446
avg_envstep_per_episode: 361.5
avg_sample_per_episode: 361.5
avg_envstep_per_sec: 510.2717838414188
avg_train_sample_per_sec: 510.2717838414188
avg_episode_per_sec: 1.4115402042639524
collect_time: 2.8337839672698517
reward_mean: 1986.25
reward_std: 833.8781127929688
reward_max: 3009.0
reward_min: 718.0
total_envstep_count: 1064891
total_train_sample_count: 1064848
total_episode_count: 5442
total_duration: 2122.9775357134044
[2022-12-21 16:24:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1270
train_sample_count: 1270
avg_envstep_per_episode: 423.3333333333333
avg_sample_per_episode: 423.3333333333333
avg_envstep_per_sec: 515.8797336214116
avg_train_sample_per_sec: 515.8797336214116
avg_episode_per_sec: 1.2186135439875863
collect_time: 2.4618140958644723
reward_mean: 1740.3333740234375
reward_std: 788.0822143554688
reward_max: 2315.0
reward_min: 626.0
total_envstep_count: 1065848
total_train_sample_count: 1065818
total_episode_count: 5445
total_duration: 2125.439349809269
[2022-12-21 16:24:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 812
train_sample_count: 812
avg_envstep_per_episode: 270.6666666666667
avg_sample_per_episode: 270.6666666666667
avg_envstep_per_sec: 515.0336581645039
avg_train_sample_per_sec: 515.0336581645039
avg_episode_per_sec: 1.902833712430433
collect_time: 1.576595989655969
reward_mean: 1698.0
reward_std: 202.3660125732422
reward_max: 1850.0
reward_min: 1412.0
total_envstep_count: 1066862
total_train_sample_count: 1066822
total_episode_count: 5448
total_duration: 2127.015945798925
[2022-12-21 16:24:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 732
train_sample_count: 732
avg_envstep_per_episode: 366.0
avg_sample_per_episode: 366.0
avg_envstep_per_sec: 498.89959151770915
avg_train_sample_per_sec: 498.89959151770915
avg_episode_per_sec: 1.3631136380265276
collect_time: 1.4672291027001505
reward_mean: 2087.0
reward_std: 238.0
reward_max: 2325.0
reward_min: 1849.0
total_envstep_count: 1067837
total_train_sample_count: 1067782
total_episode_count: 5450
total_duration: 2128.483174901625
[2022-12-21 16:24:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 731
train_sample_count: 731
avg_envstep_per_episode: 365.5
avg_sample_per_episode: 365.5
avg_envstep_per_sec: 495.10636648775153
avg_train_sample_per_sec: 495.10636648775153
avg_episode_per_sec: 1.354600181909033
collect_time: 1.4764504144546973
reward_mean: 2087.0
reward_std: 239.0
reward_max: 2326.0
reward_min: 1848.0
total_envstep_count: 1068805
total_train_sample_count: 1068765
total_episode_count: 5452
total_duration: 2129.9596253160794
[2022-12-21 16:24:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1554
train_sample_count: 1554
avg_envstep_per_episode: 310.8
avg_sample_per_episode: 310.8
avg_envstep_per_sec: 489.2187903115931
avg_train_sample_per_sec: 489.2187903115931
avg_episode_per_sec: 1.5740630318905828
collect_time: 3.1764928714414804
reward_mean: 1555.5999755859375
reward_std: 834.4570922851562
reward_max: 2594.0
reward_min: 581.0
total_envstep_count: 1069776
total_train_sample_count: 1069755
total_episode_count: 5457
total_duration: 2133.136118187521
[2022-12-21 16:24:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 960
train_sample_count: 960
avg_envstep_per_episode: 320.0
avg_sample_per_episode: 320.0
avg_envstep_per_sec: 492.005361916077
avg_train_sample_per_sec: 492.005361916077
avg_episode_per_sec: 1.5375167559877407
collect_time: 1.9511982476397287
reward_mean: 2035.0
reward_std: 410.2324523925781
reward_max: 2609.0
reward_min: 1675.0
total_envstep_count: 1070766
total_train_sample_count: 1070739
total_episode_count: 5460
total_duration: 2135.0873164351606
[2022-12-21 16:24:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 528
train_sample_count: 528
avg_envstep_per_episode: 528.0
avg_sample_per_episode: 528.0
avg_envstep_per_sec: 488.7989759344413
avg_train_sample_per_sec: 488.7989759344413
avg_episode_per_sec: 0.9257556362394721
collect_time: 1.0801986624268551
reward_mean: 3016.0
reward_std: 0.0
reward_max: 3016.0
reward_min: 3016.0
total_envstep_count: 1072014
total_train_sample_count: 1071987
total_episode_count: 5461
total_duration: 2136.1675150975875
[2022-12-21 16:24:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 653
train_sample_count: 653
avg_envstep_per_episode: 326.5
avg_sample_per_episode: 326.5
avg_envstep_per_sec: 490.8523790062023
avg_train_sample_per_sec: 490.8523790062023
avg_episode_per_sec: 1.503376352239517
collect_time: 1.3303388715810804
reward_mean: 1864.0
reward_std: 24.0
reward_max: 1888.0
reward_min: 1840.0
total_envstep_count: 1072988
total_train_sample_count: 1072952
total_episode_count: 5463
total_duration: 2137.497853969169
[2022-12-21 16:24:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2380
train_sample_count: 2380
avg_envstep_per_episode: 340.0
avg_sample_per_episode: 340.0
avg_envstep_per_sec: 496.74108906350517
avg_train_sample_per_sec: 496.74108906350517
avg_episode_per_sec: 1.4610032031279563
collect_time: 4.791228373088606
reward_mean: 1845.2857666015625
reward_std: 994.6973876953125
reward_max: 3021.0
reward_min: 579.0
total_envstep_count: 1074007
total_train_sample_count: 1073964
total_episode_count: 5470
total_duration: 2142.289082342257
[2022-12-21 16:25:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 423
train_sample_count: 423
avg_envstep_per_episode: 211.5
avg_sample_per_episode: 211.5
avg_envstep_per_sec: 505.3903579776339
avg_train_sample_per_sec: 505.3903579776339
avg_episode_per_sec: 2.389552519988813
collect_time: 0.8369767909555565
reward_mean: 1260.5
reward_std: 630.5
reward_max: 1891.0
reward_min: 630.0
total_envstep_count: 1074965
total_train_sample_count: 1074927
total_episode_count: 5472
total_duration: 2143.126059133213
[2022-12-21 16:25:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1186
train_sample_count: 1186
avg_envstep_per_episode: 395.3333333333333
avg_sample_per_episode: 395.3333333333333
avg_envstep_per_sec: 503.5640212183332
avg_train_sample_per_sec: 503.5640212183332
avg_episode_per_sec: 1.2737707113448564
collect_time: 2.355211949278201
reward_mean: 2079.666748046875
reward_std: 666.3494262695312
reward_max: 2986.0
reward_min: 1403.0
total_envstep_count: 1075946
total_train_sample_count: 1075897
total_episode_count: 5475
total_duration: 2145.4812710824913
[2022-12-21 16:25:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 509
train_sample_count: 509
avg_envstep_per_episode: 254.5
avg_sample_per_episode: 254.5
avg_envstep_per_sec: 504.3392757074364
avg_train_sample_per_sec: 504.3392757074364
avg_episode_per_sec: 1.9816867414830506
collect_time: 1.0092412479397446
reward_mean: 1601.0
reward_std: 282.0
reward_max: 1883.0
reward_min: 1319.0
total_envstep_count: 1076920
total_train_sample_count: 1076874
total_episode_count: 5477
total_duration: 2146.490512330431
[2022-12-21 16:25:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1891
train_sample_count: 1891
avg_envstep_per_episode: 236.375
avg_sample_per_episode: 236.375
avg_envstep_per_sec: 508.3340597169644
avg_train_sample_per_sec: 508.3340597169644
avg_episode_per_sec: 2.1505407074223775
collect_time: 3.7199946843083675
reward_mean: 1449.5
reward_std: 805.2130126953125
reward_max: 2609.0
reward_min: 231.0
total_envstep_count: 1077939
total_train_sample_count: 1077901
total_episode_count: 5485
total_duration: 2150.2105070147395
[2022-12-21 16:25:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 285
train_sample_count: 285
avg_envstep_per_episode: 285.0
avg_sample_per_episode: 285.0
avg_envstep_per_sec: 494.83471455510477
avg_train_sample_per_sec: 494.83471455510477
avg_episode_per_sec: 1.736262156333701
collect_time: 0.5759498911798
reward_mean: 1822.0
reward_std: 0.0
reward_max: 1822.0
reward_min: 1822.0
total_envstep_count: 1078906
total_train_sample_count: 1078870
total_episode_count: 5486
total_duration: 2150.7864569059193
[2022-12-21 16:25:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1489
train_sample_count: 1489
avg_envstep_per_episode: 297.8
avg_sample_per_episode: 297.8
avg_envstep_per_sec: 441.94496992206405
avg_train_sample_per_sec: 441.94496992206405
avg_episode_per_sec: 1.4840328069914843
collect_time: 3.36919775388004
reward_mean: 1707.199951171875
reward_std: 354.3390197753906
reward_max: 2311.0
reward_min: 1315.0
total_envstep_count: 1079902
total_train_sample_count: 1079867
total_episode_count: 5491
total_duration: 2154.1556546597994
[2022-12-21 16:25:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 98
train_sample_count: 98
avg_envstep_per_episode: 98.0
avg_sample_per_episode: 98.0
avg_envstep_per_sec: 525.8352077386302
avg_train_sample_per_sec: 525.8352077386302
avg_episode_per_sec: 5.365665385088063
collect_time: 0.1863701755944641
reward_mean: 626.0
reward_std: 0.0
reward_max: 626.0
reward_min: 626.0
total_envstep_count: 1080877
total_train_sample_count: 1080829
total_episode_count: 5492
total_duration: 2154.342024835394
[2022-12-21 16:25:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1469
train_sample_count: 1469
avg_envstep_per_episode: 293.8
avg_sample_per_episode: 293.8
avg_envstep_per_sec: 509.50093154191387
avg_train_sample_per_sec: 509.50093154191387
avg_episode_per_sec: 1.734176077406106
collect_time: 2.8832135704920754
reward_mean: 1722.4000244140625
reward_std: 631.2053833007812
reward_max: 2587.0
reward_min: 626.0
total_envstep_count: 1081857
total_train_sample_count: 1081806
total_episode_count: 5497
total_duration: 2157.225238405886
[2022-12-21 16:25:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 580
train_sample_count: 580
avg_envstep_per_episode: 290.0
avg_sample_per_episode: 290.0
avg_envstep_per_sec: 507.8915641326665
avg_train_sample_per_sec: 507.8915641326665
avg_episode_per_sec: 1.7513502211471257
collect_time: 1.141976045596414
reward_mean: 1823.5
reward_std: 784.5
reward_max: 2608.0
reward_min: 1039.0
total_envstep_count: 1082817
total_train_sample_count: 1082782
total_episode_count: 5499
total_duration: 2158.3672144514826
[2022-12-21 16:25:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 637
train_sample_count: 637
avg_envstep_per_episode: 637.0
avg_sample_per_episode: 637.0
avg_envstep_per_sec: 508.6879277523393
avg_train_sample_per_sec: 508.6879277523393
avg_episode_per_sec: 0.7985681754353835
collect_time: 1.2522412372053204
reward_mean: 2994.0
reward_std: 0.0
reward_max: 2994.0
reward_min: 2994.0
total_envstep_count: 1083776
total_train_sample_count: 1083743
total_episode_count: 5500
total_duration: 2159.619455688688
[2022-12-21 16:25:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1522
train_sample_count: 1522
avg_envstep_per_episode: 380.5
avg_sample_per_episode: 380.5
avg_envstep_per_sec: 513.4322377467946
avg_train_sample_per_sec: 513.4322377467946
avg_episode_per_sec: 1.349361991450183
collect_time: 2.96436391816634
reward_mean: 2157.5
reward_std: 483.888671875
reward_max: 2995.0
reward_min: 1848.0
total_envstep_count: 1084796
total_train_sample_count: 1084737
total_episode_count: 5504
total_duration: 2162.5838196068544
[2022-12-21 16:25:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1360
train_sample_count: 1360
avg_envstep_per_episode: 453.3333333333333
avg_sample_per_episode: 453.3333333333333
avg_envstep_per_sec: 511.80896011337194
avg_train_sample_per_sec: 511.80896011337194
avg_episode_per_sec: 1.1289903531912615
collect_time: 2.6572414826398183
reward_mean: 2502.666748046875
reward_std: 463.3532409667969
reward_max: 3001.0
reward_min: 1885.0
total_envstep_count: 1085754
total_train_sample_count: 1085713
total_episode_count: 5507
total_duration: 2165.241061089494
[2022-12-21 16:25:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 128
train_sample_count: 128
avg_envstep_per_episode: 128.0
avg_sample_per_episode: 128.0
avg_envstep_per_sec: 504.7703030259657
avg_train_sample_per_sec: 504.7703030259657
avg_episode_per_sec: 3.943517992390357
collect_time: 0.25358068656708516
reward_mean: 719.0
reward_std: 0.0
reward_max: 719.0
reward_min: 719.0
total_envstep_count: 1086729
total_train_sample_count: 1086693
total_episode_count: 5508
total_duration: 2165.494641776061
[2022-12-21 16:25:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1993
train_sample_count: 1993
avg_envstep_per_episode: 332.1666666666667
avg_sample_per_episode: 332.1666666666667
avg_envstep_per_sec: 510.62256333118944
avg_train_sample_per_sec: 510.62256333118944
avg_episode_per_sec: 1.5372480581972587
collect_time: 3.9030786007537657
reward_mean: 1972.3333740234375
reward_std: 836.8619384765625
reward_max: 3003.0
reward_min: 627.0
total_envstep_count: 1087707
total_train_sample_count: 1087678
total_episode_count: 5514
total_duration: 2169.397720376815
[2022-12-21 16:25:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1003
train_sample_count: 1003
avg_envstep_per_episode: 250.75
avg_sample_per_episode: 250.75
avg_envstep_per_sec: 494.8592738111801
avg_train_sample_per_sec: 494.8592738111801
avg_episode_per_sec: 1.9735165456078967
collect_time: 2.0268388470834386
reward_mean: 1337.25
reward_std: 968.3047485351562
reward_max: 3013.0
reward_min: 714.0
total_envstep_count: 1088704
total_train_sample_count: 1088657
total_episode_count: 5518
total_duration: 2171.4245592238985
[2022-12-21 16:25:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 807
train_sample_count: 807
avg_envstep_per_episode: 403.5
avg_sample_per_episode: 403.5
avg_envstep_per_sec: 500.74768869761715
avg_train_sample_per_sec: 500.74768869761715
avg_episode_per_sec: 1.241010380911071
collect_time: 1.6115900646469428
reward_mean: 2243.0
reward_std: 354.0
reward_max: 2597.0
reward_min: 1889.0
total_envstep_count: 1089670
total_train_sample_count: 1089620
total_episode_count: 5520
total_duration: 2173.0361492885454
[2022-12-21 16:25:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1150
train_sample_count: 1150
avg_envstep_per_episode: 287.5
avg_sample_per_episode: 287.5
avg_envstep_per_sec: 498.1378387803435
avg_train_sample_per_sec: 498.1378387803435
avg_episode_per_sec: 1.7326533522794556
collect_time: 2.3085979631976894
reward_mean: 1867.0
reward_std: 331.37591552734375
reward_max: 2343.0
reward_min: 1409.0
total_envstep_count: 1090650
total_train_sample_count: 1090614
total_episode_count: 5524
total_duration: 2175.3447472517432
[2022-12-21 16:25:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 517
train_sample_count: 517
avg_envstep_per_episode: 258.5
avg_sample_per_episode: 258.5
avg_envstep_per_sec: 507.00366287984707
avg_train_sample_per_sec: 507.00366287984707
avg_episode_per_sec: 1.9613294502121743
collect_time: 1.0197164988185143
reward_mean: 1604.0
reward_std: 287.0
reward_max: 1891.0
reward_min: 1317.0
total_envstep_count: 1091624
total_train_sample_count: 1091599
total_episode_count: 5526
total_duration: 2176.3644637505618
[2022-12-21 16:26:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 649
train_sample_count: 649
avg_envstep_per_episode: 324.5
avg_sample_per_episode: 324.5
avg_envstep_per_sec: 511.3790572061238
avg_train_sample_per_sec: 511.3790572061238
avg_episode_per_sec: 1.5758984813748036
collect_time: 1.269117283655996
reward_mean: 1961.0
reward_std: 644.0
reward_max: 2605.0
reward_min: 1317.0
total_envstep_count: 1092614
total_train_sample_count: 1092572
total_episode_count: 5528
total_duration: 2177.633581034218
[2022-12-21 16:26:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 304
train_sample_count: 304
avg_envstep_per_episode: 304.0
avg_sample_per_episode: 304.0
avg_envstep_per_sec: 503.20324665823654
avg_train_sample_per_sec: 503.20324665823654
avg_episode_per_sec: 1.6552738376915674
collect_time: 0.6041296474513199
reward_mean: 1891.0
reward_std: 0.0
reward_max: 1891.0
reward_min: 1891.0
total_envstep_count: 1093581
total_train_sample_count: 1093536
total_episode_count: 5529
total_duration: 2178.2377106816693
[2022-12-21 16:26:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1403
train_sample_count: 1403
avg_envstep_per_episode: 467.6666666666667
avg_sample_per_episode: 467.6666666666667
avg_envstep_per_sec: 504.58919636565616
avg_train_sample_per_sec: 504.58919636565616
avg_episode_per_sec: 1.078950526797554
collect_time: 2.7804796656472615
reward_mean: 2387.0
reward_std: 472.2379455566406
reward_max: 2998.0
reward_min: 1848.0
total_envstep_count: 1094564
total_train_sample_count: 1094519
total_episode_count: 5532
total_duration: 2181.0181903473167
[2022-12-21 16:26:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1222
train_sample_count: 1222
avg_envstep_per_episode: 407.3333333333333
avg_sample_per_episode: 407.3333333333333
avg_envstep_per_sec: 503.83166976982864
avg_train_sample_per_sec: 503.83166976982864
avg_episode_per_sec: 1.236902626276175
collect_time: 2.42541323485731
reward_mean: 2356.333251953125
reward_std: 933.6317138671875
reward_max: 3023.0
reward_min: 1036.0
total_envstep_count: 1095521
total_train_sample_count: 1095489
total_episode_count: 5535
total_duration: 2183.443603582174
[2022-12-21 16:26:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 507
train_sample_count: 507
avg_envstep_per_episode: 507.0
avg_sample_per_episode: 507.0
avg_envstep_per_sec: 505.4205926738998
avg_train_sample_per_sec: 505.4205926738998
avg_episode_per_sec: 0.9968847981733724
collect_time: 1.0031249366349408
reward_mean: 2589.0
reward_std: 0.0
reward_max: 2589.0
reward_min: 2589.0
total_envstep_count: 1096496
total_train_sample_count: 1096452
total_episode_count: 5536
total_duration: 2184.446728518809
[2022-12-21 16:26:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1297
train_sample_count: 1297
avg_envstep_per_episode: 648.5
avg_sample_per_episode: 648.5
avg_envstep_per_sec: 502.08921070825716
avg_train_sample_per_sec: 502.08921070825716
avg_episode_per_sec: 0.7742316279232955
collect_time: 2.583206275574864
reward_mean: 2992.0
reward_std: 22.0
reward_max: 3014.0
reward_min: 2970.0
total_envstep_count: 1097454
total_train_sample_count: 1097413
total_episode_count: 5538
total_duration: 2187.0299347943837
[2022-12-21 16:26:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1221
train_sample_count: 1221
avg_envstep_per_episode: 407.0
avg_sample_per_episode: 407.0
avg_envstep_per_sec: 502.70563059958886
avg_train_sample_per_sec: 502.70563059958886
avg_episode_per_sec: 1.2351489695321594
collect_time: 2.428856821324409
reward_mean: 2413.666748046875
reward_std: 462.40264892578125
reward_max: 3016.0
reward_min: 1892.0
total_envstep_count: 1098420
total_train_sample_count: 1098382
total_episode_count: 5541
total_duration: 2189.458791615708
[2022-12-21 16:26:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1036
train_sample_count: 1036
avg_envstep_per_episode: 345.3333333333333
avg_sample_per_episode: 345.3333333333333
avg_envstep_per_sec: 494.9658363306227
avg_train_sample_per_sec: 494.9658363306227
avg_episode_per_sec: 1.4332987538531545
collect_time: 2.0930737516760294
reward_mean: 1957.3333740234375
reward_std: 809.5930786132812
reward_max: 3008.0
reward_min: 1038.0
total_envstep_count: 1099434
total_train_sample_count: 1099394
total_episode_count: 5544
total_duration: 2191.551865367384
[2022-12-21 16:26:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1465
train_sample_count: 1465
avg_envstep_per_episode: 488.3333333333333
avg_sample_per_episode: 488.3333333333333
avg_envstep_per_sec: 501.5565224665352
avg_train_sample_per_sec: 501.5565224665352
avg_episode_per_sec: 1.0270782030031438
collect_time: 2.920907084999074
reward_mean: 2634.0
reward_std: 526.1387939453125
reward_max: 3015.0
reward_min: 1890.0
total_envstep_count: 1100391
total_train_sample_count: 1100355
total_episode_count: 5547
total_duration: 2194.472772452383
[2022-12-21 16:26:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1085
train_sample_count: 1085
avg_envstep_per_episode: 271.25
avg_sample_per_episode: 271.25
avg_envstep_per_sec: 503.5794083618023
avg_train_sample_per_sec: 503.5794083618023
avg_episode_per_sec: 1.856513947877612
collect_time: 2.1545757868250037
reward_mean: 1714.0
reward_std: 600.80029296875
reward_max: 2607.0
reward_min: 1037.0
total_envstep_count: 1101372
total_train_sample_count: 1101320
total_episode_count: 5551
total_duration: 2196.627348239208
[2022-12-21 16:26:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1266
train_sample_count: 1266
avg_envstep_per_episode: 253.2
avg_sample_per_episode: 253.2
avg_envstep_per_sec: 504.4471239722282
avg_train_sample_per_sec: 504.4471239722282
avg_episode_per_sec: 1.9922872194795742
collect_time: 2.509678298948332
reward_mean: 1610.800048828125
reward_std: 499.6376037597656
reward_max: 2607.0
reward_min: 1317.0
total_envstep_count: 1102344
total_train_sample_count: 1102310
total_episode_count: 5556
total_duration: 2199.1370265381565
[2022-12-21 16:26:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 206.66666666666666
avg_sample_per_episode: 206.66666666666666
avg_envstep_per_sec: 495.8646780395796
avg_train_sample_per_sec: 495.8646780395796
avg_episode_per_sec: 2.3993452163205466
collect_time: 1.25034112623467
reward_mean: 1327.6666259765625
reward_std: 496.1614990234375
reward_max: 1682.0
reward_min: 626.0
total_envstep_count: 1103318
total_train_sample_count: 1103290
total_episode_count: 5559
total_duration: 2200.387367664391
[2022-12-21 16:26:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 854
train_sample_count: 854
avg_envstep_per_episode: 213.5
avg_sample_per_episode: 213.5
avg_envstep_per_sec: 493.15306114640464
avg_train_sample_per_sec: 493.15306114640464
avg_episode_per_sec: 2.3098504034960405
collect_time: 1.7317138780701375
reward_mean: 1290.75
reward_std: 269.4043273925781
reward_max: 1675.0
reward_min: 1028.0
total_envstep_count: 1104338
total_train_sample_count: 1104288
total_episode_count: 5563
total_duration: 2202.119081542461
[2022-12-21 16:26:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 429
train_sample_count: 429
avg_envstep_per_episode: 214.5
avg_sample_per_episode: 214.5
avg_envstep_per_sec: 500.11001549341785
avg_train_sample_per_sec: 500.11001549341785
avg_episode_per_sec: 2.3315152237455377
collect_time: 0.8578112549430561
reward_mean: 1361.0
reward_std: 314.0
reward_max: 1675.0
reward_min: 1047.0
total_envstep_count: 1105304
total_train_sample_count: 1105269
total_episode_count: 5565
total_duration: 2202.976892797404
[2022-12-21 16:26:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1088
train_sample_count: 1088
avg_envstep_per_episode: 544.0
avg_sample_per_episode: 544.0
avg_envstep_per_sec: 503.3853328369418
avg_train_sample_per_sec: 503.3853328369418
avg_episode_per_sec: 0.9253406853620254
collect_time: 2.1613661126523693
reward_mean: 2799.5
reward_std: 190.5
reward_max: 2990.0
reward_min: 2609.0
total_envstep_count: 1106327
total_train_sample_count: 1106273
total_episode_count: 5567
total_duration: 2205.1382589100567
[2022-12-21 16:26:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 875
train_sample_count: 875
avg_envstep_per_episode: 437.5
avg_sample_per_episode: 437.5
avg_envstep_per_sec: 502.32791158276694
avg_train_sample_per_sec: 502.32791158276694
avg_episode_per_sec: 1.148178083617753
collect_time: 1.7418900678701965
reward_mean: 2467.5
reward_std: 135.5
reward_max: 2603.0
reward_min: 2332.0
total_envstep_count: 1107286
total_train_sample_count: 1107244
total_episode_count: 5569
total_duration: 2206.880148977927
[2022-12-21 16:26:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1762
train_sample_count: 1762
avg_envstep_per_episode: 440.5
avg_sample_per_episode: 440.5
avg_envstep_per_sec: 497.9377133561955
avg_train_sample_per_sec: 497.9377133561955
avg_episode_per_sec: 1.130392084804076
collect_time: 3.538595195217857
reward_mean: 2526.25
reward_std: 400.57232666015625
reward_max: 3008.0
reward_min: 1895.0
total_envstep_count: 1108274
total_train_sample_count: 1108238
total_episode_count: 5573
total_duration: 2210.418744173145
[2022-12-21 16:26:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 203
train_sample_count: 203
avg_envstep_per_episode: 203.0
avg_sample_per_episode: 203.0
avg_envstep_per_sec: 501.2212454052175
avg_train_sample_per_sec: 501.2212454052175
avg_episode_per_sec: 2.4690701744099384
collect_time: 0.4050107649285348
reward_mean: 1320.0
reward_std: 0.0
reward_max: 1320.0
reward_min: 1320.0
total_envstep_count: 1109241
total_train_sample_count: 1109209
total_episode_count: 5574
total_duration: 2210.8237549380738
[2022-12-21 16:27:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1655
train_sample_count: 1655
avg_envstep_per_episode: 413.75
avg_sample_per_episode: 413.75
avg_envstep_per_sec: 500.52763191592993
avg_train_sample_per_sec: 500.52763191592993
avg_episode_per_sec: 1.2097344578028517
collect_time: 3.306510758786597
reward_mean: 2269.0
reward_std: 562.5037841796875
reward_max: 2993.0
reward_min: 1413.0
total_envstep_count: 1110199
total_train_sample_count: 1110180
total_episode_count: 5578
total_duration: 2214.1302656968605
[2022-12-21 16:27:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 961
train_sample_count: 961
avg_envstep_per_episode: 320.3333333333333
avg_sample_per_episode: 320.3333333333333
avg_envstep_per_sec: 499.87106647222316
avg_train_sample_per_sec: 499.87106647222316
avg_episode_per_sec: 1.5604715914845675
collect_time: 1.9224957483179332
reward_mean: 1947.6666259765625
reward_std: 279.5190124511719
reward_max: 2334.0
reward_min: 1682.0
total_envstep_count: 1111198
total_train_sample_count: 1111165
total_episode_count: 5581
total_duration: 2216.0527614451785
[2022-12-21 16:27:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 631
train_sample_count: 631
avg_envstep_per_episode: 315.5
avg_sample_per_episode: 315.5
avg_envstep_per_sec: 502.7836684053202
avg_train_sample_per_sec: 502.7836684053202
avg_episode_per_sec: 1.5936090916174965
collect_time: 1.2550129203705915
reward_mean: 1819.0
reward_std: 780.0
reward_max: 2599.0
reward_min: 1039.0
total_envstep_count: 1112188
total_train_sample_count: 1112156
total_episode_count: 5583
total_duration: 2217.307774365549
[2022-12-21 16:27:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 385
train_sample_count: 385
avg_envstep_per_episode: 192.5
avg_sample_per_episode: 192.5
avg_envstep_per_sec: 488.96194935489234
avg_train_sample_per_sec: 488.96194935489234
avg_episode_per_sec: 2.5400620745708693
collect_time: 0.787382332117962
reward_mean: 1058.5
reward_std: 247.5
reward_max: 1306.0
reward_min: 811.0
total_envstep_count: 1113170
total_train_sample_count: 1113141
total_episode_count: 5585
total_duration: 2218.095156697667
[2022-12-21 16:27:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1674
train_sample_count: 1674
avg_envstep_per_episode: 418.5
avg_sample_per_episode: 418.5
avg_envstep_per_sec: 496.75615387613715
avg_train_sample_per_sec: 496.75615387613715
avg_episode_per_sec: 1.186992004483004
collect_time: 3.369862631671395
reward_mean: 2310.75
reward_std: 754.390869140625
reward_max: 3010.0
reward_min: 1037.0
total_envstep_count: 1114200
total_train_sample_count: 1114167
total_episode_count: 5589
total_duration: 2221.4650193293382
[2022-12-21 16:27:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1281
train_sample_count: 1281
avg_envstep_per_episode: 427.0
avg_sample_per_episode: 427.0
avg_envstep_per_sec: 494.413412488021
avg_train_sample_per_sec: 494.413412488021
avg_episode_per_sec: 1.157876844234241
collect_time: 2.5909491280862795
reward_mean: 2503.333251953125
reward_std: 466.2562255859375
reward_max: 3023.0
reward_min: 1892.0
total_envstep_count: 1115183
total_train_sample_count: 1115136
total_episode_count: 5592
total_duration: 2224.0559684574246
[2022-12-21 16:27:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 163
train_sample_count: 163
avg_envstep_per_episode: 163.0
avg_sample_per_episode: 163.0
avg_envstep_per_sec: 418.72677067530265
avg_train_sample_per_sec: 418.72677067530265
avg_episode_per_sec: 2.568875893713513
collect_time: 0.3892753256189504
reward_mean: 1038.0
reward_std: 0.0
reward_max: 1038.0
reward_min: 1038.0
total_envstep_count: 1116143
total_train_sample_count: 1116103
total_episode_count: 5593
total_duration: 2224.4452437830437
[2022-12-21 16:27:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 291
train_sample_count: 291
avg_envstep_per_episode: 291.0
avg_sample_per_episode: 291.0
avg_envstep_per_sec: 454.731960551471
avg_train_sample_per_sec: 454.731960551471
avg_episode_per_sec: 1.5626527854002439
collect_time: 0.6399374252187884
reward_mean: 1833.0
reward_std: 0.0
reward_max: 1833.0
reward_min: 1833.0
total_envstep_count: 1117103
total_train_sample_count: 1117066
total_episode_count: 5594
total_duration: 2225.0851812082624
[2022-12-21 16:27:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2588
train_sample_count: 2588
avg_envstep_per_episode: 369.7142857142857
avg_sample_per_episode: 369.7142857142857
avg_envstep_per_sec: 467.3528573365667
avg_train_sample_per_sec: 467.3528573365667
avg_episode_per_sec: 1.2640919634296626
collect_time: 5.537571792647109
reward_mean: 2126.428466796875
reward_std: 698.2688598632812
reward_max: 3011.0
reward_min: 1133.0
total_envstep_count: 1118130
total_train_sample_count: 1118106
total_episode_count: 5601
total_duration: 2230.6227530009096
[2022-12-21 16:27:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 802
train_sample_count: 802
avg_envstep_per_episode: 401.0
avg_sample_per_episode: 401.0
avg_envstep_per_sec: 476.1860064736739
avg_train_sample_per_sec: 476.1860064736739
avg_episode_per_sec: 1.1874962754954461
collect_time: 1.684215808732168
reward_mean: 2016.5
reward_std: 978.5
reward_max: 2995.0
reward_min: 1038.0
total_envstep_count: 1119113
total_train_sample_count: 1119076
total_episode_count: 5603
total_duration: 2232.3069688096416
[2022-12-21 16:27:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 973
train_sample_count: 973
avg_envstep_per_episode: 243.25
avg_sample_per_episode: 243.25
avg_envstep_per_sec: 492.9679058860662
avg_train_sample_per_sec: 492.9679058860662
avg_episode_per_sec: 2.026589541155462
collect_time: 1.9737593226299763
reward_mean: 1468.25
reward_std: 440.1331481933594
reward_max: 1890.0
reward_min: 811.0
total_envstep_count: 1120093
total_train_sample_count: 1120049
total_episode_count: 5607
total_duration: 2234.2807281322716
[2022-12-21 16:27:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 839
train_sample_count: 839
avg_envstep_per_episode: 279.6666666666667
avg_sample_per_episode: 279.6666666666667
avg_envstep_per_sec: 502.3737780979949
avg_train_sample_per_sec: 502.3737780979949
avg_episode_per_sec: 1.7963305533897314
collect_time: 1.670071242922917
reward_mean: 1556.6666259765625
reward_std: 557.2158813476562
reward_max: 2329.0
reward_min: 1035.0
total_envstep_count: 1121074
total_train_sample_count: 1121044
total_episode_count: 5610
total_duration: 2235.9507993751945
[2022-12-21 16:27:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 498
train_sample_count: 498
avg_envstep_per_episode: 249.0
avg_sample_per_episode: 249.0
avg_envstep_per_sec: 506.39694660341274
avg_train_sample_per_sec: 506.39694660341274
avg_episode_per_sec: 2.0337226771221397
collect_time: 0.983418251907453
reward_mean: 1442.5
reward_std: 404.5
reward_max: 1847.0
reward_min: 1038.0
total_envstep_count: 1122048
total_train_sample_count: 1122010
total_episode_count: 5612
total_duration: 2236.934217627102
[2022-12-21 16:27:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 754
train_sample_count: 754
avg_envstep_per_episode: 377.0
avg_sample_per_episode: 377.0
avg_envstep_per_sec: 501.92589388453905
avg_train_sample_per_sec: 501.92589388453905
avg_episode_per_sec: 1.3313684187918806
collect_time: 1.5022137912921605
reward_mean: 2219.0
reward_std: 385.0
reward_max: 2604.0
reward_min: 1834.0
total_envstep_count: 1123031
total_train_sample_count: 1122992
total_episode_count: 5614
total_duration: 2238.436431418394
[2022-12-21 16:27:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1178
train_sample_count: 1178
avg_envstep_per_episode: 589.0
avg_sample_per_episode: 589.0
avg_envstep_per_sec: 501.3401322582655
avg_train_sample_per_sec: 501.3401322582655
avg_episode_per_sec: 0.8511717016269363
collect_time: 2.349702176631559
reward_mean: 2652.0
reward_std: 318.0
reward_max: 2970.0
reward_min: 2334.0
total_envstep_count: 1124005
total_train_sample_count: 1123978
total_episode_count: 5616
total_duration: 2240.7861335950256
[2022-12-21 16:27:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1346
train_sample_count: 1346
avg_envstep_per_episode: 448.6666666666667
avg_sample_per_episode: 448.6666666666667
avg_envstep_per_sec: 493.7388798772547
avg_train_sample_per_sec: 493.7388798772547
avg_episode_per_sec: 1.1004581275124548
collect_time: 2.726137346798819
reward_mean: 2337.666748046875
reward_std: 667.845458984375
reward_max: 2990.0
reward_min: 1420.0
total_envstep_count: 1125035
total_train_sample_count: 1125000
total_episode_count: 5619
total_duration: 2243.512270941824
[2022-12-21 16:27:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1185
train_sample_count: 1185
avg_envstep_per_episode: 237.0
avg_sample_per_episode: 237.0
avg_envstep_per_sec: 484.0797888792228
avg_train_sample_per_sec: 484.0797888792228
avg_episode_per_sec: 2.042530754764653
collect_time: 2.4479435564612175
reward_mean: 1338.800048828125
reward_std: 926.5640869140625
reward_max: 3008.0
reward_min: 231.0
total_envstep_count: 1126015
total_train_sample_count: 1125993
total_episode_count: 5624
total_duration: 2245.9602144982855
[2022-12-21 16:27:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1536
train_sample_count: 1536
avg_envstep_per_episode: 384.0
avg_sample_per_episode: 384.0
avg_envstep_per_sec: 487.11296340809787
avg_train_sample_per_sec: 487.11296340809787
avg_episode_per_sec: 1.2685233422085882
collect_time: 3.153272680844579
reward_mean: 2116.5
reward_std: 902.2960815429688
reward_max: 3018.0
reward_min: 1041.0
total_envstep_count: 1126995
total_train_sample_count: 1126965
total_episode_count: 5628
total_duration: 2249.11348717913
[2022-12-21 16:27:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 98
train_sample_count: 98
avg_envstep_per_episode: 98.0
avg_sample_per_episode: 98.0
avg_envstep_per_sec: 486.8156737906456
avg_train_sample_per_sec: 486.8156737906456
avg_episode_per_sec: 4.967506875414751
collect_time: 0.20130822665776527
reward_mean: 626.0
reward_std: 0.0
reward_max: 626.0
reward_min: 626.0
total_envstep_count: 1127954
total_train_sample_count: 1127927
total_episode_count: 5629
total_duration: 2249.3147954057877
[2022-12-21 16:28:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 163
train_sample_count: 163
avg_envstep_per_episode: 163.0
avg_sample_per_episode: 163.0
avg_envstep_per_sec: 508.4949806721554
avg_train_sample_per_sec: 508.4949806721554
avg_episode_per_sec: 3.1196011084181317
collect_time: 0.32055380327360955
reward_mean: 1038.0
reward_std: 0.0
reward_max: 1038.0
reward_min: 1038.0
total_envstep_count: 1128937
total_train_sample_count: 1128894
total_episode_count: 5630
total_duration: 2249.635349209061
[2022-12-21 16:28:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1718
train_sample_count: 1718
avg_envstep_per_episode: 429.5
avg_sample_per_episode: 429.5
avg_envstep_per_sec: 490.0233792231687
avg_train_sample_per_sec: 490.0233792231687
avg_episode_per_sec: 1.1409159004031868
collect_time: 3.5059551703911263
reward_mean: 2164.0
reward_std: 855.8338012695312
reward_max: 2995.0
reward_min: 740.0
total_envstep_count: 1129909
total_train_sample_count: 1129868
total_episode_count: 5634
total_duration: 2253.1413043794523
[2022-12-21 16:28:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 618
train_sample_count: 618
avg_envstep_per_episode: 618.0
avg_sample_per_episode: 618.0
avg_envstep_per_sec: 487.1215915514161
avg_train_sample_per_sec: 487.1215915514161
avg_episode_per_sec: 0.7882226400508351
collect_time: 1.268677083337148
reward_mean: 2998.0
reward_std: 0.0
reward_max: 2998.0
reward_min: 2998.0
total_envstep_count: 1130877
total_train_sample_count: 1130834
total_episode_count: 5635
total_duration: 2254.4099814627893
[2022-12-21 16:28:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1025
train_sample_count: 1025
avg_envstep_per_episode: 341.6666666666667
avg_sample_per_episode: 341.6666666666667
avg_envstep_per_sec: 489.7970960126493
avg_train_sample_per_sec: 489.7970960126493
avg_episode_per_sec: 1.4335524761345833
collect_time: 2.092703301722983
reward_mean: 1999.3333740234375
reward_std: 729.4072265625
reward_max: 3011.0
reward_min: 1319.0
total_envstep_count: 1131874
total_train_sample_count: 1131835
total_episode_count: 5638
total_duration: 2256.502684764512
[2022-12-21 16:28:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1392
train_sample_count: 1392
avg_envstep_per_episode: 464.0
avg_sample_per_episode: 464.0
avg_envstep_per_sec: 495.9609174089344
avg_train_sample_per_sec: 495.9609174089344
avg_episode_per_sec: 1.068881287519255
collect_time: 2.806672766217696
reward_mean: 2258.666748046875
reward_std: 1048.41162109375
reward_max: 3005.0
reward_min: 776.0
total_envstep_count: 1132887
total_train_sample_count: 1132855
total_episode_count: 5641
total_duration: 2259.30935753073
[2022-12-21 16:28:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 944
train_sample_count: 944
avg_envstep_per_episode: 472.0
avg_sample_per_episode: 472.0
avg_envstep_per_sec: 494.0917060337579
avg_train_sample_per_sec: 494.0917060337579
avg_episode_per_sec: 1.0468044619359276
collect_time: 1.9105764951567574
reward_mean: 2812.5
reward_std: 205.5
reward_max: 3018.0
reward_min: 2607.0
total_envstep_count: 1133885
total_train_sample_count: 1133847
total_episode_count: 5643
total_duration: 2261.2199340258867
[2022-12-21 16:28:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 990
train_sample_count: 990
avg_envstep_per_episode: 330.0
avg_sample_per_episode: 330.0
avg_envstep_per_sec: 500.71323144528645
avg_train_sample_per_sec: 500.71323144528645
avg_episode_per_sec: 1.517312822561474
collect_time: 1.9771796266346089
reward_mean: 1881.0
reward_std: 927.97021484375
reward_max: 3013.0
reward_min: 740.0
total_envstep_count: 1134858
total_train_sample_count: 1134813
total_episode_count: 5646
total_duration: 2263.1971136525212
[2022-12-21 16:28:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 377
train_sample_count: 377
avg_envstep_per_episode: 377.0
avg_sample_per_episode: 377.0
avg_envstep_per_sec: 502.84660130471616
avg_train_sample_per_sec: 502.84660130471616
avg_episode_per_sec: 1.3338106135403611
collect_time: 0.7497316259507631
reward_mean: 2339.0
reward_std: 0.0
reward_max: 2339.0
reward_min: 2339.0
total_envstep_count: 1135825
total_train_sample_count: 1135778
total_episode_count: 5647
total_duration: 2263.946845278472
[2022-12-21 16:28:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1962
train_sample_count: 1962
avg_envstep_per_episode: 490.5
avg_sample_per_episode: 490.5
avg_envstep_per_sec: 506.45555528364565
avg_train_sample_per_sec: 506.45555528364565
avg_episode_per_sec: 1.0325291646965253
collect_time: 3.8739825825410517
reward_mean: 2583.0
reward_std: 730.4114990234375
reward_max: 3020.0
reward_min: 1318.0
total_envstep_count: 1136805
total_train_sample_count: 1136768
total_episode_count: 5651
total_duration: 2267.820827861013
[2022-12-21 16:28:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 427
train_sample_count: 427
avg_envstep_per_episode: 427.0
avg_sample_per_episode: 427.0
avg_envstep_per_sec: 505.04782574876305
avg_train_sample_per_sec: 505.04782574876305
avg_episode_per_sec: 1.1827817933226301
collect_time: 0.8454644852038466
reward_mean: 2609.0
reward_std: 0.0
reward_max: 2609.0
reward_min: 2609.0
total_envstep_count: 1138260
total_train_sample_count: 1138215
total_episode_count: 5652
total_duration: 2268.6662923462172
[2022-12-21 16:28:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2281
train_sample_count: 2281
avg_envstep_per_episode: 456.2
avg_sample_per_episode: 456.2
avg_envstep_per_sec: 498.4453349205373
avg_train_sample_per_sec: 498.4453349205373
avg_episode_per_sec: 1.0926026631313839
collect_time: 4.576229006865195
reward_mean: 2503.39990234375
reward_std: 439.7210998535156
reward_max: 3010.0
reward_min: 1847.0
total_envstep_count: 1139232
total_train_sample_count: 1139200
total_episode_count: 5657
total_duration: 2273.2425213530823
[2022-12-21 16:28:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 715
train_sample_count: 715
avg_envstep_per_episode: 357.5
avg_sample_per_episode: 357.5
avg_envstep_per_sec: 500.99192954076955
avg_train_sample_per_sec: 500.99192954076955
avg_episode_per_sec: 1.4013760266874673
collect_time: 1.4271686984167575
reward_mean: 1812.0
reward_std: 500.0
reward_max: 2312.0
reward_min: 1312.0
total_envstep_count: 1140190
total_train_sample_count: 1140167
total_episode_count: 5659
total_duration: 2274.669690051499
[2022-12-21 16:28:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 645
train_sample_count: 645
avg_envstep_per_episode: 322.5
avg_sample_per_episode: 322.5
avg_envstep_per_sec: 497.63749459208645
avg_train_sample_per_sec: 497.63749459208645
avg_episode_per_sec: 1.5430619987351517
collect_time: 1.2961242008677554
reward_mean: 1702.5
reward_std: 891.5
reward_max: 2594.0
reward_min: 811.0
total_envstep_count: 1141172
total_train_sample_count: 1141136
total_episode_count: 5661
total_duration: 2275.9658142523667
[2022-12-21 16:28:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 789
train_sample_count: 789
avg_envstep_per_episode: 263.0
avg_sample_per_episode: 263.0
avg_envstep_per_sec: 496.7157988487946
avg_train_sample_per_sec: 496.7157988487946
avg_episode_per_sec: 1.8886532275619565
collect_time: 1.5884334700619815
reward_mean: 1596.0
reward_std: 784.1942749023438
reward_max: 2705.0
reward_min: 1036.0
total_envstep_count: 1142177
total_train_sample_count: 1142117
total_episode_count: 5664
total_duration: 2277.5542477224285
[2022-12-21 16:28:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 984
train_sample_count: 984
avg_envstep_per_episode: 328.0
avg_sample_per_episode: 328.0
avg_envstep_per_sec: 498.07082866267393
avg_train_sample_per_sec: 498.07082866267393
avg_episode_per_sec: 1.5185086239715668
collect_time: 1.9756226290988605
reward_mean: 1997.6666259765625
reward_std: 679.2826538085938
reward_max: 2603.0
reward_min: 1049.0
total_envstep_count: 1143143
total_train_sample_count: 1143089
total_episode_count: 5667
total_duration: 2279.5298703515273
[2022-12-21 16:28:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1498
train_sample_count: 1498
avg_envstep_per_episode: 299.6
avg_sample_per_episode: 299.6
avg_envstep_per_sec: 497.5776071880755
avg_train_sample_per_sec: 497.5776071880755
avg_episode_per_sec: 1.6608064325369676
collect_time: 3.0105856420379116
reward_mean: 1538.800048828125
reward_std: 1214.2694091796875
reward_max: 3014.0
reward_min: 231.0
total_envstep_count: 1144100
total_train_sample_count: 1144059
total_episode_count: 5672
total_duration: 2282.540455993565
[2022-12-21 16:28:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 948
train_sample_count: 948
avg_envstep_per_episode: 474.0
avg_sample_per_episode: 474.0
avg_envstep_per_sec: 495.0686356834405
avg_train_sample_per_sec: 495.0686356834405
avg_episode_per_sec: 1.0444485984882712
collect_time: 1.914886000991134
reward_mean: 2812.5
reward_std: 200.5
reward_max: 3013.0
reward_min: 2612.0
total_envstep_count: 1145074
total_train_sample_count: 1145031
total_episode_count: 5674
total_duration: 2284.455341994556
[2022-12-21 16:29:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 524
train_sample_count: 524
avg_envstep_per_episode: 524.0
avg_sample_per_episode: 524.0
avg_envstep_per_sec: 494.0757017709656
avg_train_sample_per_sec: 494.0757017709656
avg_episode_per_sec: 0.9428925606316138
collect_time: 1.0605662211717226
reward_mean: 3017.0
reward_std: 0.0
reward_max: 3017.0
reward_min: 3017.0
total_envstep_count: 1146057
total_train_sample_count: 1146035
total_episode_count: 5675
total_duration: 2285.515908215728
[2022-12-21 16:29:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 687
train_sample_count: 687
avg_envstep_per_episode: 343.5
avg_sample_per_episode: 343.5
avg_envstep_per_sec: 503.06349588050307
avg_train_sample_per_sec: 503.06349588050307
avg_episode_per_sec: 1.4645225498704602
collect_time: 1.3656327792132008
reward_mean: 2114.5
reward_std: 222.5
reward_max: 2337.0
reward_min: 1892.0
total_envstep_count: 1147047
total_train_sample_count: 1146998
total_episode_count: 5677
total_duration: 2286.881540994941
[2022-12-21 16:29:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1120
train_sample_count: 1120
avg_envstep_per_episode: 280.0
avg_sample_per_episode: 280.0
avg_envstep_per_sec: 502.7162456440587
avg_train_sample_per_sec: 502.7162456440587
avg_episode_per_sec: 1.7954151630144952
collect_time: 2.2278969691244086
reward_mean: 1339.0
reward_std: 1111.9244384765625
reward_max: 2579.0
reward_min: 231.0
total_envstep_count: 1148011
total_train_sample_count: 1147974
total_episode_count: 5681
total_duration: 2289.1094379640654
[2022-12-21 16:29:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2400
train_sample_count: 2400
avg_envstep_per_episode: 400.0
avg_sample_per_episode: 400.0
avg_envstep_per_sec: 502.29799072210926
avg_train_sample_per_sec: 502.29799072210926
avg_episode_per_sec: 1.255744976805273
collect_time: 4.778040215828323
reward_mean: 2236.333251953125
reward_std: 671.22314453125
reward_max: 3007.0
reward_min: 1330.0
total_envstep_count: 1149046
total_train_sample_count: 1148994
total_episode_count: 5687
total_duration: 2293.8874781798936
[2022-12-21 16:29:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 290
train_sample_count: 290
avg_envstep_per_episode: 290.0
avg_sample_per_episode: 290.0
avg_envstep_per_sec: 495.19545098228025
avg_train_sample_per_sec: 495.19545098228025
avg_episode_per_sec: 1.7075705206285525
collect_time: 0.5856273506243844
reward_mean: 1838.0
reward_std: 0.0
reward_max: 1838.0
reward_min: 1838.0
total_envstep_count: 1150293
total_train_sample_count: 1150244
total_episode_count: 5688
total_duration: 2294.473105530518
[2022-12-21 16:29:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 895
train_sample_count: 895
avg_envstep_per_episode: 298.3333333333333
avg_sample_per_episode: 298.3333333333333
avg_envstep_per_sec: 500.54532411149563
avg_train_sample_per_sec: 500.54532411149563
avg_episode_per_sec: 1.677805555680991
collect_time: 1.7880498665903835
reward_mean: 1577.0
reward_std: 230.17095947265625
reward_max: 1871.0
reward_min: 1309.0
total_envstep_count: 1151259
total_train_sample_count: 1151223
total_episode_count: 5691
total_duration: 2296.2611553971083
[2022-12-21 16:29:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 622
train_sample_count: 622
avg_envstep_per_episode: 311.0
avg_sample_per_episode: 311.0
avg_envstep_per_sec: 507.0405202695995
avg_train_sample_per_sec: 507.0405202695995
avg_episode_per_sec: 1.630355370641799
collect_time: 1.2267264156112714
reward_mean: 1823.5
reward_std: 776.5
reward_max: 2600.0
reward_min: 1047.0
total_envstep_count: 1152251
total_train_sample_count: 1152193
total_episode_count: 5693
total_duration: 2297.4878818127195
[2022-12-21 16:29:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1404
train_sample_count: 1404
avg_envstep_per_episode: 351.0
avg_sample_per_episode: 351.0
avg_envstep_per_sec: 506.9529893177946
avg_train_sample_per_sec: 506.9529893177946
avg_episode_per_sec: 1.4443105108769076
collect_time: 2.7694875650883515
reward_mean: 1939.75
reward_std: 836.3770751953125
reward_max: 3008.0
reward_min: 743.0
total_envstep_count: 1153240
total_train_sample_count: 1153189
total_episode_count: 5697
total_duration: 2300.2573693778077
[2022-12-21 16:29:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 810
train_sample_count: 810
avg_envstep_per_episode: 405.0
avg_sample_per_episode: 405.0
avg_envstep_per_sec: 499.0213432625912
avg_train_sample_per_sec: 499.0213432625912
avg_episode_per_sec: 1.2321514648459042
collect_time: 1.62317706634397
reward_mean: 2156.5
reward_std: 843.5
reward_max: 3000.0
reward_min: 1313.0
total_envstep_count: 1154199
total_train_sample_count: 1154155
total_episode_count: 5699
total_duration: 2301.8805464441516
[2022-12-21 16:30:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 994
train_sample_count: 994
avg_envstep_per_episode: 331.3333333333333
avg_sample_per_episode: 331.3333333333333
avg_envstep_per_sec: 495.06732350866554
avg_train_sample_per_sec: 495.06732350866554
avg_episode_per_sec: 1.4941669723601576
collect_time: 2.007807731997487
reward_mean: 1936.0
reward_std: 520.4312133789062
reward_max: 2592.0
reward_min: 1319.0
total_envstep_count: 1155180
total_train_sample_count: 1155125
total_episode_count: 5702
total_duration: 2303.8883541761493
[2022-12-21 16:30:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1366
train_sample_count: 1366
avg_envstep_per_episode: 455.3333333333333
avg_sample_per_episode: 455.3333333333333
avg_envstep_per_sec: 496.02468831056467
avg_train_sample_per_sec: 496.02468831056467
avg_episode_per_sec: 1.0893660797450175
collect_time: 2.7538951834283245
reward_mean: 2560.666748046875
reward_std: 316.36407470703125
reward_max: 3008.0
reward_min: 2330.0
total_envstep_count: 1156146
total_train_sample_count: 1156107
total_episode_count: 5705
total_duration: 2306.642249359578
[2022-12-21 16:30:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 873
train_sample_count: 873
avg_envstep_per_episode: 291.0
avg_sample_per_episode: 291.0
avg_envstep_per_sec: 497.09715811400446
avg_train_sample_per_sec: 497.09715811400446
avg_episode_per_sec: 1.7082376567491562
collect_time: 1.7561959181423963
reward_mean: 1735.6666259765625
reward_std: 528.3289794921875
reward_max: 2331.0
reward_min: 1047.0
total_envstep_count: 1157135
total_train_sample_count: 1157100
total_episode_count: 5708
total_duration: 2308.3984452777204
[2022-12-21 16:30:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 390
train_sample_count: 390
avg_envstep_per_episode: 390.0
avg_sample_per_episode: 390.0
avg_envstep_per_sec: 500.9645240041395
avg_train_sample_per_sec: 500.9645240041395
avg_episode_per_sec: 1.2845244205234347
collect_time: 0.7784982395216021
reward_mean: 2340.0
reward_std: 0.0
reward_max: 2340.0
reward_min: 2340.0
total_envstep_count: 1158094
total_train_sample_count: 1158066
total_episode_count: 5709
total_duration: 2309.176943517242
[2022-12-21 16:30:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1452
train_sample_count: 1452
avg_envstep_per_episode: 484.0
avg_sample_per_episode: 484.0
avg_envstep_per_sec: 503.1947352978586
avg_train_sample_per_sec: 503.1947352978586
avg_episode_per_sec: 1.0396585440038402
collect_time: 2.8855627814557923
reward_mean: 2644.666748046875
reward_std: 274.24359130859375
reward_max: 3003.0
reward_min: 2337.0
total_envstep_count: 1159067
total_train_sample_count: 1159038
total_episode_count: 5712
total_duration: 2312.062506298698
[2022-12-21 16:30:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 712
train_sample_count: 712
avg_envstep_per_episode: 356.0
avg_sample_per_episode: 356.0
avg_envstep_per_sec: 501.95318135529766
avg_train_sample_per_sec: 501.95318135529766
avg_episode_per_sec: 1.409980846503645
collect_time: 1.4184589847155982
reward_mean: 1956.5
reward_std: 637.5
reward_max: 2594.0
reward_min: 1319.0
total_envstep_count: 1160050
total_train_sample_count: 1160014
total_episode_count: 5714
total_duration: 2313.4809652834133
[2022-12-21 16:30:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 591
train_sample_count: 591
avg_envstep_per_episode: 591.0
avg_sample_per_episode: 591.0
avg_envstep_per_sec: 500.1419942571201
avg_train_sample_per_sec: 500.1419942571201
avg_episode_per_sec: 0.8462639496736379
collect_time: 1.1816644208767848
reward_mean: 3003.0
reward_std: 0.0
reward_max: 3003.0
reward_min: 3003.0
total_envstep_count: 1161322
total_train_sample_count: 1161289
total_episode_count: 5715
total_duration: 2314.66262970429
[2022-12-21 16:30:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1876
train_sample_count: 1876
avg_envstep_per_episode: 469.0
avg_sample_per_episode: 469.0
avg_envstep_per_sec: 500.1390050617848
avg_train_sample_per_sec: 500.1390050617848
avg_episode_per_sec: 1.0663944670826968
collect_time: 3.750957195926456
reward_mean: 2558.5
reward_std: 471.7968444824219
reward_max: 3012.0
reward_min: 1892.0
total_envstep_count: 1162302
total_train_sample_count: 1162265
total_episode_count: 5719
total_duration: 2318.413586900216
[2022-12-21 16:30:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1743
train_sample_count: 1743
avg_envstep_per_episode: 348.6
avg_sample_per_episode: 348.6
avg_envstep_per_sec: 497.60500277879066
avg_train_sample_per_sec: 497.60500277879066
avg_episode_per_sec: 1.4274383326987683
collect_time: 3.502778288535108
reward_mean: 2040.199951171875
reward_std: 904.260009765625
reward_max: 3025.0
reward_min: 589.0
total_envstep_count: 1163259
total_train_sample_count: 1163252
total_episode_count: 5724
total_duration: 2321.916365188751
[2022-12-21 16:30:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 310
train_sample_count: 310
avg_envstep_per_episode: 310.0
avg_sample_per_episode: 310.0
avg_envstep_per_sec: 485.448822144793
avg_train_sample_per_sec: 485.448822144793
avg_episode_per_sec: 1.565963942402558
collect_time: 0.6385843076729878
reward_mean: 1892.0
reward_std: 0.0
reward_max: 1892.0
reward_min: 1892.0
total_envstep_count: 1164378
total_train_sample_count: 1164318
total_episode_count: 5725
total_duration: 2322.554949496424
[2022-12-21 16:30:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 307
train_sample_count: 307
avg_envstep_per_episode: 307.0
avg_sample_per_episode: 307.0
avg_envstep_per_sec: 496.6096728495922
avg_train_sample_per_sec: 496.6096728495922
avg_episode_per_sec: 1.617621084200626
collect_time: 0.6181917445111482
reward_mean: 1827.0
reward_std: 0.0
reward_max: 1827.0
reward_min: 1827.0
total_envstep_count: 1165433
total_train_sample_count: 1165381
total_episode_count: 5726
total_duration: 2323.173141240935
[2022-12-21 16:30:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1621
train_sample_count: 1621
avg_envstep_per_episode: 540.3333333333334
avg_sample_per_episode: 540.3333333333334
avg_envstep_per_sec: 494.8009892935143
avg_train_sample_per_sec: 494.8009892935143
avg_episode_per_sec: 0.9157328611230987
collect_time: 3.276064589754545
reward_mean: 2778.0
reward_std: 318.92633056640625
reward_max: 3008.0
reward_min: 2327.0
total_envstep_count: 1166406
total_train_sample_count: 1166354
total_episode_count: 5729
total_duration: 2326.4492058306896
[2022-12-21 16:30:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1069
train_sample_count: 1069
avg_envstep_per_episode: 534.5
avg_sample_per_episode: 534.5
avg_envstep_per_sec: 495.1823060607679
avg_train_sample_per_sec: 495.1823060607679
avg_episode_per_sec: 0.9264402358480224
collect_time: 2.1588008838684436
reward_mean: 3015.0
reward_std: 3.0
reward_max: 3018.0
reward_min: 3012.0
total_envstep_count: 1167364
total_train_sample_count: 1167327
total_episode_count: 5731
total_duration: 2328.608006714558
[2022-12-21 16:30:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 747
train_sample_count: 747
avg_envstep_per_episode: 373.5
avg_sample_per_episode: 373.5
avg_envstep_per_sec: 499.2087036535324
avg_train_sample_per_sec: 499.2087036535324
avg_episode_per_sec: 1.3365694876935272
collect_time: 1.4963681412863408
reward_mean: 2209.5
reward_std: 805.5
reward_max: 3015.0
reward_min: 1404.0
total_envstep_count: 1168323
total_train_sample_count: 1168290
total_episode_count: 5733
total_duration: 2330.1043748558445
[2022-12-21 16:30:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 517
train_sample_count: 517
avg_envstep_per_episode: 258.5
avg_sample_per_episode: 258.5
avg_envstep_per_sec: 497.7699693151309
avg_train_sample_per_sec: 497.7699693151309
avg_episode_per_sec: 1.925609165629133
collect_time: 1.0386323640844128
reward_mean: 1651.5
reward_std: 239.5
reward_max: 1891.0
reward_min: 1412.0
total_envstep_count: 1169313
total_train_sample_count: 1169263
total_episode_count: 5735
total_duration: 2331.143007219929
[2022-12-21 16:30:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2161
train_sample_count: 2161
avg_envstep_per_episode: 432.2
avg_sample_per_episode: 432.2
avg_envstep_per_sec: 500.950870759521
avg_train_sample_per_sec: 500.950870759521
avg_episode_per_sec: 1.1590718897721448
collect_time: 4.313796274520056
reward_mean: 2295.39990234375
reward_std: 475.1734924316406
reward_max: 3005.0
reward_min: 1673.0
total_envstep_count: 1170311
total_train_sample_count: 1170272
total_episode_count: 5740
total_duration: 2335.456803494449
[2022-12-21 16:30:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 433
train_sample_count: 433
avg_envstep_per_episode: 144.33333333333334
avg_sample_per_episode: 144.33333333333334
avg_envstep_per_sec: 510.6426015138611
avg_train_sample_per_sec: 510.6426015138611
avg_episode_per_sec: 3.537939502405504
collect_time: 0.8479511868307104
reward_mean: 865.0
reward_std: 461.853515625
reward_max: 1318.0
reward_min: 231.0
total_envstep_count: 1171284
total_train_sample_count: 1171245
total_episode_count: 5743
total_duration: 2336.30475468128
[2022-12-21 16:31:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 657
train_sample_count: 657
avg_envstep_per_episode: 657.0
avg_sample_per_episode: 657.0
avg_envstep_per_sec: 505.42373633570895
avg_train_sample_per_sec: 505.42373633570895
avg_episode_per_sec: 0.7692903140573957
collect_time: 1.2998993770320517
reward_mean: 2990.0
reward_std: 0.0
reward_max: 2990.0
reward_min: 2990.0
total_envstep_count: 1172243
total_train_sample_count: 1172214
total_episode_count: 5744
total_duration: 2337.604654058312
[2022-12-21 16:31:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1167
train_sample_count: 1167
avg_envstep_per_episode: 389.0
avg_sample_per_episode: 389.0
avg_envstep_per_sec: 504.50947299896995
avg_train_sample_per_sec: 504.50947299896995
avg_episode_per_sec: 1.2969395192775577
collect_time: 2.3131379338884734
reward_mean: 2221.333251953125
reward_std: 695.9857788085938
reward_max: 3013.0
reward_min: 1319.0
total_envstep_count: 1173209
total_train_sample_count: 1173189
total_episode_count: 5747
total_duration: 2339.9177919922004
[2022-12-21 16:31:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1124
train_sample_count: 1124
avg_envstep_per_episode: 374.6666666666667
avg_sample_per_episode: 374.6666666666667
avg_envstep_per_sec: 513.4272637610592
avg_train_sample_per_sec: 513.4272637610592
avg_episode_per_sec: 1.3703574655544282
collect_time: 2.189209805038892
reward_mean: 2143.333251953125
reward_std: 956.9271240234375
reward_max: 3015.0
reward_min: 811.0
total_envstep_count: 1174215
total_train_sample_count: 1174169
total_episode_count: 5750
total_duration: 2342.1070017972393
[2022-12-21 16:31:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1195
train_sample_count: 1195
avg_envstep_per_episode: 298.75
avg_sample_per_episode: 298.75
avg_envstep_per_sec: 509.6046735429574
avg_train_sample_per_sec: 509.6046735429574
avg_episode_per_sec: 1.7057897022358406
collect_time: 2.3449549465312485
reward_mean: 1837.25
reward_std: 744.9534301757812
reward_max: 3016.0
reward_min: 1038.0
total_envstep_count: 1175195
total_train_sample_count: 1175148
total_episode_count: 5754
total_duration: 2344.4519567437706
[2022-12-21 16:31:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1148
train_sample_count: 1148
avg_envstep_per_episode: 382.6666666666667
avg_sample_per_episode: 382.6666666666667
avg_envstep_per_sec: 506.8520147385839
avg_train_sample_per_sec: 506.8520147385839
avg_episode_per_sec: 1.3245261709196443
collect_time: 2.2649609089392637
reward_mean: 2046.3333740234375
reward_std: 701.8952026367188
reward_max: 2995.0
reward_min: 1319.0
total_envstep_count: 1176168
total_train_sample_count: 1176116
total_episode_count: 5757
total_duration: 2346.71691765271
[2022-12-21 16:31:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 953
train_sample_count: 953
avg_envstep_per_episode: 238.25
avg_sample_per_episode: 238.25
avg_envstep_per_sec: 506.52078205182636
avg_train_sample_per_sec: 506.52078205182636
avg_episode_per_sec: 2.126005381119943
collect_time: 1.881462782513217
reward_mean: 1364.5
reward_std: 839.5101318359375
reward_max: 2601.0
reward_min: 231.0
total_envstep_count: 1177134
total_train_sample_count: 1177105
total_episode_count: 5761
total_duration: 2348.598380435223
[2022-12-21 16:31:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 461
train_sample_count: 461
avg_envstep_per_episode: 230.5
avg_sample_per_episode: 230.5
avg_envstep_per_sec: 523.2870716222715
avg_train_sample_per_sec: 523.2870716222715
avg_episode_per_sec: 2.2702259072549738
collect_time: 0.8809695958488487
reward_mean: 1464.5
reward_std: 427.5
reward_max: 1892.0
reward_min: 1037.0
total_envstep_count: 1178101
total_train_sample_count: 1178070
total_episode_count: 5763
total_duration: 2349.479350031072
[2022-12-21 16:31:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 543
train_sample_count: 543
avg_envstep_per_episode: 271.5
avg_sample_per_episode: 271.5
avg_envstep_per_sec: 520.5532529655118
avg_train_sample_per_sec: 520.5532529655118
avg_episode_per_sec: 1.917323215342585
collect_time: 1.0431209427788848
reward_mean: 1673.0
reward_std: 1.0
reward_max: 1674.0
reward_min: 1672.0
total_envstep_count: 1179083
total_train_sample_count: 1179045
total_episode_count: 5765
total_duration: 2350.522470973851
[2022-12-21 16:31:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1251
train_sample_count: 1251
avg_envstep_per_episode: 417.0
avg_sample_per_episode: 417.0
avg_envstep_per_sec: 510.6328374668823
avg_train_sample_per_sec: 510.6328374668823
avg_episode_per_sec: 1.2245391785776554
collect_time: 2.4499011975138303
reward_mean: 2182.666748046875
reward_std: 572.9400024414062
reward_max: 2983.0
reward_min: 1673.0
total_envstep_count: 1180057
total_train_sample_count: 1180020
total_episode_count: 5768
total_duration: 2352.972372171365
[2022-12-21 16:31:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1348
train_sample_count: 1348
avg_envstep_per_episode: 337.0
avg_sample_per_episode: 337.0
avg_envstep_per_sec: 519.0348540678416
avg_train_sample_per_sec: 519.0348540678416
avg_episode_per_sec: 1.5401627717146635
collect_time: 2.5971280915632047
reward_mean: 1926.75
reward_std: 915.3191528320312
reward_max: 3015.0
reward_min: 768.0
total_envstep_count: 1181046
total_train_sample_count: 1181008
total_episode_count: 5772
total_duration: 2355.569500262928
[2022-12-21 16:31:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1016
train_sample_count: 1016
avg_envstep_per_episode: 338.6666666666667
avg_sample_per_episode: 338.6666666666667
avg_envstep_per_sec: 510.74223129686493
avg_train_sample_per_sec: 510.74223129686493
avg_episode_per_sec: 1.5080971396560974
collect_time: 1.9892617797047958
reward_mean: 1737.0
reward_std: 758.7265625
reward_max: 2579.0
reward_min: 740.0
total_envstep_count: 1182028
total_train_sample_count: 1181976
total_episode_count: 5775
total_duration: 2357.558762042633
[2022-12-21 16:31:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1198
train_sample_count: 1198
avg_envstep_per_episode: 239.6
avg_sample_per_episode: 239.6
avg_envstep_per_sec: 505.4164693739548
avg_train_sample_per_sec: 505.4164693739548
avg_episode_per_sec: 2.1094176518111634
collect_time: 2.3703224421711644
reward_mean: 1402.5999755859375
reward_std: 925.469482421875
reward_max: 3009.0
reward_min: 231.0
total_envstep_count: 1183009
total_train_sample_count: 1182982
total_episode_count: 5780
total_duration: 2359.929084484804
[2022-12-21 16:31:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 618
train_sample_count: 618
avg_envstep_per_episode: 309.0
avg_sample_per_episode: 309.0
avg_envstep_per_sec: 497.76959572442325
avg_train_sample_per_sec: 497.76959572442325
avg_episode_per_sec: 1.610904840532114
collect_time: 1.2415382645068966
reward_mean: 1803.5
reward_std: 1218.5
reward_max: 3022.0
reward_min: 585.0
total_envstep_count: 1183968
total_train_sample_count: 1183948
total_episode_count: 5782
total_duration: 2361.170622749311
[2022-12-21 16:31:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1070
train_sample_count: 1070
avg_envstep_per_episode: 267.5
avg_sample_per_episode: 267.5
avg_envstep_per_sec: 501.8915835448087
avg_train_sample_per_sec: 501.8915835448087
avg_episode_per_sec: 1.876230218859098
collect_time: 2.1319345354283485
reward_mean: 1584.0
reward_std: 633.1322631835938
reward_max: 2584.0
reward_min: 1037.0
total_envstep_count: 1185005
total_train_sample_count: 1184970
total_episode_count: 5786
total_duration: 2363.302557284739
[2022-12-21 16:31:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1648
train_sample_count: 1648
avg_envstep_per_episode: 329.6
avg_sample_per_episode: 329.6
avg_envstep_per_sec: 503.68663362761595
avg_train_sample_per_sec: 503.68663362761595
avg_episode_per_sec: 1.5281754661032039
collect_time: 3.271875586872123
reward_mean: 1848.4000244140625
reward_std: 1007.4190673828125
reward_max: 3019.0
reward_min: 728.0
total_envstep_count: 1185993
total_train_sample_count: 1185958
total_episode_count: 5791
total_duration: 2366.5744328716114
[2022-12-21 16:31:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 935
train_sample_count: 935
avg_envstep_per_episode: 311.6666666666667
avg_sample_per_episode: 311.6666666666667
avg_envstep_per_sec: 505.51771053166823
avg_train_sample_per_sec: 505.51771053166823
avg_episode_per_sec: 1.6219819589251387
collect_time: 1.8495890065189453
reward_mean: 1876.6666259765625
reward_std: 382.274169921875
reward_max: 2337.0
reward_min: 1401.0
total_envstep_count: 1186974
total_train_sample_count: 1186929
total_episode_count: 5794
total_duration: 2368.42402187813
[2022-12-21 16:32:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 790
train_sample_count: 790
avg_envstep_per_episode: 263.3333333333333
avg_sample_per_episode: 263.3333333333333
avg_envstep_per_sec: 501.409504646481
avg_train_sample_per_sec: 501.409504646481
avg_episode_per_sec: 1.904086726505624
collect_time: 1.5755584859863991
reward_mean: 1701.3333740234375
reward_std: 271.058837890625
reward_max: 1894.0
reward_min: 1318.0
total_envstep_count: 1187947
total_train_sample_count: 1187899
total_episode_count: 5797
total_duration: 2369.9995803641164
[2022-12-21 16:32:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 640
train_sample_count: 640
avg_envstep_per_episode: 320.0
avg_sample_per_episode: 320.0
avg_envstep_per_sec: 496.49398798266725
avg_train_sample_per_sec: 496.49398798266725
avg_episode_per_sec: 1.5515437124458353
collect_time: 1.289038770842765
reward_mean: 1961.0
reward_std: 643.0
reward_max: 2604.0
reward_min: 1318.0
total_envstep_count: 1188914
total_train_sample_count: 1188875
total_episode_count: 5799
total_duration: 2371.288619134959
[2022-12-21 16:32:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 507
train_sample_count: 507
avg_envstep_per_episode: 253.5
avg_sample_per_episode: 253.5
avg_envstep_per_sec: 501.82089876261205
avg_train_sample_per_sec: 501.82089876261205
avg_episode_per_sec: 1.9795696203653335
collect_time: 1.0103206168777716
reward_mean: 1651.0
reward_std: 242.0
reward_max: 1893.0
reward_min: 1409.0
total_envstep_count: 1189880
total_train_sample_count: 1189838
total_episode_count: 5801
total_duration: 2372.2989397518368
[2022-12-21 16:32:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1388
train_sample_count: 1388
avg_envstep_per_episode: 347.0
avg_sample_per_episode: 347.0
avg_envstep_per_sec: 500.33876301415694
avg_train_sample_per_sec: 500.33876301415694
avg_episode_per_sec: 1.4418984524903657
collect_time: 2.7741204611818713
reward_mean: 2001.25
reward_std: 802.3139038085938
reward_max: 3010.0
reward_min: 810.0
total_envstep_count: 1190861
total_train_sample_count: 1190830
total_episode_count: 5805
total_duration: 2375.073060213019
[2022-12-21 16:32:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1023
train_sample_count: 1023
avg_envstep_per_episode: 341.0
avg_sample_per_episode: 341.0
avg_envstep_per_sec: 499.5505428256551
avg_train_sample_per_sec: 499.5505428256551
avg_episode_per_sec: 1.4649576035942966
collect_time: 2.047840833509074
reward_mean: 1906.3333740234375
reward_std: 821.2568969726562
reward_max: 3008.0
reward_min: 1037.0
total_envstep_count: 1191858
total_train_sample_count: 1191817
total_episode_count: 5808
total_duration: 2377.1209010465277
[2022-12-21 16:32:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 549
train_sample_count: 549
avg_envstep_per_episode: 274.5
avg_sample_per_episode: 274.5
avg_envstep_per_sec: 502.59254063030465
avg_train_sample_per_sec: 502.59254063030465
avg_episode_per_sec: 1.8309382172324395
collect_time: 1.0923361483071266
reward_mean: 1793.0
reward_std: 99.0
reward_max: 1892.0
reward_min: 1694.0
total_envstep_count: 1192833
total_train_sample_count: 1192798
total_episode_count: 5810
total_duration: 2378.2132371948346
[2022-12-21 16:32:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1480
train_sample_count: 1480
avg_envstep_per_episode: 370.0
avg_sample_per_episode: 370.0
avg_envstep_per_sec: 500.08776823570093
avg_train_sample_per_sec: 500.08776823570093
avg_episode_per_sec: 1.3515885627991917
collect_time: 2.9594805032352793
reward_mean: 2013.0
reward_std: 572.7996826171875
reward_max: 2988.0
reward_min: 1551.0
total_envstep_count: 1193838
total_train_sample_count: 1193798
total_episode_count: 5814
total_duration: 2381.17271769807
[2022-12-21 16:32:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1075
train_sample_count: 1075
avg_envstep_per_episode: 537.5
avg_sample_per_episode: 537.5
avg_envstep_per_sec: 498.0485862346241
avg_train_sample_per_sec: 498.0485862346241
avg_episode_per_sec: 0.9266020209016262
collect_time: 2.158423956440229
reward_mean: 3014.0
reward_std: 0.0
reward_max: 3014.0
reward_min: 3014.0
total_envstep_count: 1194813
total_train_sample_count: 1194777
total_episode_count: 5816
total_duration: 2383.3311416545102
[2022-12-21 16:32:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 529
train_sample_count: 529
avg_envstep_per_episode: 264.5
avg_sample_per_episode: 264.5
avg_envstep_per_sec: 503.450847034091
avg_train_sample_per_sec: 503.450847034091
avg_episode_per_sec: 1.9034058489001549
collect_time: 1.0507480583584736
reward_mean: 1551.5
reward_std: 1.5
reward_max: 1553.0
reward_min: 1550.0
total_envstep_count: 1195803
total_train_sample_count: 1195750
total_episode_count: 5818
total_duration: 2384.3818897128685
[2022-12-21 16:32:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 784
train_sample_count: 784
avg_envstep_per_episode: 392.0
avg_sample_per_episode: 392.0
avg_envstep_per_sec: 502.85910919884753
avg_train_sample_per_sec: 502.85910919884753
avg_episode_per_sec: 1.28280384999706
collect_time: 1.559084812541359
reward_mean: 2345.0
reward_std: 676.0
reward_max: 3021.0
reward_min: 1669.0
total_envstep_count: 1196777
total_train_sample_count: 1196726
total_episode_count: 5820
total_duration: 2385.9409745254097
[2022-12-21 16:32:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1292
train_sample_count: 1292
avg_envstep_per_episode: 430.6666666666667
avg_sample_per_episode: 430.6666666666667
avg_envstep_per_sec: 504.40346249254696
avg_train_sample_per_sec: 504.40346249254696
avg_episode_per_sec: 1.1712154701839326
collect_time: 2.5614415761848393
reward_mean: 2212.666748046875
reward_std: 686.7009887695312
reward_max: 2984.0
reward_min: 1316.0
total_envstep_count: 1197734
total_train_sample_count: 1197694
total_episode_count: 5823
total_duration: 2388.5024161015945
[2022-12-21 16:32:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1409
train_sample_count: 1409
avg_envstep_per_episode: 352.25
avg_sample_per_episode: 352.25
avg_envstep_per_sec: 504.78150928628503
avg_train_sample_per_sec: 504.78150928628503
avg_episode_per_sec: 1.4330206083357986
collect_time: 2.791306682354901
reward_mean: 2026.25
reward_std: 1140.40771484375
reward_max: 3019.0
reward_min: 231.0
total_envstep_count: 1198739
total_train_sample_count: 1198695
total_episode_count: 5827
total_duration: 2391.2937227839493
[2022-12-21 16:32:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 291
train_sample_count: 291
avg_envstep_per_episode: 291.0
avg_sample_per_episode: 291.0
avg_envstep_per_sec: 510.14125029248254
avg_train_sample_per_sec: 510.14125029248254
avg_episode_per_sec: 1.753062715781727
collect_time: 0.5704302481580525
reward_mean: 1829.0
reward_std: 0.0
reward_max: 1829.0
reward_min: 1829.0
total_envstep_count: 1199722
total_train_sample_count: 1199706
total_episode_count: 5828
total_duration: 2391.8641530321074
[2022-12-21 16:33:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1715
train_sample_count: 1715
avg_envstep_per_episode: 343.0
avg_sample_per_episode: 343.0
avg_envstep_per_sec: 505.5921856545057
avg_train_sample_per_sec: 505.5921856545057
avg_episode_per_sec: 1.474029695785731
collect_time: 3.3920619199837434
reward_mean: 2094.800048828125
reward_std: 590.5260009765625
reward_max: 2609.0
reward_min: 1035.0
total_envstep_count: 1200711
total_train_sample_count: 1200677
total_episode_count: 5833
total_duration: 2395.2562149520913
[2022-12-21 16:33:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 535
train_sample_count: 535
avg_envstep_per_episode: 535.0
avg_sample_per_episode: 535.0
avg_envstep_per_sec: 500.24356172872194
avg_train_sample_per_sec: 500.24356172872194
avg_episode_per_sec: 0.9350346948200411
collect_time: 1.069479031676426
reward_mean: 2586.0
reward_std: 0.0
reward_max: 2586.0
reward_min: 2586.0
total_envstep_count: 1201686
total_train_sample_count: 1201656
total_episode_count: 5834
total_duration: 2396.325693983768
[2022-12-21 16:33:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1340
train_sample_count: 1340
avg_envstep_per_episode: 446.6666666666667
avg_sample_per_episode: 446.6666666666667
avg_envstep_per_sec: 501.1663407295399
avg_train_sample_per_sec: 501.1663407295399
avg_episode_per_sec: 1.122014195663149
collect_time: 2.67376296271091
reward_mean: 2641.666748046875
reward_std: 530.0945434570312
reward_max: 3017.0
reward_min: 1892.0
total_envstep_count: 1202659
total_train_sample_count: 1202624
total_episode_count: 5837
total_duration: 2398.999456946479
[2022-12-21 16:33:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 582
train_sample_count: 582
avg_envstep_per_episode: 291.0
avg_sample_per_episode: 291.0
avg_envstep_per_sec: 497.3898994781339
avg_train_sample_per_sec: 497.3898994781339
avg_episode_per_sec: 1.7092436408183296
collect_time: 1.1701082000471659
reward_mean: 1869.0
reward_std: 23.0
reward_max: 1892.0
reward_min: 1846.0
total_envstep_count: 1203625
total_train_sample_count: 1203590
total_episode_count: 5839
total_duration: 2400.169565146526
[2022-12-21 16:33:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1572
train_sample_count: 1572
avg_envstep_per_episode: 314.4
avg_sample_per_episode: 314.4
avg_envstep_per_sec: 498.22662589378143
avg_train_sample_per_sec: 498.22662589378143
avg_episode_per_sec: 1.5846902859216967
collect_time: 3.1551906668575755
reward_mean: 1934.4000244140625
reward_std: 755.89697265625
reward_max: 3021.0
reward_min: 1052.0
total_envstep_count: 1204636
total_train_sample_count: 1204586
total_episode_count: 5844
total_duration: 2403.3247558133835
[2022-12-21 16:33:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1035
train_sample_count: 1035
avg_envstep_per_episode: 258.75
avg_sample_per_episode: 258.75
avg_envstep_per_sec: 492.07514380720755
avg_train_sample_per_sec: 492.07514380720755
avg_episode_per_sec: 1.9017396862114302
collect_time: 2.1033372911140327
reward_mean: 1525.0
reward_std: 904.0953979492188
reward_max: 3015.0
reward_min: 626.0
total_envstep_count: 1205618
total_train_sample_count: 1205561
total_episode_count: 5848
total_duration: 2405.4280931044977
[2022-12-21 16:33:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 273
train_sample_count: 273
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 492.7076061926129
avg_train_sample_per_sec: 492.7076061926129
avg_episode_per_sec: 1.8047897662733074
collect_time: 0.5540811559813363
reward_mean: 1674.0
reward_std: 0.0
reward_max: 1674.0
reward_min: 1674.0
total_envstep_count: 1206594
total_train_sample_count: 1206542
total_episode_count: 5849
total_duration: 2405.982174260479
[2022-12-21 16:33:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 950
train_sample_count: 950
avg_envstep_per_episode: 316.6666666666667
avg_sample_per_episode: 316.6666666666667
avg_envstep_per_sec: 498.42102704986877
avg_train_sample_per_sec: 498.42102704986877
avg_episode_per_sec: 1.5739611380522172
collect_time: 1.9060191052191486
reward_mean: 1947.0
reward_std: 281.65228271484375
reward_max: 2335.0
reward_min: 1675.0
total_envstep_count: 1207567
total_train_sample_count: 1207540
total_episode_count: 5852
total_duration: 2407.888193365698
[2022-12-21 16:33:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1325
train_sample_count: 1325
avg_envstep_per_episode: 441.6666666666667
avg_sample_per_episode: 441.6666666666667
avg_envstep_per_sec: 497.2075018730722
avg_train_sample_per_sec: 497.2075018730722
avg_episode_per_sec: 1.1257528344295975
collect_time: 2.664883363602683
reward_mean: 2500.0
reward_std: 457.41522216796875
reward_max: 2999.0
reward_min: 1894.0
total_envstep_count: 1208548
total_train_sample_count: 1208517
total_episode_count: 5855
total_duration: 2410.5530767293008
[2022-12-21 16:33:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 947
train_sample_count: 947
avg_envstep_per_episode: 315.6666666666667
avg_sample_per_episode: 315.6666666666667
avg_envstep_per_sec: 503.88512381924494
avg_train_sample_per_sec: 503.88512381924494
avg_episode_per_sec: 1.5962569920356229
collect_time: 1.879396622829672
reward_mean: 1914.0
reward_std: 779.5310668945312
reward_max: 3015.0
reward_min: 1315.0
total_envstep_count: 1209537
total_train_sample_count: 1209500
total_episode_count: 5858
total_duration: 2412.4324733521303
[2022-12-21 16:33:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 451
train_sample_count: 451
avg_envstep_per_episode: 225.5
avg_sample_per_episode: 225.5
avg_envstep_per_sec: 498.99674052467014
avg_train_sample_per_sec: 498.99674052467014
avg_episode_per_sec: 2.2128458559852335
collect_time: 0.9038135189536429
reward_mean: 1434.0
reward_std: 393.0
reward_max: 1827.0
reward_min: 1041.0
total_envstep_count: 1210496
total_train_sample_count: 1210467
total_episode_count: 5860
total_duration: 2413.3362868710838
[2022-12-21 16:33:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1471
train_sample_count: 1471
avg_envstep_per_episode: 367.75
avg_sample_per_episode: 367.75
avg_envstep_per_sec: 502.1540090303612
avg_train_sample_per_sec: 502.1540090303612
avg_episode_per_sec: 1.365476571122668
collect_time: 2.9293801772895147
reward_mean: 2080.5
reward_std: 1000.5609741210938
reward_max: 3013.0
reward_min: 626.0
total_envstep_count: 1211476
total_train_sample_count: 1211434
total_episode_count: 5864
total_duration: 2416.2656670483734
[2022-12-21 16:33:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 170
train_sample_count: 170
avg_envstep_per_episode: 170.0
avg_sample_per_episode: 170.0
avg_envstep_per_sec: 487.90944191450996
avg_train_sample_per_sec: 487.90944191450996
avg_episode_per_sec: 2.870055540673588
collect_time: 0.34842531296983364
reward_mean: 809.0
reward_std: 0.0
reward_max: 809.0
reward_min: 809.0
total_envstep_count: 1212436
total_train_sample_count: 1212396
total_episode_count: 5865
total_duration: 2416.6140923613434
[2022-12-21 16:33:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1299
train_sample_count: 1299
avg_envstep_per_episode: 649.5
avg_sample_per_episode: 649.5
avg_envstep_per_sec: 500.9374317402452
avg_train_sample_per_sec: 500.9374317402452
avg_episode_per_sec: 0.77126625364164
collect_time: 2.593138219851736
reward_mean: 2991.5
reward_std: 0.5
reward_max: 2992.0
reward_min: 2991.0
total_envstep_count: 1213386
total_train_sample_count: 1213359
total_episode_count: 5867
total_duration: 2419.2072305811953
[2022-12-21 16:33:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 760
train_sample_count: 760
avg_envstep_per_episode: 380.0
avg_sample_per_episode: 380.0
avg_envstep_per_sec: 498.1476277561319
avg_train_sample_per_sec: 498.1476277561319
avg_episode_per_sec: 1.3109148098845576
collect_time: 1.525652151398095
reward_mean: 2026.5
reward_std: 975.5
reward_max: 3002.0
reward_min: 1051.0
total_envstep_count: 1214392
total_train_sample_count: 1214359
total_episode_count: 5869
total_duration: 2420.732882732593
[2022-12-21 16:33:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1297
train_sample_count: 1297
avg_envstep_per_episode: 432.3333333333333
avg_sample_per_episode: 432.3333333333333
avg_envstep_per_sec: 494.5212539427584
avg_train_sample_per_sec: 494.5212539427584
avg_episode_per_sec: 1.1438425303224944
collect_time: 2.6227386379436175
reward_mean: 2351.333251953125
reward_std: 928.670166015625
reward_max: 3011.0
reward_min: 1038.0
total_envstep_count: 1215349
total_train_sample_count: 1215332
total_episode_count: 5872
total_duration: 2423.355621370537
[2022-12-21 16:33:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1021
train_sample_count: 1021
avg_envstep_per_episode: 340.3333333333333
avg_sample_per_episode: 340.3333333333333
avg_envstep_per_sec: 497.2545891905044
avg_train_sample_per_sec: 497.2545891905044
avg_episode_per_sec: 1.4610810652022657
collect_time: 2.0532741621593003
reward_mean: 1899.3333740234375
reward_std: 813.0569458007812
reward_max: 2609.0
reward_min: 761.0
total_envstep_count: 1216364
total_train_sample_count: 1216317
total_episode_count: 5875
total_duration: 2425.408895532696
[2022-12-21 16:33:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 445.0
avg_sample_per_episode: 445.0
avg_envstep_per_sec: 500.4687068234487
avg_train_sample_per_sec: 500.4687068234487
avg_episode_per_sec: 1.1246487793785365
collect_time: 1.778332966408561
reward_mean: 2152.0
reward_std: 832.0
reward_max: 2984.0
reward_min: 1320.0
total_envstep_count: 1217338
total_train_sample_count: 1217291
total_episode_count: 5877
total_duration: 2427.1872284991045
[2022-12-21 16:34:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1184
train_sample_count: 1184
avg_envstep_per_episode: 592.0
avg_sample_per_episode: 592.0
avg_envstep_per_sec: 497.8685452024921
avg_train_sample_per_sec: 497.8685452024921
avg_episode_per_sec: 0.8409941641933988
collect_time: 2.3781377863878626
reward_mean: 2649.0
reward_std: 323.0
reward_max: 2972.0
reward_min: 2326.0
total_envstep_count: 1218320
total_train_sample_count: 1218283
total_episode_count: 5879
total_duration: 2429.5653662854925
[2022-12-21 16:34:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 234
train_sample_count: 234
avg_envstep_per_episode: 234.0
avg_sample_per_episode: 234.0
avg_envstep_per_sec: 504.68868632155824
avg_train_sample_per_sec: 504.68868632155824
avg_episode_per_sec: 2.1567892577844368
collect_time: 0.4636521609103574
reward_mean: 1551.0
reward_std: 0.0
reward_max: 1551.0
reward_min: 1551.0
total_envstep_count: 1219303
total_train_sample_count: 1219249
total_episode_count: 5880
total_duration: 2430.029018446403
[2022-12-21 16:34:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1025
train_sample_count: 1025
avg_envstep_per_episode: 512.5
avg_sample_per_episode: 512.5
avg_envstep_per_sec: 503.94777693670017
avg_train_sample_per_sec: 503.94777693670017
avg_episode_per_sec: 0.9833127354862443
collect_time: 2.0339409099700188
reward_mean: 3019.0
reward_std: 0.0
reward_max: 3019.0
reward_min: 3019.0
total_envstep_count: 1220277
total_train_sample_count: 1220226
total_episode_count: 5882
total_duration: 2432.062959356373
[2022-12-21 16:34:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2216
train_sample_count: 2216
avg_envstep_per_episode: 443.2
avg_sample_per_episode: 443.2
avg_envstep_per_sec: 501.89541146359477
avg_train_sample_per_sec: 501.89541146359477
avg_episode_per_sec: 1.1324354951795912
collect_time: 4.415262521603545
reward_mean: 2331.0
reward_std: 885.3028564453125
reward_max: 3017.0
reward_min: 810.0
total_envstep_count: 1221265
total_train_sample_count: 1221230
total_episode_count: 5887
total_duration: 2436.4782218779765
[2022-12-21 16:34:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 638
train_sample_count: 638
avg_envstep_per_episode: 319.0
avg_sample_per_episode: 319.0
avg_envstep_per_sec: 501.08588489393765
avg_train_sample_per_sec: 501.08588489393765
avg_episode_per_sec: 1.5708021470029394
collect_time: 1.2732348270696994
reward_mean: 1821.0
reward_std: 1194.0
reward_max: 3015.0
reward_min: 627.0
total_envstep_count: 1222248
total_train_sample_count: 1222204
total_episode_count: 5889
total_duration: 2437.751456705046
[2022-12-21 16:34:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 431
train_sample_count: 431
avg_envstep_per_episode: 215.5
avg_sample_per_episode: 215.5
avg_envstep_per_sec: 494.5009519316754
avg_train_sample_per_sec: 494.5009519316754
avg_episode_per_sec: 2.294667990402206
collect_time: 0.8715857842464796
reward_mean: 1312.0
reward_std: 2.0
reward_max: 1314.0
reward_min: 1310.0
total_envstep_count: 1223214
total_train_sample_count: 1223175
total_episode_count: 5891
total_duration: 2438.623042489293
[2022-12-21 16:34:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1099
train_sample_count: 1099
avg_envstep_per_episode: 366.3333333333333
avg_sample_per_episode: 366.3333333333333
avg_envstep_per_sec: 498.48921874456715
avg_train_sample_per_sec: 498.48921874456715
avg_episode_per_sec: 1.360753099393723
collect_time: 2.204661522605854
reward_mean: 2087.333251953125
reward_std: 1312.6275634765625
reward_max: 3018.0
reward_min: 231.0
total_envstep_count: 1224173
total_train_sample_count: 1224142
total_episode_count: 5894
total_duration: 2440.8277040118987
[2022-12-21 16:34:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 840
train_sample_count: 840
avg_envstep_per_episode: 420.0
avg_sample_per_episode: 420.0
avg_envstep_per_sec: 491.4684779658437
avg_train_sample_per_sec: 491.4684779658437
avg_episode_per_sec: 1.1701630427758185
collect_time: 1.709163532678038
reward_mean: 2429.0
reward_std: 581.0
reward_max: 3010.0
reward_min: 1848.0
total_envstep_count: 1225171
total_train_sample_count: 1225138
total_episode_count: 5896
total_duration: 2442.5368675445766
[2022-12-21 16:34:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1224
train_sample_count: 1224
avg_envstep_per_episode: 408.0
avg_sample_per_episode: 408.0
avg_envstep_per_sec: 490.54693469971534
avg_train_sample_per_sec: 490.54693469971534
avg_episode_per_sec: 1.2023209183816552
collect_time: 2.495174087163061
reward_mean: 2218.333251953125
reward_std: 694.2052612304688
reward_max: 3009.0
reward_min: 1319.0
total_envstep_count: 1226129
total_train_sample_count: 1226110
total_episode_count: 5899
total_duration: 2445.0320416317395
[2022-12-21 16:35:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1350
train_sample_count: 1350
avg_envstep_per_episode: 337.5
avg_sample_per_episode: 337.5
avg_envstep_per_sec: 498.89233913318833
avg_train_sample_per_sec: 498.89233913318833
avg_episode_per_sec: 1.478199523357595
collect_time: 2.705994648756459
reward_mean: 1795.0
reward_std: 496.0065612792969
reward_max: 2566.0
reward_min: 1319.0
total_envstep_count: 1227149
total_train_sample_count: 1227112
total_episode_count: 5903
total_duration: 2447.738036280496
[2022-12-21 16:35:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 251
train_sample_count: 251
avg_envstep_per_episode: 251.0
avg_sample_per_episode: 251.0
avg_envstep_per_sec: 506.20765583020034
avg_train_sample_per_sec: 506.20765583020034
avg_episode_per_sec: 2.0167635690446226
collect_time: 0.49584394291380324
reward_mean: 1545.0
reward_std: 0.0
reward_max: 1545.0
reward_min: 1545.0
total_envstep_count: 1228140
total_train_sample_count: 1228107
total_episode_count: 5904
total_duration: 2448.23388022341
[2022-12-21 16:35:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1834
train_sample_count: 1834
avg_envstep_per_episode: 262.0
avg_sample_per_episode: 262.0
avg_envstep_per_sec: 494.96804928033396
avg_train_sample_per_sec: 494.96804928033396
avg_episode_per_sec: 1.8891910277875341
collect_time: 3.705289670043493
reward_mean: 1367.5714111328125
reward_std: 1041.7333984375
reward_max: 2977.0
reward_min: 231.0
total_envstep_count: 1229136
total_train_sample_count: 1229089
total_episode_count: 5911
total_duration: 2451.9391698934533
[2022-12-21 16:35:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1046
train_sample_count: 1046
avg_envstep_per_episode: 523.0
avg_sample_per_episode: 523.0
avg_envstep_per_sec: 406.39596254502356
avg_train_sample_per_sec: 406.39596254502356
avg_episode_per_sec: 0.7770477295315938
collect_time: 2.573844467965442
reward_mean: 2802.5
reward_std: 194.5
reward_max: 2997.0
reward_min: 2608.0
total_envstep_count: 1230104
total_train_sample_count: 1230063
total_episode_count: 5913
total_duration: 2454.5130143614188
[2022-12-21 16:35:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 784
train_sample_count: 784
avg_envstep_per_episode: 196.0
avg_sample_per_episode: 196.0
avg_envstep_per_sec: 505.6323871510365
avg_train_sample_per_sec: 505.6323871510365
avg_episode_per_sec: 2.5797570773012066
collect_time: 1.5505335890713283
reward_mean: 1218.75
reward_std: 239.4330596923828
reward_max: 1426.0
reward_min: 811.0
total_envstep_count: 1231063
total_train_sample_count: 1231051
total_episode_count: 5917
total_duration: 2456.06354795049
[2022-12-21 16:35:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 379
train_sample_count: 379
avg_envstep_per_episode: 379.0
avg_sample_per_episode: 379.0
avg_envstep_per_sec: 505.1888470828665
avg_train_sample_per_sec: 505.1888470828665
avg_episode_per_sec: 1.3329521031210199
collect_time: 0.7502145033257877
reward_mean: 2339.0
reward_std: 0.0
reward_max: 2339.0
reward_min: 2339.0
total_envstep_count: 1232054
total_train_sample_count: 1232018
total_episode_count: 5918
total_duration: 2456.813762453816
[2022-12-21 16:35:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1089
train_sample_count: 1089
avg_envstep_per_episode: 363.0
avg_sample_per_episode: 363.0
avg_envstep_per_sec: 502.0449724593997
avg_train_sample_per_sec: 502.0449724593997
avg_episode_per_sec: 1.3830440012655638
collect_time: 2.169128384386057
reward_mean: 1863.3333740234375
reward_std: 825.5319213867188
reward_max: 2995.0
reward_min: 1049.0
total_envstep_count: 1233061
total_train_sample_count: 1233011
total_episode_count: 5921
total_duration: 2458.982890838202
[2022-12-21 16:35:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2024
train_sample_count: 2024
avg_envstep_per_episode: 506.0
avg_sample_per_episode: 506.0
avg_envstep_per_sec: 503.38915494912777
avg_train_sample_per_sec: 503.38915494912777
avg_episode_per_sec: 0.9948402271721892
collect_time: 4.020746136663481
reward_mean: 2735.75
reward_std: 288.8177490234375
reward_max: 3019.0
reward_min: 2322.0
total_envstep_count: 1234026
total_train_sample_count: 1234003
total_episode_count: 5925
total_duration: 2463.0036369748655
[2022-12-21 16:35:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 290
train_sample_count: 290
avg_envstep_per_episode: 290.0
avg_sample_per_episode: 290.0
avg_envstep_per_sec: 511.0526621522617
avg_train_sample_per_sec: 511.0526621522617
avg_episode_per_sec: 1.7622505591457298
collect_time: 0.5674561967423979
reward_mean: 1834.0
reward_std: 0.0
reward_max: 1834.0
reward_min: 1834.0
total_envstep_count: 1234985
total_train_sample_count: 1234965
total_episode_count: 5926
total_duration: 2463.571093171608
[2022-12-21 16:35:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 742
train_sample_count: 742
avg_envstep_per_episode: 371.0
avg_sample_per_episode: 371.0
avg_envstep_per_sec: 509.5507929346915
avg_train_sample_per_sec: 509.5507929346915
avg_episode_per_sec: 1.373452272061163
collect_time: 1.4561845654807983
reward_mean: 2023.5
reward_std: 985.5
reward_max: 3009.0
reward_min: 1038.0
total_envstep_count: 1235960
total_train_sample_count: 1235935
total_episode_count: 5928
total_duration: 2465.0272777370888
[2022-12-21 16:35:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1251
train_sample_count: 1251
avg_envstep_per_episode: 417.0
avg_sample_per_episode: 417.0
avg_envstep_per_sec: 519.1870012240598
avg_train_sample_per_sec: 519.1870012240598
avg_episode_per_sec: 1.2450527607291604
collect_time: 2.4095364426508814
reward_mean: 2506.666748046875
reward_std: 463.1128845214844
reward_max: 3017.0
reward_min: 1896.0
total_envstep_count: 1236943
total_train_sample_count: 1236910
total_episode_count: 5931
total_duration: 2467.4368141797395
[2022-12-21 16:35:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1598
train_sample_count: 1598
avg_envstep_per_episode: 319.6
avg_sample_per_episode: 319.6
avg_envstep_per_sec: 511.2242733132728
avg_train_sample_per_sec: 511.2242733132728
avg_episode_per_sec: 1.59957532325805
collect_time: 3.125829666974288
reward_mean: 1825.800048828125
reward_std: 1065.8359375
reward_max: 3014.0
reward_min: 231.0
total_envstep_count: 1237939
total_train_sample_count: 1237920
total_episode_count: 5936
total_duration: 2470.562643846714
[2022-12-21 16:35:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 834
train_sample_count: 834
avg_envstep_per_episode: 417.0
avg_sample_per_episode: 417.0
avg_envstep_per_sec: 507.49668326916174
avg_train_sample_per_sec: 507.49668326916174
avg_episode_per_sec: 1.2170184251059035
collect_time: 1.6433604937624198
reward_mean: 2346.0
reward_std: 667.0
reward_max: 3013.0
reward_min: 1679.0
total_envstep_count: 1238929
total_train_sample_count: 1238886
total_episode_count: 5938
total_duration: 2472.2060043404763
[2022-12-21 16:35:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 538
train_sample_count: 538
avg_envstep_per_episode: 179.33333333333334
avg_sample_per_episode: 179.33333333333334
avg_envstep_per_sec: 492.57829084099814
avg_train_sample_per_sec: 492.57829084099814
avg_episode_per_sec: 2.7467190939089114
collect_time: 1.0922121620127667
reward_mean: 1058.0
reward_std: 206.3120574951172
reward_max: 1316.0
reward_min: 811.0
total_envstep_count: 1239926
total_train_sample_count: 1239892
total_episode_count: 5941
total_duration: 2473.298216502489
[2022-12-21 16:35:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 339
train_sample_count: 339
avg_envstep_per_episode: 169.5
avg_sample_per_episode: 169.5
avg_envstep_per_sec: 492.4253502466828
avg_train_sample_per_sec: 492.4253502466828
avg_episode_per_sec: 2.9051643082400163
collect_time: 0.6884292204497116
reward_mean: 1062.5
reward_std: 831.5
reward_max: 1894.0
reward_min: 231.0
total_envstep_count: 1240909
total_train_sample_count: 1240891
total_episode_count: 5943
total_duration: 2473.9866457229386
[2022-12-21 16:35:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2668
train_sample_count: 2668
avg_envstep_per_episode: 381.14285714285717
avg_sample_per_episode: 381.14285714285717
avg_envstep_per_sec: 500.52698970461404
avg_train_sample_per_sec: 500.52698970461404
avg_episode_per_sec: 1.313226734607308
collect_time: 5.330381887247519
reward_mean: 2103.28564453125
reward_std: 941.88623046875
reward_max: 3022.0
reward_min: 217.0
total_envstep_count: 1241937
total_train_sample_count: 1241891
total_episode_count: 5950
total_duration: 2479.317027610186
[2022-12-21 16:35:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 529
train_sample_count: 529
avg_envstep_per_episode: 529.0
avg_sample_per_episode: 529.0
avg_envstep_per_sec: 496.6931236711246
avg_train_sample_per_sec: 496.6931236711246
avg_episode_per_sec: 0.9389284001344511
collect_time: 1.06504393717008
reward_mean: 3016.0
reward_std: 0.0
reward_max: 3016.0
reward_min: 3016.0
total_envstep_count: 1243760
total_train_sample_count: 1243716
total_episode_count: 5951
total_duration: 2480.382071547356
[2022-12-21 16:35:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1148
train_sample_count: 1148
avg_envstep_per_episode: 382.6666666666667
avg_sample_per_episode: 382.6666666666667
avg_envstep_per_sec: 502.43432751578973
avg_train_sample_per_sec: 502.43432751578973
avg_episode_per_sec: 1.312981692114433
collect_time: 2.2848757282889323
reward_mean: 2364.333251953125
reward_std: 333.2989807128906
reward_max: 2604.0
reward_min: 1893.0
total_envstep_count: 1244742
total_train_sample_count: 1244708
total_episode_count: 5954
total_duration: 2482.6669472756453
[2022-12-21 16:35:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2063
train_sample_count: 2063
avg_envstep_per_episode: 294.7142857142857
avg_sample_per_episode: 294.7142857142857
avg_envstep_per_sec: 502.5198464597341
avg_train_sample_per_sec: 502.5198464597341
avg_episode_per_sec: 1.7051085434891609
collect_time: 4.105310495762288
reward_mean: 1734.0
reward_std: 752.3994140625
reward_max: 3019.0
reward_min: 1039.0
total_envstep_count: 1245797
total_train_sample_count: 1245763
total_episode_count: 5961
total_duration: 2486.7722577714076
[2022-12-21 16:36:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 731
train_sample_count: 731
avg_envstep_per_episode: 365.5
avg_sample_per_episode: 365.5
avg_envstep_per_sec: 498.9854519453946
avg_train_sample_per_sec: 498.9854519453946
avg_episode_per_sec: 1.365213274816401
collect_time: 1.464972570142176
reward_mean: 1863.0
reward_std: 1143.0
reward_max: 3006.0
reward_min: 720.0
total_envstep_count: 1246779
total_train_sample_count: 1246734
total_episode_count: 5963
total_duration: 2488.2372303415495
[2022-12-21 16:36:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 160
train_sample_count: 160
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 504.8984970106314
avg_train_sample_per_sec: 504.8984970106314
avg_episode_per_sec: 3.155615606316446
collect_time: 0.31689537787756766
reward_mean: 1047.0
reward_std: 0.0
reward_max: 1047.0
reward_min: 1047.0
total_envstep_count: 1247762
total_train_sample_count: 1247734
total_episode_count: 5964
total_duration: 2488.5541257194272
[2022-12-21 16:36:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1022
train_sample_count: 1022
avg_envstep_per_episode: 340.6666666666667
avg_sample_per_episode: 340.6666666666667
avg_envstep_per_sec: 489.4506153481951
avg_train_sample_per_sec: 489.4506153481951
avg_episode_per_sec: 1.436743489280416
collect_time: 2.0880553991600346
reward_mean: 2130.333251953125
reward_std: 338.4694519042969
reward_max: 2609.0
reward_min: 1890.0
total_envstep_count: 1248736
total_train_sample_count: 1248696
total_episode_count: 5967
total_duration: 2490.6421811185874
[2022-12-21 16:36:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 348.0
avg_sample_per_episode: 348.0
avg_envstep_per_sec: 493.3494078679484
avg_train_sample_per_sec: 493.3494078679484
avg_episode_per_sec: 1.4176707122642196
collect_time: 1.410764843131815
reward_mean: 1858.0
reward_std: 460.0
reward_max: 2318.0
reward_min: 1398.0
total_envstep_count: 1249718
total_train_sample_count: 1249668
total_episode_count: 5969
total_duration: 2492.052945961719
[2022-12-21 16:36:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1759
train_sample_count: 1759
avg_envstep_per_episode: 439.75
avg_sample_per_episode: 439.75
avg_envstep_per_sec: 494.99435769057294
avg_train_sample_per_sec: 494.99435769057294
avg_episode_per_sec: 1.1256267372156292
collect_time: 3.5535758593425677
reward_mean: 2521.0
reward_std: 856.2210693359375
reward_max: 3021.0
reward_min: 1038.0
total_envstep_count: 1250682
total_train_sample_count: 1250647
total_episode_count: 5973
total_duration: 2495.6065218210615
[2022-12-21 16:36:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 997
train_sample_count: 997
avg_envstep_per_episode: 249.25
avg_sample_per_episode: 249.25
avg_envstep_per_sec: 477.96556805512375
avg_train_sample_per_sec: 477.96556805512375
avg_episode_per_sec: 1.9176151175732148
collect_time: 2.085924314709247
reward_mean: 1558.5
reward_std: 639.4221801757812
reward_max: 2609.0
reward_min: 1039.0
total_envstep_count: 1251655
total_train_sample_count: 1251620
total_episode_count: 5977
total_duration: 2497.6924461357708
[2022-12-21 16:36:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 656
train_sample_count: 656
avg_envstep_per_episode: 328.0
avg_sample_per_episode: 328.0
avg_envstep_per_sec: 489.4332597581068
avg_train_sample_per_sec: 489.4332597581068
avg_episode_per_sec: 1.4921745724332522
collect_time: 1.3403257480380792
reward_mean: 1829.0
reward_std: 1193.0
reward_max: 3022.0
reward_min: 636.0
total_envstep_count: 1252622
total_train_sample_count: 1252588
total_episode_count: 5979
total_duration: 2499.032771883809
[2022-12-21 16:36:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 794
train_sample_count: 794
avg_envstep_per_episode: 397.0
avg_sample_per_episode: 397.0
avg_envstep_per_sec: 491.2969911494012
avg_train_sample_per_sec: 491.2969911494012
avg_episode_per_sec: 1.237523907177333
collect_time: 1.6161303942497547
reward_mean: 2167.0
reward_std: 847.0
reward_max: 3014.0
reward_min: 1320.0
total_envstep_count: 1253596
total_train_sample_count: 1253562
total_episode_count: 5981
total_duration: 2500.648902278059
[2022-12-21 16:36:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 800
train_sample_count: 800
avg_envstep_per_episode: 400.0
avg_sample_per_episode: 400.0
avg_envstep_per_sec: 487.067752996546
avg_train_sample_per_sec: 487.067752996546
avg_episode_per_sec: 1.217669382491365
collect_time: 1.642481964938609
reward_mean: 2335.0
reward_std: 0.0
reward_max: 2335.0
reward_min: 2335.0
total_envstep_count: 1254578
total_train_sample_count: 1254542
total_episode_count: 5983
total_duration: 2502.2913842429975
[2022-12-21 16:37:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1598
train_sample_count: 1598
avg_envstep_per_episode: 399.5
avg_sample_per_episode: 399.5
avg_envstep_per_sec: 498.7497707579307
avg_train_sample_per_sec: 498.7497707579307
avg_episode_per_sec: 1.2484349706080868
collect_time: 3.2040114977327834
reward_mean: 2293.25
reward_std: 741.2500610351562
reward_max: 3019.0
reward_min: 1316.0
total_envstep_count: 1255559
total_train_sample_count: 1255516
total_episode_count: 5987
total_duration: 2505.49539574073
[2022-12-21 16:37:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 815
train_sample_count: 815
avg_envstep_per_episode: 407.5
avg_sample_per_episode: 407.5
avg_envstep_per_sec: 497.257769026871
avg_train_sample_per_sec: 497.257769026871
avg_episode_per_sec: 1.220264463869622
collect_time: 1.63898897265084
reward_mean: 2455.5
reward_std: 560.5
reward_max: 3016.0
reward_min: 1895.0
total_envstep_count: 1256517
total_train_sample_count: 1256487
total_episode_count: 5989
total_duration: 2507.1343847133808
[2022-12-21 16:37:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 920
train_sample_count: 920
avg_envstep_per_episode: 230.0
avg_sample_per_episode: 230.0
avg_envstep_per_sec: 492.35766480971245
avg_train_sample_per_sec: 492.35766480971245
avg_episode_per_sec: 2.1406854991726627
collect_time: 1.8685603287105599
reward_mean: 1259.25
reward_std: 1054.1817626953125
reward_max: 3015.0
reward_min: 231.0
total_envstep_count: 1257521
total_train_sample_count: 1257467
total_episode_count: 5993
total_duration: 2509.002945042091
[2022-12-21 16:37:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 586
train_sample_count: 586
avg_envstep_per_episode: 586.0
avg_sample_per_episode: 586.0
avg_envstep_per_sec: 494.768146346991
avg_train_sample_per_sec: 494.768146346991
avg_episode_per_sec: 0.8443142429129539
collect_time: 1.1843931431855483
reward_mean: 3004.0
reward_std: 0.0
reward_max: 3004.0
reward_min: 3004.0
total_envstep_count: 1258496
total_train_sample_count: 1258437
total_episode_count: 5994
total_duration: 2510.1873381852765
[2022-12-21 16:37:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1097
train_sample_count: 1097
avg_envstep_per_episode: 365.6666666666667
avg_sample_per_episode: 365.6666666666667
avg_envstep_per_sec: 490.80858005674907
avg_train_sample_per_sec: 490.80858005674907
avg_episode_per_sec: 1.3422294805562873
collect_time: 2.2350872510687587
reward_mean: 2256.666748046875
reward_std: 812.683349609375
reward_max: 3024.0
reward_min: 1132.0
total_envstep_count: 1259461
total_train_sample_count: 1259438
total_episode_count: 5997
total_duration: 2512.4224254363453
[2022-12-21 16:37:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 670
train_sample_count: 670
avg_envstep_per_episode: 335.0
avg_sample_per_episode: 335.0
avg_envstep_per_sec: 497.1869060586966
avg_train_sample_per_sec: 497.1869060586966
avg_episode_per_sec: 1.4841400180856614
collect_time: 1.3475817481019936
reward_mean: 2029.5
reward_std: 991.5
reward_max: 3021.0
reward_min: 1038.0
total_envstep_count: 1260421
total_train_sample_count: 1260408
total_episode_count: 5999
total_duration: 2513.7700071844474
[2022-12-21 16:37:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2174
train_sample_count: 2174
avg_envstep_per_episode: 362.3333333333333
avg_sample_per_episode: 362.3333333333333
avg_envstep_per_sec: 501.0982369910907
avg_train_sample_per_sec: 501.0982369910907
avg_episode_per_sec: 1.3829758150628078
collect_time: 4.33847066206831
reward_mean: 1992.3333740234375
reward_std: 1026.3431396484375
reward_max: 3022.0
reward_min: 231.0
total_envstep_count: 1261423
total_train_sample_count: 1261382
total_episode_count: 6005
total_duration: 2518.1084778465156
[2022-12-21 16:37:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 354
train_sample_count: 354
avg_envstep_per_episode: 177.0
avg_sample_per_episode: 177.0
avg_envstep_per_sec: 488.4029357826933
avg_train_sample_per_sec: 488.4029357826933
avg_episode_per_sec: 2.759338620241205
collect_time: 0.7248113679593162
reward_mean: 972.0
reward_std: 161.0
reward_max: 1133.0
reward_min: 811.0
total_envstep_count: 1262421
total_train_sample_count: 1262372
total_episode_count: 6007
total_duration: 2518.833289214475
[2022-12-21 16:37:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 491
train_sample_count: 491
avg_envstep_per_episode: 491.0
avg_sample_per_episode: 491.0
avg_envstep_per_sec: 498.20014855473187
avg_train_sample_per_sec: 498.20014855473187
avg_episode_per_sec: 1.014664253675625
collect_time: 0.9855476788282393
reward_mean: 3023.0
reward_std: 0.0
reward_max: 3023.0
reward_min: 3023.0
total_envstep_count: 1263388
total_train_sample_count: 1263355
total_episode_count: 6008
total_duration: 2519.8188368933033
[2022-12-21 16:37:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1177
train_sample_count: 1177
avg_envstep_per_episode: 294.25
avg_sample_per_episode: 294.25
avg_envstep_per_sec: 494.23196567241234
avg_train_sample_per_sec: 494.23196567241234
avg_episode_per_sec: 1.679632848504375
collect_time: 2.381472834114783
reward_mean: 1721.5
reward_std: 654.4747924804688
reward_max: 2600.0
reward_min: 761.0
total_envstep_count: 1264377
total_train_sample_count: 1264340
total_episode_count: 6012
total_duration: 2522.2003097274182
[2022-12-21 16:37:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1796
train_sample_count: 1796
avg_envstep_per_episode: 449.0
avg_sample_per_episode: 449.0
avg_envstep_per_sec: 493.0287754692446
avg_train_sample_per_sec: 493.0287754692446
avg_episode_per_sec: 1.098059633561792
collect_time: 3.642789405731219
reward_mean: 2444.75
reward_std: 981.9409790039062
reward_max: 3019.0
reward_min: 744.0
total_envstep_count: 1265374
total_train_sample_count: 1265332
total_episode_count: 6016
total_duration: 2525.8430991331493
[2022-12-21 16:37:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1030
train_sample_count: 1030
avg_envstep_per_episode: 257.5
avg_sample_per_episode: 257.5
avg_envstep_per_sec: 501.6883919724138
avg_train_sample_per_sec: 501.6883919724138
avg_episode_per_sec: 1.9483044348443255
collect_time: 2.0530672355214397
reward_mean: 1624.0
reward_std: 349.83709716796875
reward_max: 1892.0
reward_min: 1038.0
total_envstep_count: 1266331
total_train_sample_count: 1266302
total_episode_count: 6020
total_duration: 2527.896166368671
[2022-12-21 16:37:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 831
train_sample_count: 831
avg_envstep_per_episode: 415.5
avg_sample_per_episode: 415.5
avg_envstep_per_sec: 499.33396602579273
avg_train_sample_per_sec: 499.33396602579273
avg_episode_per_sec: 1.201766464562678
collect_time: 1.6642168499249965
reward_mean: 2211.5
reward_std: 790.5
reward_max: 3002.0
reward_min: 1421.0
total_envstep_count: 1267337
total_train_sample_count: 1267289
total_episode_count: 6022
total_duration: 2529.560383218596
[2022-12-21 16:37:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 203
train_sample_count: 203
avg_envstep_per_episode: 203.0
avg_sample_per_episode: 203.0
avg_envstep_per_sec: 503.33543229197346
avg_train_sample_per_sec: 503.33543229197346
avg_episode_per_sec: 2.4794848881378004
collect_time: 0.40330957643022497
reward_mean: 1320.0
reward_std: 0.0
reward_max: 1320.0
reward_min: 1320.0
total_envstep_count: 1268592
total_train_sample_count: 1268560
total_episode_count: 6023
total_duration: 2529.9636927950264
[2022-12-21 16:37:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1488
train_sample_count: 1488
avg_envstep_per_episode: 496.0
avg_sample_per_episode: 496.0
avg_envstep_per_sec: 500.2284275435171
avg_train_sample_per_sec: 500.2284275435171
avg_episode_per_sec: 1.0085250555312846
collect_time: 2.9746410201178586
reward_mean: 2787.666748046875
reward_std: 319.3830871582031
reward_max: 3016.0
reward_min: 2336.0
total_envstep_count: 1269573
total_train_sample_count: 1269532
total_episode_count: 6026
total_duration: 2532.9383338151442
[2022-12-21 16:37:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1314
train_sample_count: 1314
avg_envstep_per_episode: 438.0
avg_sample_per_episode: 438.0
avg_envstep_per_sec: 495.0331760048719
avg_train_sample_per_sec: 495.0331760048719
avg_episode_per_sec: 1.1302127306047305
collect_time: 2.654367552907339
reward_mean: 2624.0
reward_std: 562.8569946289062
reward_max: 3022.0
reward_min: 1828.0
total_envstep_count: 1270563
total_train_sample_count: 1270522
total_episode_count: 6029
total_duration: 2535.5927013680516
[2022-12-21 16:37:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1034
train_sample_count: 1034
avg_envstep_per_episode: 344.6666666666667
avg_sample_per_episode: 344.6666666666667
avg_envstep_per_sec: 501.20829452061986
avg_train_sample_per_sec: 501.20829452061986
avg_episode_per_sec: 1.4541826726903864
collect_time: 2.06301454166669
reward_mean: 1862.6666259765625
reward_std: 829.3099365234375
reward_max: 3001.0
reward_min: 1049.0
total_envstep_count: 1271528
total_train_sample_count: 1271496
total_episode_count: 6032
total_duration: 2537.6557159097183
[2022-12-21 16:38:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1153
train_sample_count: 1153
avg_envstep_per_episode: 288.25
avg_sample_per_episode: 288.25
avg_envstep_per_sec: 508.1155622304007
avg_train_sample_per_sec: 508.1155622304007
avg_episode_per_sec: 1.7627599730456227
collect_time: 2.269168838165169
reward_mean: 1771.0
reward_std: 129.40826416015625
reward_max: 1889.0
reward_min: 1552.0
total_envstep_count: 1272518
total_train_sample_count: 1272469
total_episode_count: 6036
total_duration: 2539.9248847478834
[2022-12-21 16:38:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 675
train_sample_count: 675
avg_envstep_per_episode: 225.0
avg_sample_per_episode: 225.0
avg_envstep_per_sec: 498.2627420067894
avg_train_sample_per_sec: 498.2627420067894
avg_episode_per_sec: 2.2145010755857304
collect_time: 1.3547069509580196
reward_mean: 1384.6666259765625
reward_std: 357.3255615234375
reward_max: 1890.0
reward_min: 1131.0
total_envstep_count: 1273477
total_train_sample_count: 1273432
total_episode_count: 6039
total_duration: 2541.2795916988416
[2022-12-21 16:38:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 823
train_sample_count: 823
avg_envstep_per_episode: 411.5
avg_sample_per_episode: 411.5
avg_envstep_per_sec: 493.36876075930775
avg_train_sample_per_sec: 493.36876075930775
avg_episode_per_sec: 1.1989520310068231
collect_time: 1.6681234513781962
reward_mean: 2342.0
reward_std: 671.0
reward_max: 3013.0
reward_min: 1671.0
total_envstep_count: 1274437
total_train_sample_count: 1274399
total_episode_count: 6041
total_duration: 2542.9477151502197
[2022-12-21 16:38:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1544
train_sample_count: 1544
avg_envstep_per_episode: 308.8
avg_sample_per_episode: 308.8
avg_envstep_per_sec: 489.42891180101964
avg_train_sample_per_sec: 489.42891180101964
avg_episode_per_sec: 1.584938185884131
collect_time: 3.1546971639217807
reward_mean: 1775.0
reward_std: 1086.6527099609375
reward_max: 3020.0
reward_min: 231.0
total_envstep_count: 1275392
total_train_sample_count: 1275367
total_episode_count: 6046
total_duration: 2546.1024123141415
[2022-12-21 16:38:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 936
train_sample_count: 936
avg_envstep_per_episode: 234.0
avg_sample_per_episode: 234.0
avg_envstep_per_sec: 494.6904645155589
avg_train_sample_per_sec: 494.6904645155589
avg_episode_per_sec: 2.1140618141690553
collect_time: 1.8920922620099565
reward_mean: 1426.75
reward_std: 1008.0846557617188
reward_max: 3020.0
reward_min: 231.0
total_envstep_count: 1276349
total_train_sample_count: 1276327
total_episode_count: 6050
total_duration: 2547.9945045761515
[2022-12-21 16:38:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1069
train_sample_count: 1069
avg_envstep_per_episode: 267.25
avg_sample_per_episode: 267.25
avg_envstep_per_sec: 493.2856171669185
avg_train_sample_per_sec: 493.2856171669185
avg_episode_per_sec: 1.8457834131596575
collect_time: 2.1671014981940386
reward_mean: 1615.5
reward_std: 578.8516845703125
reward_max: 2603.0
reward_min: 1133.0
total_envstep_count: 1277386
total_train_sample_count: 1277348
total_episode_count: 6054
total_duration: 2550.1616060743454
[2022-12-21 16:38:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 207
train_sample_count: 207
avg_envstep_per_episode: 207.0
avg_sample_per_episode: 207.0
avg_envstep_per_sec: 507.785955565924
avg_train_sample_per_sec: 507.785955565924
avg_episode_per_sec: 2.453072249110744
collect_time: 0.4076520780676179
reward_mean: 1318.0
reward_std: 0.0
reward_max: 1318.0
reward_min: 1318.0
total_envstep_count: 1278641
total_train_sample_count: 1278599
total_episode_count: 6055
total_duration: 2550.569258152413
[2022-12-21 16:38:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 644
train_sample_count: 644
avg_envstep_per_episode: 322.0
avg_sample_per_episode: 322.0
avg_envstep_per_sec: 502.0839490911442
avg_train_sample_per_sec: 502.0839490911442
avg_episode_per_sec: 1.559266922643305
collect_time: 1.2826540286056696
reward_mean: 1869.0
reward_std: 737.0
reward_max: 2606.0
reward_min: 1132.0
total_envstep_count: 1279623
total_train_sample_count: 1279603
total_episode_count: 6057
total_duration: 2551.8519121810186
[2022-12-21 16:38:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2081
train_sample_count: 2081
avg_envstep_per_episode: 346.8333333333333
avg_sample_per_episode: 346.8333333333333
avg_envstep_per_sec: 500.0105306202826
avg_train_sample_per_sec: 500.0105306202826
avg_episode_per_sec: 1.4416449705534338
collect_time: 4.161912344962891
reward_mean: 1818.8333740234375
reward_std: 1036.62646484375
reward_max: 3008.0
reward_min: 231.0
total_envstep_count: 1280625
total_train_sample_count: 1280580
total_episode_count: 6063
total_duration: 2556.0138245259814
[2022-12-21 16:38:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1012
train_sample_count: 1012
avg_envstep_per_episode: 506.0
avg_sample_per_episode: 506.0
avg_envstep_per_sec: 502.2908775467056
avg_train_sample_per_sec: 502.2908775467056
avg_episode_per_sec: 0.9926697184717501
collect_time: 2.0147688226846188
reward_mean: 2666.0
reward_std: 349.0
reward_max: 3015.0
reward_min: 2317.0
total_envstep_count: 1281583
total_train_sample_count: 1281544
total_episode_count: 6065
total_duration: 2558.028593348666
[2022-12-21 16:38:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 546
train_sample_count: 546
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 498.1408962262838
avg_train_sample_per_sec: 498.1408962262838
avg_episode_per_sec: 1.8246919275688052
collect_time: 1.0960754359585363
reward_mean: 1692.0
reward_std: 138.0
reward_max: 1830.0
reward_min: 1554.0
total_envstep_count: 1282550
total_train_sample_count: 1282510
total_episode_count: 6067
total_duration: 2559.1246687846246
[2022-12-21 16:38:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1222
train_sample_count: 1222
avg_envstep_per_episode: 305.5
avg_sample_per_episode: 305.5
avg_envstep_per_sec: 497.0003976875345
avg_train_sample_per_sec: 497.0003976875345
avg_episode_per_sec: 1.6268425456220441
collect_time: 2.458750547657056
reward_mean: 1812.75
reward_std: 551.7002563476562
reward_max: 2337.0
reward_min: 1039.0
total_envstep_count: 1283514
total_train_sample_count: 1283480
total_episode_count: 6071
total_duration: 2561.5834193322817
[2022-12-21 16:38:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 772
train_sample_count: 772
avg_envstep_per_episode: 386.0
avg_sample_per_episode: 386.0
avg_envstep_per_sec: 493.7732852253586
avg_train_sample_per_sec: 493.7732852253586
avg_episode_per_sec: 1.2792054021382346
collect_time: 1.5634705706033862
reward_mean: 2163.0
reward_std: 847.0
reward_max: 3010.0
reward_min: 1316.0
total_envstep_count: 1284504
total_train_sample_count: 1284468
total_episode_count: 6073
total_duration: 2563.146889902885
[2022-12-21 16:38:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1401
train_sample_count: 1401
avg_envstep_per_episode: 350.25
avg_sample_per_episode: 350.25
avg_envstep_per_sec: 494.25999252360623
avg_train_sample_per_sec: 494.25999252360623
avg_episode_per_sec: 1.4111634333293541
collect_time: 2.8345405681061413
reward_mean: 2083.5
reward_std: 552.397705078125
reward_max: 3008.0
reward_min: 1543.0
total_envstep_count: 1285493
total_train_sample_count: 1285449
total_episode_count: 6077
total_duration: 2565.981430470991
